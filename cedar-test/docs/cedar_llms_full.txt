Source: https://docs.cedarcopilot.com/llms-full.txt
Fetched: 2025-08-26T02:04:56.534415+00:00
ETag: None
Last-Modified: None
# Agent Backend Connection
Source: https://docs.cedarcopilot.com/agent-backend-connection/agent-backend-connection

Overview of connecting AI agents to Cedar-OS

<Info>
  If you already have your backend setup, you can skip this. Move onto [Creating
  custom agent flows](/agent-backend-connection/custom-request) and [Processing
  agent responses](/agent-backend-connection/custom-response-processing) to
  understand how Cedar-OS makes a network call and handles the response.
</Info>

Before we get to the juicy interactions like speaking to your AI for it to do work
inside your applications, we have to connect to the agent!

Cedar-OS has working configurations with every major backend. We support:

* **Mastra** - Full-featured agent framework with memory, tools, and knowledge base
* **AI SDK** - Vercel's unified AI SDK supporting multiple providers
* **OpenAI** - Direct OpenAI API integration
* **Anthropic** - Direct Anthropic API integration
* **Custom Backend** - Build your own integration

## How to choose your provider

* **You want a full-featured agent: Mastra** - When you need memory across sessions (conversation history), tool calls, knowledge base, and more complex agent capabilities.
* **Simplicity: AI SDK** - One interface, multiple providers. Perfect for getting started quickly.
* **You only have one API Key: Anthropic/OpenAI** - Direct integration with a single provider.
* **You already have a custom backend (e.g Langchain): Custom Backend** - glad I could help :^)

## Initial Configuration

Choose your provider and configure it with the CedarCopilot component. By default, this will make your chat and all other functions to the backend work

<CodeGroup>
  ```tsx AI SDK
  import { CedarCopilot } from 'cedar-os';

  // TypeScript Type
  type AISDKConfig = {
  	provider: 'ai-sdk';
  	providers: {
  		openai?: { apiKey: string };
  		anthropic?: { apiKey: string };
  		google?: { apiKey: string };
  		mistral?: { apiKey: string };
  		groq?: { apiKey: string };
  		xai?: { apiKey: string };
  	};
  };

  function App() {
  	return (
  		// You don't need to put every model,
  		// but if you try to use a model without a key it will fail
  		<CedarCopilot
  			llmProvider={{
  				provider: 'ai-sdk',
  				providers: {
  					openai: {
  						apiKey: process.env.NEXT_PUBLIC_OPENAI_API_KEY,
  					},
  					anthropic: {
  						apiKey: process.env.NEXT_PUBLIC_ANTHROPIC_API_KEY,
  					},
  					google: {
  						apiKey: process.env.NEXT_PUBLIC_GOOGLE_API_KEY,
  					},
  					groq: {
  						apiKey: process.env.GROQ_API_KEY,
  					},
  					xai: {
  						apiKey: process.env.XAI_API_KEY,
  					},
  				},
  			}}>
  			<YourApp />
  		</CedarCopilot>
  	);
  }
  ```

  ```tsx OpenAI
  import { CedarCopilot } from 'cedar-os';

  // TypeScript Type
  type OpenAIConfig = {
  	provider: 'openai';
  	apiKey: string;
  };

  function App() {
  	return (
  		<CedarCopilot
  			llmProvider={{
  				provider: 'openai',
  				apiKey: process.env.NEXT_PUBLIC_OPENAI_API_KEY,
  			}}>
  			<YourApp />
  		</CedarCopilot>
  	);
  }
  ```

  ```tsx Anthropic
  import { CedarCopilot } from 'cedar-os';

  // TypeScript Type
  type AnthropicConfig = {
  	provider: 'anthropic';
  	apiKey: string;
  };

  function App() {
  	return (
  		<CedarCopilot
  			llmProvider={{
  				provider: 'anthropic',
  				apiKey: process.env.NEXT_PUBLIC_ANTHROPIC_API_KEY,
  			}}>
  			<YourApp />
  		</CedarCopilot>
  	);
  }
  ```

  ```tsx Mastra
  import { CedarCopilot } from 'cedar-os';

  // TypeScript Type
  type MastraConfig = {
  	provider: 'mastra';
  	baseURL: string;
  	apiKey?: string; // Optional: only if your backend requires auth
  	chatPath?: string; // Optional: base chat path (defaults to '/chat')
  	voiceRoute?: string; // Optional: voice endpoint route (auto-configures voice endpoint)
  };

  function App() {
  	return (
  		<CedarCopilot
  			llmProvider={{
  				provider: 'mastra',
  				baseURL: 'http://localhost:3000/api', // Your Mastra backend URL
  				apiKey: process.env.MASTRA_API_KEY, // Optional: only if your backend requires auth
  				chatPath: '/chat', // Optional: base chat path (defaults to '/chat')
  				voiceRoute: '/chat/voice-execute', // Optional: voice endpoint route
  			}}>
  			<YourApp />
  		</CedarCopilot>
  	);
  }
  ```

  ```tsx Custom Backend
  import { CedarCopilot } from 'cedar-os';

  // TypeScript Type
  type CustomConfig = {
  	provider: 'custom';
  	config: Record<string, unknown>; // Flexible config object for any custom backend needs
  };

  function App() {
  	return (
  		<CedarCopilot
  			llmProvider={{
  				provider: 'custom',
  				config: {
  					baseURL: 'https://your-api.com',
  					apiKey: 'your-api-key',
  					// Any additional config your backend needs
  					organizationId: 'org-123',
  					projectId: 'project-456',
  				},
  			}}>
  			<YourApp />
  		</CedarCopilot>
  	);
  }
  ```
</CodeGroup>

### Mastra Configuration Options

When using the Mastra provider, you have additional configuration options:

* **baseURL**: The base URL of your Mastra backend (required)
* **apiKey**: Optional API key if your backend requires authentication
* **chatPath**: Optional base path for chat endpoints (defaults to `/chat`)
* **voiceRoute**: Optional route for voice endpoints (automatically configures voice endpoint)

The `chatPath` parameter is particularly useful if your Mastra backend uses a different base path for chat endpoints. For example:

* With default `chatPath: '/chat'`: Routes become `/chat/execute-function`, `/chat/init`, etc.
* With custom `chatPath: '/api/v1/chat'`: Routes become `/api/v1/chat/execute-function`, `/api/v1/chat/init`, etc.

The `voiceRoute` parameter automatically configures the voice endpoint by combining it with the `baseURL`. For example:

* With `baseURL: 'http://localhost:3000/api'` and `voiceRoute: '/chat/voice-execute'`: Voice endpoint becomes `http://localhost:3000/api/chat/voice-execute`
* If not specified, the voice endpoint remains at the default value and must be configured manually

The high-level `sendMessage()` function (that handles sending the chat), calls by default:

* `${chatPath}` (on message send, non-streaming)
* `${chatPath}/stream` (on message send, streaming).

You can still override this by passing a custom `route` parameter to `sendMessage()`.

### Typed Provider Connection

Cedar-OS provides full TypeScript support. When you configure a provider, all methods are properly typed:

```typescript
// Types can be found in cedar-os/types.ts

// Base params sent to all providers
export interface BaseParams {
	prompt: string; // Compiled frontend context and user message
	systemPrompt?: string;
	temperature?: number;
	maxTokens?: number;
	[key: string]: unknown;
}

// What the frontend expects in return
export interface LLMResponse {
	content: string; // In the chat sendMessage() flow, this is the message added to the chat
	usage?: {
		promptTokens: number;
		completionTokens: number;
		totalTokens: number;
	};
	metadata?: Record<string, unknown>;
	object?: StructuredResponseType | StructuredResponseType[]; // See the docs on How Responses are Processed to understand how this field is parsed
}
```

<AccordionGroup>
  <Accordion title="Reserved object shapes in the Cedar chat">
    When returning structured data in the `object` field of `LLMResponse`, objects with a `type` field have special meanings in Cedar-OS:

    **`type: "setState"`** - Defers to frontend setState execution (state manipulation)

    * Learn more: [Agentic State Access](/state-access/agentic-state-access)

    **`type: "message"`** - Processes and adds content as a message in the chat

    * Automatically renders the object content as a new chat message
    * Note: if you return an object with this type AND a content field, both will be rendered as chat messages in the order the are received

    Other `type` values can be used for custom handling (such as generative UI). See [Custom Response Handling](/agent-backend-connection/custom-response-processing) to learn how this works.
  </Accordion>
</AccordionGroup>

When designing agentic workflows, the best practice for working with Cedar-OS is to create typed functions with hardcoded system prompts in a single file. This approach ensures consistency, type safety, and reusability across your application.

<CodeGroup>
  ```tsx AI SDK
  import { useTypedAgentConnection } from 'cedar-os';
  import { z } from 'zod';

  // Get a typed connection for AI SDK
  const { callLLM, streamLLM, callLLMStructured } =
  	useTypedAgentConnection('ai-sdk');

  interface AISDKParams extends BaseParams {
  	model: string; // Format: "provider/model" e.g., "openai/gpt-4o", "anthropic/claude-3-sonnet"
  }

  // Example with OpenAI model through AI SDK
  const openaiResponse = await callLLM({
  	model: 'openai/gpt-4o',
  	prompt: 'Hello, AI!',
  	systemPrompt: 'You are a helpful assistant.',
  });

  // Example with Anthropic model through AI SDK
  const anthropicResponse = await callLLM({
  	model: 'anthropic/claude-3-sonnet',
  	prompt: 'Hello, AI!',
  	systemPrompt: 'You are a helpful assistant.',
  });

  // Example with xAI Grok model through AI SDK
  const grokResponse = await callLLM({
  	model: 'xai/grok-beta',
  	prompt: 'Hello, AI!',
  	systemPrompt: 'You are a helpful assistant.',
  });

  // Structured response example with Zod schema
  const ProductSchema = z.object({
  	name: z.string(),
  	price: z.number(),
  	category: z.string(),
  	inStock: z.boolean(),
  	description: z.string(),
  });

  type Product = z.infer<typeof ProductSchema>;

  const structuredResponse: Product = await callLLMStructured({
  	model: 'openai/gpt-4o',
  	prompt: 'Generate a product for a tech store',
  	systemPrompt: 'You are a product generator for an electronics store.',
  	schema: ProductSchema,
  });

  // structuredResponse.object is now fully typed as Product
  console.log(structuredResponse.object.name); // string
  console.log(structuredResponse.object.price); // number
  console.log(structuredResponse.object.inStock); // boolean
  ```

  ```tsx OpenAI
  import { useTypedAgentConnection } from 'cedar-os';
  import { z } from 'zod';

  // Get a typed connection for OpenAI
  const { callLLM, streamLLM, callLLMStructured } =
  	useTypedAgentConnection('openai');

  interface OpenAIParams extends BaseParams {
  	model: string;
  }

  // Example usage
  const response = await callLLM({
  	model: 'gpt-4o',
  	prompt: 'Generate a product description for a new product',
  	systemPrompt:
  		'You are a product description generator. You are given a product name and you need to generate a product description for it.',
  });

  // Streaming example
  const stream = await streamLLM({
  	model: 'gpt-4o',
  	prompt: 'Tell me a story',
  	systemPrompt: 'You are a creative storyteller.',
  });

  // Structured response example
  const UserAnalysisSchema = z.object({
  	sentiment: z.enum(['positive', 'negative', 'neutral']),
  	confidence: z.number().min(0).max(1),
  	keyTopics: z.array(z.string()),
  	actionItems: z.array(
  		z.object({
  			task: z.string(),
  			priority: z.enum(['low', 'medium', 'high']),
  			dueDate: z.string().optional(),
  		})
  	),
  });

  type UserAnalysis = z.infer<typeof UserAnalysisSchema>;

  const analysisResponse: UserAnalysis = await callLLMStructured({
  	model: 'gpt-4o',
  	prompt:
  		'Analyze this user feedback: "The app is great but loading times are slow"',
  	systemPrompt:
  		'You are a user feedback analyzer. Extract sentiment, topics, and action items.',
  	schema: UserAnalysisSchema,
  });

  // analysisResponse.object is fully typed as UserAnalysis
  console.log(analysisResponse.object.sentiment); // 'positive' | 'negative' | 'neutral'
  console.log(analysisResponse.object.confidence); // number
  console.log(analysisResponse.object.actionItems[0].priority); // 'low' | 'medium' | 'high'
  ```

  ```tsx Anthropic
  import { useTypedAgentConnection } from 'cedar-os';
  import { z } from 'zod';

  // Get a typed connection for Anthropic
  const { callLLM, streamLLM, callLLMStructured } =
  	useTypedAgentConnection('anthropic');

  interface AnthropicParams extends BaseParams {
  	model: string;
  }

  // Example usage
  const response = await callLLM({
  	model: 'claude-3-sonnet-20240229',
  	prompt: 'Hello, AI!',
  	systemPrompt: 'You are a helpful assistant.',
  });

  // System prompts example
  const analysisResponse = await callLLM({
  	model: 'claude-3-opus-20240229',
  	prompt: 'Analyze this data...',
  	systemPrompt:
  		'You are a data analyst with expertise in statistical analysis.',
  });

  // Structured response example with complex schema
  const CodeReviewSchema = z.object({
  	overallScore: z.number().min(1).max(10),
  	issues: z.array(
  		z.object({
  			type: z.enum([
  				'bug',
  				'performance',
  				'security',
  				'style',
  				'maintainability',
  			]),
  			severity: z.enum(['low', 'medium', 'high', 'critical']),
  			line: z.number().optional(),
  			description: z.string(),
  			suggestion: z.string(),
  		})
  	),
  	strengths: z.array(z.string()),
  	recommendations: z.array(
  		z.object({
  			category: z.string(),
  			action: z.string(),
  			impact: z.enum(['low', 'medium', 'high']),
  		})
  	),
  });

  type CodeReview = z.infer<typeof CodeReviewSchema>;

  const codeReviewResponse: CodeReview = await callLLMStructured({
  	model: 'claude-3-opus-20240229',
  	prompt: 'Review this React component code: [code here]',
  	systemPrompt:
  		'You are a senior software engineer conducting a thorough code review.',
  	schema: CodeReviewSchema,
  });

  // codeReviewResponse.object is fully typed as CodeReview
  console.log(codeReviewResponse.object.overallScore); // number (1-10)
  console.log(codeReviewResponse.object.issues[0].severity); // 'low' | 'medium' | 'high' | 'critical'
  console.log(codeReviewResponse.object.recommendations[0].impact); // 'low' | 'medium' | 'high'
  ```

  ```tsx Mastra
  import { useTypedAgentConnection } from 'cedar-os';
  import { z } from 'zod';

  // Get a typed connection for Mastra
  const { callLLM, streamLLM, callLLMStructured } =
  	useTypedAgentConnection('mastra');

  interface MastraParams extends BaseParams {
  	route: string;
  	resourceId?: string; // User ID in Cedar
  	threadId?: string;
  }

  // Example usage
  const response = await callLLM({
  	route: '/chat/completions', // Full route path
  	prompt: 'Hello, AI!',
  });

  // Response is fully typed as LLMResponse
  console.log(response.content); // string
  console.log(response.usage?.totalTokens); // number | undefined
  console.log(response.object); // unknown (for structured responses)

  // Example with additional Mastra features
  // Note: When using sendMessage(), the default route is automatically constructed
  // as `${chatPath}` (e.g., '/chat')
  const advancedResponse = await callLLM({
  	route: '/chat', // This would be the default for sendMessage()
  	prompt: 'Remember my name is John',
  	// Additional Mastra-specific parameters can be added
  	sessionId: 'user-123',
  	tools: ['web_search', 'calculator'],
  	knowledgeBaseId: 'kb-456',
  });

  // Structured response example with Mastra
  const TaskPlanSchema = z.object({
  	title: z.string(),
  	steps: z.array(
  		z.object({
  			id: z.number(),
  			description: z.string(),
  			estimatedTime: z.string(),
  			dependencies: z.array(z.number()).optional(),
  			toolsRequired: z.array(z.string()).optional(),
  		})
  	),
  	totalEstimatedTime: z.string(),
  	complexity: z.enum(['simple', 'moderate', 'complex']),
  	requiredTools: z.array(z.string()),
  });

  type TaskPlan = z.infer<typeof TaskPlanSchema>;

  const taskPlanResponse: TaskPlan = await callLLMStructured({
  	route: '/chat/structured',
  	prompt: 'Create a plan to build a todo app with user authentication',
  	schema: TaskPlanSchema,
  	// Mastra-specific parameters
  	sessionId: 'user-123',
  	tools: ['web_search', 'code_generator'],
  	knowledgeBaseId: 'development-kb',
  });

  // taskPlanResponse.object is fully typed as TaskPlan
  console.log(taskPlanResponse.object.title); // string
  console.log(taskPlanResponse.object.steps[0].estimatedTime); // string
  console.log(taskPlanResponse.object.complexity); // 'simple' | 'moderate' | 'complex'
  console.log(taskPlanResponse.object.requiredTools); // string[]
  ```

  ```tsx Custom Backend
  import { useTypedAgentConnection } from 'cedar-os';
  import { z } from 'zod';

  // Get a typed connection for Custom Backend
  const { callLLM, streamLLM, callLLMStructured } =
  	useTypedAgentConnection('custom');

  interface CustomParams extends BaseParams {
  	userId?: string;
  	threadId?: string;
  	[key: string]: unknown;
  }

  // Example usage with custom parameters
  const response = await callLLM({
  	prompt: 'Hello, AI!',
  	systemPrompt: 'You are a helpful assistant.',
  	// Custom backend specific parameters
  	organizationId: 'org-123',
  	projectId: 'project-456',
  	customParameter: 'custom-value',
  });

  // Streaming example with custom parameters
  const stream = await streamLLM({
  	prompt: 'Generate a report',
  	systemPrompt: 'You are a report generator.',
  	organizationId: 'org-123',
  	projectId: 'project-456',
  	streamOptions: {
  		bufferSize: 1024,
  		timeout: 30000,
  	},
  });

  // Custom authentication example
  const authenticatedResponse = await callLLM({
  	prompt: 'Secure request',
  	systemPrompt: 'You are a secure assistant.',
  	headers: {
  		'X-Custom-Auth': 'bearer-token',
  		'X-Request-ID': 'req-789',
  	},
  	organizationId: 'org-123',
  });

  // Structured response example with custom backend
  const ReportSchema = z.object({
  	summary: z.string(),
  	metrics: z.object({
  		totalUsers: z.number(),
  		activeUsers: z.number(),
  		conversionRate: z.number().min(0).max(1),
  		revenue: z.number(),
  	}),
  	insights: z.array(
  		z.object({
  			category: z.string(),
  			finding: z.string(),
  			impact: z.enum(['positive', 'negative', 'neutral']),
  			confidence: z.number().min(0).max(1),
  		})
  	),
  	recommendations: z.array(z.string()),
  	generatedAt: z.string(),
  });

  type Report = z.infer<typeof ReportSchema>;

  const reportResponse: Report = await callLLMStructured({
  	prompt: 'Generate a business analytics report based on the provided data',
  	systemPrompt: 'You are a business analyst creating comprehensive reports.',
  	schema: ReportSchema,
  	// Custom backend parameters
  	organizationId: 'org-123',
  	projectId: 'project-456',
  	dataSource: 'analytics-db',
  	reportType: 'monthly',
  	headers: {
  		'X-Custom-Auth': 'bearer-token',
  		'X-Report-Format': 'structured',
  	},
  });

  // reportResponse.object is fully typed as Report
  console.log(reportResponse.object.summary); // string
  console.log(reportResponse.object.metrics.conversionRate); // number (0-1)
  console.log(reportResponse.object.insights[0].impact); // 'positive' | 'negative' | 'neutral'
  console.log(reportResponse.object.recommendations); // string[]
  ```
</CodeGroup>

For more advanced usage, see our guides on:

* [Chat Input](/agent-input-context/agent-input-context) - Building rich chat interfaces
* [Messages](/chat/chat-overview) - Handling AI responses
* [State Access](/state-access/agentic-state-access) - Managing application state

## Detailed Provider Guides

For more advanced configuration and usage patterns:

* [Extending Mastra](/agent-backend-connection/mastra) - Full agent framework with backend extension guides
* [Custom Backend](/agent-backend-connection/custom) - Build your own integration through API


# Custom Backend Implementation
Source: https://docs.cedarcopilot.com/agent-backend-connection/custom

Learn how to create a custom backend provider for Cedar-OS by implementing the required provider interface functions.

# Custom Backend Implementation

Cedar-OS provides a flexible agent connection system that allows you to integrate with any LLM provider or custom backend. This guide explains how to implement a custom provider by creating the required functions and registering them with the system.

## Agent Connection Architecture

The Cedar-OS agent connection system is built around a **provider pattern** that abstracts different LLM services behind a common interface. Each provider implements a set of standardized functions that handle:

* **Non-streaming LLM calls** (`callLLM`)
* **Structured output calls** (`callLLMStructured`)
* **Streaming responses** (`streamLLM`)
* **Response parsing** (`handleResponse`, `handleStreamResponse`)

The system automatically handles:

* Request/response logging
* Error handling and retries
* Stream management and cancellation
* Type safety and validation

## Provider Interface

Every custom provider must implement the `ProviderImplementation` interface with these 5 required functions:

```typescript
interface ProviderImplementation<TParams, TConfig> {
	callLLM: (params: TParams, config: TConfig) => Promise<LLMResponse>;
	callLLMStructured: (
		params: TParams & StructuredParams,
		config: TConfig
	) => Promise<LLMResponse>;
	streamLLM: (
		params: TParams,
		config: TConfig,
		handler: StreamHandler
	) => StreamResponse;
	handleResponse: (response: Response) => Promise<LLMResponse>;
	handleStreamResponse: (chunk: string) => StreamEvent;
}
```

## Required Function Implementations

### 1. `callLLM` - Basic LLM Calls

**Purpose:** Make non-streaming calls to your LLM service.

**Input Parameters:**

```typescript
interface CustomParams extends BaseParams {
	prompt: string; // The user's input prompt
	systemPrompt?: string; // Optional system prompt
	temperature?: number; // Sampling temperature (0-1)
	maxTokens?: number; // Maximum tokens to generate
	[key: string]: unknown; // Any additional custom parameters
}

// Your custom config type
type CustomConfig = { provider: 'custom'; config: Record<string, unknown> };
```

**Expected Output:**

```typescript
interface LLMResponse {
	content: string; // The generated text response
	usage?: {
		// Optional token usage info
		promptTokens: number;
		completionTokens: number;
		totalTokens: number;
	};
	metadata?: Record<string, unknown>; // Optional metadata (model, id, etc.)
	object?: StructuredResponseType | StructuredResponseType[]; // For structured output (See How Responses are Processed)
}
```

**Example Implementation:**

```typescript
callLLM: async (params, config) => {
	const { prompt, systemPrompt, temperature, maxTokens, ...rest } = params;

	// Build your API request
	const response = await fetch('https://your-api.com/chat/completions', {
		method: 'POST',
		headers: {
			'Content-Type': 'application/json',
			Authorization: `Bearer ${config.config.apiKey}`,
		},
		body: JSON.stringify({
			messages: [
				...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
				{ role: 'user', content: prompt },
			],
			temperature,
			max_tokens: maxTokens,
			...rest,
		}),
	});

	return this.handleResponse(response);
};
```

### 2. `callLLMStructured` - Structured Output Calls

**Purpose:** Make calls that return structured data (JSON) based on a provided schema.

**Input Parameters:**

```typescript
interface StructuredParams {
	schema?: unknown; // JSON Schema or Zod schema
	schemaName?: string; // Name for the schema
	schemaDescription?: string; // Description of expected output
}

// Combined with your custom params
type StructuredCustomParams = CustomParams & StructuredParams;
```

**Expected Output:** Same as `callLLM`, but with the `object` field populated with parsed structured data.

**Example Implementation:**

```typescript
callLLMStructured: async (params, config) => {
	const {
		prompt,
		systemPrompt,
		schema,
		schemaName,
		schemaDescription,
		...rest
	} = params;

	const body = {
		messages: [
			...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
			{ role: 'user', content: prompt },
		],
		...rest,
	};

	// Add schema for structured output (format depends on your API)
	if (schema) {
		body.response_format = {
			type: 'json_schema',
			json_schema: {
				name: schemaName || 'response',
				description: schemaDescription,
				schema: schema,
			},
		};
	}

	const response = await fetch('https://your-api.com/chat/completions', {
		method: 'POST',
		headers: {
			'Content-Type': 'application/json',
			Authorization: `Bearer ${config.config.apiKey}`,
		},
		body: JSON.stringify(body),
	});

	const result = await this.handleResponse(response);

	// Parse structured output if schema was provided
	if (schema && result.content) {
		try {
			result.object = JSON.parse(result.content);
		} catch {
			// Leave object undefined if parsing fails
		}
	}

	return result;
};
```

### 3. `streamLLM` - Streaming Responses

**Purpose:** Handle real-time streaming responses from your LLM service.

**Input Parameters:**

* Same `params` as `callLLM`
* `handler`: A callback function to process stream events

**Stream Handler Types:**

```typescript
type StreamEvent =
	| { type: 'chunk'; content: string } // New content chunk
	| { type: 'done' } // Stream completed
	| { type: 'error'; error: Error } // Error occurred
	| { type: 'metadata'; data: unknown }; // Optional metadata

type StreamHandler = (event: StreamEvent) => void | Promise<void>;
```

**Expected Output:**

```typescript
interface StreamResponse {
	abort: () => void; // Function to cancel the stream
	completion: Promise<void>; // Promise that resolves when stream completes
}
```

**Example Implementation:**

```typescript
streamLLM: (params, config, handler) => {
	const abortController = new AbortController();

	const completion = (async () => {
		try {
			const { prompt, systemPrompt, temperature, maxTokens, ...rest } = params;

			const response = await fetch('https://your-api.com/chat/completions', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
					Authorization: `Bearer ${config.config.apiKey}`,
				},
				body: JSON.stringify({
					messages: [
						...(systemPrompt
							? [{ role: 'system', content: systemPrompt }]
							: []),
						{ role: 'user', content: prompt },
					],
					temperature,
					max_tokens: maxTokens,
					stream: true, // Enable streaming
					...rest,
				}),
				signal: abortController.signal,
			});

			if (!response.ok) {
				throw new Error(`HTTP error! status: ${response.status}`);
			}

			// Handle Server-Sent Events stream
			await this.handleEventStream(response, {
				onMessage: (chunk) => {
					// Parse your API's streaming format
					try {
						const data = JSON.parse(chunk);
						const content = data.choices?.[0]?.delta?.content || '';
						if (content) {
							handler({ type: 'chunk', content });
						}
					} catch {
						// Skip parsing errors
					}
				},
				onDone: () => {
					handler({ type: 'done' });
				},
			});
		} catch (error) {
			if (error instanceof Error && error.name !== 'AbortError') {
				handler({ type: 'error', error });
			}
		}
	})();

	return {
		abort: () => abortController.abort(),
		completion,
	};
};
```

### 4. `handleResponse` - Parse API Responses

**Purpose:** Convert your API's response format to the standard `LLMResponse` format.

**Input:** Standard `Response` object from fetch
**Output:** `LLMResponse` object

**Example Implementation:**

```typescript
handleResponse: async (response) => {
	if (!response.ok) {
		throw new Error(`HTTP error! status: ${response.status}`);
	}

	const data = await response.json();

	return {
		content: data.choices?.[0]?.message?.content || data.text || '',
		usage: data.usage
			? {
					promptTokens: data.usage.prompt_tokens || 0,
					completionTokens: data.usage.completion_tokens || 0,
					totalTokens: data.usage.total_tokens || 0,
			  }
			: undefined,
		metadata: {
			model: data.model,
			id: data.id,
			// Add any other relevant metadata
		},
	};
};
```

### 5. `handleStreamResponse` - Parse Stream Chunks

**Purpose:** Convert individual stream chunks to `StreamEvent` objects.

**Input:** Raw string chunk from the stream
**Output:** `StreamEvent` object

**Example Implementation:**

```typescript
handleStreamResponse: (chunk) => {
	try {
		const data = JSON.parse(chunk);
		const content = data.choices?.[0]?.delta?.content || '';
		return { type: 'chunk', content };
	} catch (error) {
		return { type: 'error', error: error as Error };
	}
};
```

## Complete Custom Provider Example

Here's a complete example of a custom provider implementation:

```typescript
import type {
	CustomParams,
	ProviderImplementation,
	InferProviderConfig,
	StructuredParams,
	LLMResponse,
	StreamHandler,
	StreamResponse,
	StreamEvent,
} from '@cedar-os/core';

type CustomConfig = InferProviderConfig<'custom'>;

export const myCustomProvider: ProviderImplementation<
	CustomParams,
	CustomConfig
> = {
	callLLM: async (params, config) => {
		const { prompt, systemPrompt, temperature, maxTokens, ...rest } = params;

		const response = await fetch(`${config.config.baseURL}/chat/completions`, {
			method: 'POST',
			headers: {
				'Content-Type': 'application/json',
				Authorization: `Bearer ${config.config.apiKey}`,
			},
			body: JSON.stringify({
				messages: [
					...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
					{ role: 'user', content: prompt },
				],
				temperature,
				max_tokens: maxTokens,
				...rest,
			}),
		});

		return myCustomProvider.handleResponse(response);
	},

	callLLMStructured: async (params, config) => {
		// Implementation similar to callLLM but with schema handling
		// ... (see example above)
	},

	streamLLM: (params, config, handler) => {
		// Implementation for streaming
		// ... (see example above)
	},

	handleResponse: async (response) => {
		if (!response.ok) {
			throw new Error(`HTTP error! status: ${response.status}`);
		}

		const data = await response.json();
		return {
			content: data.response || data.text || '',
			usage: data.usage,
			metadata: { model: data.model, id: data.id },
		};
	},

	handleStreamResponse: (chunk) => {
		try {
			const data = JSON.parse(chunk);
			const content = data.delta?.content || '';
			return { type: 'chunk', content };
		} catch (error) {
			return { type: 'error', error: error as Error };
		}
	},
};
```

## Registering Your Custom Provider

After implementing your provider, you need to register it with the Cedar-OS system:

### 1. Add to Provider Registry

Update the provider registry in `packages/cedar-os/src/store/agentConnection/providers/index.ts`:

```typescript
import { myCustomProvider } from './my-custom-provider';

export const providerRegistry = {
	openai: openAIProvider,
	anthropic: openAIProvider,
	mastra: mastraProvider,
	'ai-sdk': aiSDKProvider,
	custom: myCustomProvider, // Replace the default with your implementation
} as const;
```

### 2. Configure the Provider

Set up your custom provider configuration:

```typescript
import { useCedarStore } from '@cedar-os/core';

const store = useCedarStore();

// Configure your custom provider
store.setProviderConfig({
	provider: 'custom',
	config: {
		apiKey: 'your-api-key',
		baseURL: 'https://your-api.com',
		model: 'your-model-name',
		// Any other configuration your provider needs
	},
});

// Connect to the provider
await store.connect();
```

### 3. Use the Provider

Once configured, you can use your custom provider like any other:

```typescript
// Make a basic call
const response = await store.callLLM({
	prompt: 'Hello, world!',
	temperature: 0.7,
	maxTokens: 100,
});

// Make a streaming call
store.streamLLM(
	{
		prompt: 'Tell me a story',
		temperature: 0.8,
	},
	(event) => {
		if (event.type === 'chunk') {
			console.log('New content:', event.content);
		} else if (event.type === 'done') {
			console.log('Stream completed');
		}
	}
);
```

## Helper Utilities

Cedar-OS provides several utility functions to help with common tasks:

### Event Stream Handling

For processing Server-Sent Events streams:

```typescript
import { handleEventStream } from '@cedar-os/core';

await handleEventStream(response, {
	onMessage: (chunk) => {
		handler({ type: 'chunk', content: chunk });
	},
	onDone: () => {
		handler({ type: 'done' });
	},
});
```

### Type Safety

Use TypeScript interfaces for better type safety:

```typescript
interface MyProviderParams extends CustomParams {
	model: string;
	customSetting?: boolean;
}

interface MyProviderConfig {
	provider: 'custom';
	config: {
		apiKey: string;
		baseURL: string;
		defaultModel: string;
	};
}
```

## Best Practices

1. **Error Handling**: Always handle network errors, API errors, and parsing errors gracefully
2. **Abort Signals**: Support cancellation in streaming operations using `AbortController`
3. **Type Safety**: Use TypeScript interfaces for better development experience
4. **Logging**: The system automatically logs requests/responses, but you can add custom logging
5. **Configuration**: Make your provider configurable through the config object
6. **Testing**: Test all functions thoroughly, especially streaming and error scenarios

## Troubleshooting

**Provider not found**: Make sure you've registered your provider in the provider registry.

**Type errors**: Ensure your parameter and config types extend the required base interfaces.

**Streaming issues**: Check that your API supports Server-Sent Events and that you're parsing the format correctly.

**Authentication errors**: Verify your API key and authentication method match your provider's requirements.


# Creating custom agent flows
Source: https://docs.cedarcopilot.com/agent-backend-connection/custom-request

Learn how Cedar makes appropriate calls to your agent

Cedar provides a flexible system for creating custom agent flows that can work with different backend providers. This guide explains how Cedar prepares requests, routes calls, and handles responses from your agent backend.

<img src="https://mintlify.s3.us-west-1.amazonaws.com/cedar/images/gettingInput.png" alt="Cedar-OS  Diagram" />

### Preparing the Request Body

Before making any call to your agent backend, Cedar automatically assembles all the necessary context and data. This preparation process ensures your agent receives comprehensive information to generate meaningful responses.

<Steps>
  <Step title="User prompt extraction">
    Cedar extracts the current user input from the chat editor, converting the rich text content into a clean string format.

    ```tsx
    // Cedar automatically calls stringifyEditor() to extract text
    const editorContent = state.stringifyEditor();
    // Result: "What's the status of the user authentication feature?"
    ```
  </Step>

  <Step title="State and context gathering">
    Cedar collects all subscribed state and additional context that has been registered with the agent input system.

    ```tsx
    // Cedar automatically gathers additional context
    const additionalContext = state.stringifyAdditionalContext();
    // Result includes: subscribed state, custom setters, mention data, etc.
    ```

    <Note>
      The `agentInputContextSlice` manages all context gathering. See [Agent Input Context](/agent-input-context/agent-input-context) for details on how to subscribe state and provide context to your agents.
    </Note>
  </Step>

  <Step title="Context tokenization">
    Cedar serializes the collected context into a structured format that your agent backend can parse and understand.

    ```tsx
    // Example of tokenized additional context
    {
      "todos": [
        { "id": "1", "title": "Fix login bug", "completed": false }
      ],
        	"setters": {
    			"addTodo": {
    			"name": "addTodo",
    			"stateKey": "todos",
    			"description": "Add a new todo item",
    			"schema": {
    				"type": "object",
    				"properties": {
    				"title": {
    					"type": "string",
    					"description": "The title of the todo item"
    				}
    				},
    				"required": ["title"]
    			}
    			}
          }
    }
    ```
  </Step>

  <Step title="Network Request Body Structure">
    The network request body varies significantly between providers, allowing Cedar to work with different backend architectures while maintaining a consistent internal API.

    For mastra and Custom backends, we pass in additionalContext, state, and more as seperate fields to give you control over what you want to do with the context and state.

    For direct LLM calls, we automatically tokenise the additionalContext & prompt into one string for optimal responses.

    ### Request Body Differences

    <CodeGroup>
      ```json Mastra Format
      {
        "prompt": "What's the status of the user authentication feature?",
        "systemPrompt": "You are a helpful project manager...",
        "additionalContext": {
          "todos": [...],
          "setters": {...}
        },
        "states": {
      	"emails:": [...]
        },
        "route": "/chat",
        "resourceId": "user123",
        "threadId": "thread456",
      }
      ```

      ```json OpenAI Format
      {
      	"model": "gpt-4o-mini",
      	"messages": [
      		{
      			"role": "system",
      			"content": "You are a helpful project manager..."
      		},
      		{
      			"role": "user",
      			"content": "
      			User Text: What's the status of the user authentication feature?

      			Additional Context: {
      				  todos: [
      				    { id: 1, title: Fix login bug, completed: false }
      			  ],
      			  setters: {
      				    addTodo: {
      				      name: addTodo,
      			      stateKey: todos,
      			      description: Add a new todo item,
      			      parameters: [title: string]
      			    }
      			  }
      			}"
      		}
      	],
      }
      ```

      ```json Custom Format
      {
        "prompt": "What's the status of the user authentication feature?",
        "additionalContext": {
          "todos": [...],
          "setters": {...}
        },
        "states": {
      	"emails:": [...]
        },
      }
      ```
    </CodeGroup>
  </Step>
</Steps>

## Creating Your Own AI Workflow

Beyond using Cedar's built-in agent connections, you can create custom AI workflows that leverage Cedar's context system while implementing your own processing logic.

<Steps>
  <Step title="Define your prompt">
    Create a function that defines a specific prompt for your workflow. This allows you to customize the AI's behavior for your specific use case.

    ```tsx
    function createSummaryWorkflow() {
    	const systemPrompt = `You are a project summary assistant. 
      Analyze the provided todos and create a concise project status report. 
      Focus on completion rates and upcoming priorities.`;

    	return systemPrompt;
    }
    ```
  </Step>

  <Step title="Extract specific additional context">
    Use Cedar's context system to get exactly the data your workflow needs. You can filter and transform the context to match your requirements.

    ```tsx
    function getProjectContext(state: CedarState) {
    	const additionalContext = state.stringifyAdditionalContext();

    	// Extract only the data relevant to project summaries
    	const projectContext = {
    		todos: additionalContext.todos || [],
    		deadlines: additionalContext.deadlines || [],
    		teamMembers: additionalContext.teamMembers || [],
    	};

    	return projectContext;
    }
    ```
  </Step>

  <Step title="Call the LLM">
    Make the API call to your chosen LLM provider with your custom prompt and filtered context.

    ```tsx
    async function callLLM(prompt: string, context: any) {
    	const response = await fetch('https://api.openai.com/v1/chat/completions', {
    		method: 'POST',
    		headers: {
    			Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    			'Content-Type': 'application/json',
    		},
    		body: JSON.stringify({
    			model: 'gpt-4o-mini',
    			messages: [
    				{
    					role: 'system',
    					content: createSummaryWorkflow(),
    				},
    				{
    					role: 'user',
    					content: `Project Context: ${JSON.stringify(
    						context,
    						null,
    						2
    					)}\n\nGenerate a project summary.`,
    				},
    			],
    		}),
    	});

    	return response;
    }
    ```
  </Step>

  <Step title="Handle the LLM response">
    Process the raw LLM response using Cedar's response handling system to ensure proper integration with your application.

    ```tsx
    async function handleLLMResponse(response: Response, state: CedarState) {
    	const data = await response.json();
    	const content = data.choices[0]?.message?.content;

    	// Use Cedar's response processor
    	const processor = state.agentConnection.responseProcessors.get('message');
    	if (processor && content) {
    		await processor(content, state);
    	}

    	return content;
    }
    ```
  </Step>

  <Step title="Custom parsing and return">
    Add your own parsing logic to extract structured data from the LLM response and return it in the format your application needs.

    ```tsx
    function parseProjectSummary(llmResponse: string) {
    	// Extract structured data from the response
    	const summaryMatch = llmResponse.match(/Summary: (.*?)(?:\n|$)/);
    	const prioritiesMatch = llmResponse.match(/Priorities: (.*?)(?:\n|$)/);
    	const completionMatch = llmResponse.match(/Completion: (\d+)%/);

    	return {
    		summary: summaryMatch?.[1] || '',
    		priorities: prioritiesMatch?.[1]?.split(',').map((p) => p.trim()) || [],
    		completionRate: completionMatch?.[1] ? parseInt(completionMatch[1]) : 0,
    		generatedAt: new Date().toISOString(),
    	};
    }

    // Complete workflow function
    export async function runProjectSummaryWorkflow(state: CedarState) {
    	try {
    		const context = getProjectContext(state);
    		const response = await callLLM(createSummaryWorkflow(), context);
    		const llmContent = await handleLLMResponse(response, state);
    		const structuredResult = parseProjectSummary(llmContent);

    		return structuredResult;
    	} catch (error) {
    		console.error('Project summary workflow failed:', error);
    		throw error;
    	}
    }
    ```
  </Step>
</Steps>

<Note>
  For more advanced response processing patterns and custom response handlers,
  see [Custom Response
  Processing](/agent-backend-connection/custom-response-processing) to learn how
  to create sophisticated response processors that can handle streaming,
  actions, and complex data transformations.
</Note>


# Processing agent responses
Source: https://docs.cedarcopilot.com/agent-backend-connection/custom-response-processing

Learn how Cedar deals with all structured objects returned from the backend.

Cedar processes your agent responses via a switch statement based on the "type" field.

This allows you to completely customize how structured responses from your agent backend are processed. This is the system through which messages are added to the chat, state actions are executed, or any decisions are made on how to deal with responses from the backend.

<img src="https://mintlify.s3.us-west-1.amazonaws.com/cedar/images/handlingLLMResponse.png" alt="Cedar-OS  Diagram" />

Note: This system is how we run anything user customisable, such as [Custom Message Rendering](/chat/custom-message-rendering).

## LLM Response Structure

When your agent backend returns responses, they follow the `LLMResponse` interface:

```tsx
interface LLMResponse {
	content: string; // Text content from the LLM
	usage?: {
		promptTokens: number;
		completionTokens: number;
		totalTokens: number;
	};
	metadata?: Record<string, unknown>; // Additional metadata
	// The object field contains structured output when using JSON Schema or Zod
	object?: StructuredResponseType | StructuredResponseType[];
}
```

The **`object` field** is where Cedar looks for structured responses to process. It can contain:

* A single `StructuredResponseType` object
* An array of `StructuredResponseType` objects for multiple operations
* `undefined` if no structured output was generated

Only objects in the `object` field are processed by the response processing system. The `content` field is always added to the chat by default as a simple text message.

## Base Response Type

All structured responses in Cedar extend the `BaseStructuredResponseType` interface:

```tsx
interface BaseStructuredResponseType {
	type: string; // String identifier for processor matching
	content?: string; // Optional text content
}
```

## Requirements for Custom Response Processing

To use the custom response processing system, your response objects must have a `type` field. This field determines which processor will be used to handle the response.

```tsx
// Valid response - has required 'type' field
{
  type: 'notification',
  content: 'Task completed successfully',
  level: 'success'
}

// Invalid - missing 'type' field
{
  content: 'This response will be added as a regular message'
}
```

## Response Processor Interface

Cedar uses a strongly typed `ResponseProcessor` interface that ensures type safety throughout the processing pipeline:

```tsx
export interface ResponseProcessor<
	T extends StructuredResponseType = StructuredResponseType
> {
	type: string; // Must match the response type
	namespace?: string; // Optional organization namespace
	execute: (obj: T, store: CedarStore) => void | Promise<void>; // Receives narrowly typed response
	validate?: (obj: StructuredResponseType) => obj is T; // Receives broadly typed response for validation
}
```

**Key typing features:**

* The `execute` function receives your **narrowly typed custom response** (e.g., `NotificationResponse`)
* The `validate` function receives the **broadly typed `StructuredResponseType`** for runtime validation

## Custom Response Type Definition

Cedar exports a `CustomStructuredResponseType<T, P>` type that allows you to create type-safe custom responses:

```tsx
import { CustomStructuredResponseType } from 'cedar-os';

// T = type string, P = additional properties
export type CustomStructuredResponseType<
	T extends string,
	P extends object = Record<string, never>
> = BaseStructuredResponseType & { type: T } & P;

// Example usage
type NotificationResponse = CustomStructuredResponseType<
	'notification',
	{
		level: 'info' | 'success' | 'warning' | 'error';
	}
>;

type StateUpdateResponse = CustomStructuredResponseType<
	'state-update',
	{
		key: string;
		value: any;
		timestamp: string;
	}
>;
```

## Response Processor Factory Function

Cedar exports a `createResponseProcessor` factory function to create type-safe processors:

```tsx
import { createResponseProcessor } from 'cedar-os';

// Create a processor with full type safety
const NotificationProcessor = createResponseProcessor<NotificationResponse>({
	type: 'notification',
	namespace: 'my-app',
	execute: (obj, store) => {
		// obj is narrowly typed as NotificationResponse
		showToast(obj.content, obj.level);
		store.addMessage({
			type: 'text',
			role: 'assistant',
			content: `ðŸ“¢ ${obj.content}`,
		});
	},
	validate: (obj): obj is NotificationResponse => {
		// obj is broadly typed as StructuredResponseType for validation
		return obj.type === 'notification' && 'level' in obj;
	},
});
```

## How Response Processing Works Internally

When a response comes back from the backend, Cedar uses the following process:

1. **Response Reception**: The system receives the LLM response and checks for structured objects in the `object` field
2. **Type Detection**: If an object exists, the system examines its `type` field
3. **Processor Lookup**: The system searches for a registered processor that matches the response type
4. **Validation**: If a processor is found and has a validation function, it checks if the response structure is valid
5. **Processing**: If validation passes (or no validation exists), the processor's `execute` function is called
6. **Override Behavior**: This is the ONLY thing that runs - it completely overrides default behavior, so if you want to add the message to chat, you must do so manually in your processor

## Full Implementation Examples

```tsx
import {
	createResponseProcessor,
	CustomStructuredResponseType,
} from 'cedar-os';

// Define custom response type
type UnregisteredResponseType = CustomStructuredResponseType<
	'unregistered_event',
	{ level: string }
>;

// Create the processor
const responseProcessor = createResponseProcessor<UnregisteredResponseType>({
	type: 'unregistered_event',
	namespace: 'product-roadmap',
	execute: (obj, store) => {
		// Custom processing logic
		console.log('ðŸ”¥ Unregistered event', obj);

		// Manually add to chat if desired
		store.addMessage({
			type: 'text',
			role: 'assistant',
			content: `Received ${obj.type} with level: ${obj.level}`,
		});
	},
	validate: (obj): obj is UnregisteredResponseType => {
		return obj.type === 'unregistered_event' && 'level' in obj;
	},
});

// Register with CedarCopilot
<CedarCopilot
	responseProcessors={[responseProcessor]}
	// ... other props
>
	{children}
</CedarCopilot>;
```

## Default Response Types and Processors

Cedar automatically handles these response types with default behavior. Each type has a corresponding default processor:

### `"message"` Type

* **Behavior**: Adds text messages directly to chat with specified role
* **Properties**: `content: string`, `role?: 'user' | 'assistant' | 'bot'`
* **Default Processor**: `messageResponseProcessor` adds messages to chat

```tsx
// Default messageResponseProcessor implementation
const messageResponseProcessor = {
	type: 'message',
	execute: (obj, store) => {
		store.addMessage({
			role: obj.role || 'assistant',
			content: obj.content,
			type: 'text',
		});
	},
};
```

### `"setState"` Type

* **Behavior**: Executes state actions via custom setters and adds setState message to chat
* **Properties**: `stateKey: string`, `setterKey: string`, `args?: unknown[]`
* **Default Processor**: `setStateResponseProcessor` executes state actions and adds to chat

```tsx
// Default setStateResponseProcessor implementation
const setStateResponseProcessor = {
	type: 'setState',
	namespace: 'default',
	execute: async (obj, store) => {
		// Execute the state action
		const args = Array.isArray(obj.args) ? obj.args : [];
		store.executeCustomSetter(obj.stateKey, obj.setterKey, ...args);

		// Add setState message to chat
		store.addMessage(obj as unknown as MessageInput);
	},
	validate: (obj): obj is SetStateResponse =>
		obj.type === 'setState' &&
		'stateKey' in obj &&
		'setterKey' in obj &&
		typeof obj.stateKey === 'string' &&
		typeof obj.setterKey === 'string',
};
```

**SetState Factory Functions**: Cedar provides special factory functions for setState responses:

```tsx
import { createSetStateResponseProcessor, SetStateResponseFor } from 'cedar-os';

// Specific setState response type using helper
type UpdateCounterResponse = SetStateResponseFor<
	'counter', // StateKey
	'increment', // SetterKey
	[number] // Args
>;

// Create custom setState processor with filtering
const CounterSetStateProcessor =
	createSetStateResponseProcessor<UpdateCounterResponse>({
		namespace: 'counter',
		setterKey: 'increment', // Only handle increment actions
		execute: (obj, store) => {
			// Custom processing logic
			const amount = obj.args?.[0] || 1;
			store.executeCustomSetter('counter', 'increment', amount);

			// Custom message instead of default
			store.addMessage({
				type: 'text',
				role: 'assistant',
				content: `âœ… Counter incremented by ${amount}. New value: ${
					store.getState().counter.value
				}`,
			});
		},
	});
```

### `"progress_update"` Type

* **Behavior**: Updates existing progress messages or creates new ones with state tracking
* **Properties**: `text: string`, `state: 'in_progress' | 'complete' | 'error'`
* **Default Processor**: `progressUpdateResponseProcessor` manages progress message lifecycle

```tsx
// Default progressUpdateResponseProcessor implementation
const progressUpdateResponseProcessor = {
	type: 'progress_update',
	execute: (obj, store) => {
		const existingMessage = store.findProgressMessage(obj.text);

		if (existingMessage) {
			store.updateMessage(existingMessage.id, {
				metadata: { ...existingMessage.metadata, state: obj.state },
			});
		} else {
			store.addMessage({
				type: 'progress_update',
				role: 'assistant',
				content: obj.text,
				metadata: { state: obj.state },
			});
		}
	},
};
```

**âš ï¸ Important**: If you override any of these default types, you lose the built-in behavior. Since processors completely override default handling, ensure your custom implementation covers all functionality you need, including adding messages to the chat if desired.

## Recommended File Structure

Cedar encourages organizing custom processors in dedicated files for easier maintenance and debugging:

```
src/
  cedar-os/
    processors/
      responseProcessors.ts   // All custom response processors
      index.ts               // Export registration function
  components/
    Layout.tsx              // Register processors with CedarCopilot
```

This structure keeps all Cedar-related logic organized under a `cedar-os` directory, making it easier to maintain, debug, and ensure consistency across your application. Remember that processors completely override default behavior, so plan your implementations to handle all the functionality you need.


# Extending Mastra
Source: https://docs.cedarcopilot.com/agent-backend-connection/mastra

Connecting Cedar-OS with Mastra

Mastra is a full-featured typescript framework to build agents. It provides memory, tool calls, knowledge base, and more. It's our personal recommended choice when building complex agents.

## Initial Configuration

<Steps>
  <Step title="Set up your project">
    Run `plant-seed` and select either:

    * **Mastra starter** - for a complete setup with both frontend and backend
    * **Mastra reference repo** - to see a full implementation example

    If you already have a Mastra backend, use the **blank frontend cedar repo** option instead.

    For reference, you can still follow the official Mastra guide: [Install using the `create-mastra` CLI](https://mastra.ai/en/docs/getting-started/installation#install-using-the-create-mastra-cli).
  </Step>

  <Step title="Wrap your app with CedarCopilot">
    Wrap your application with the CedarCopilot provider to connect to your Mastra backend:

    ```tsx
    import { CedarCopilot } from 'cedar-os';
    function App() {
    	return (
    		<CedarCopilot
    			llmProvider={{
    				provider: 'mastra',
    				baseURL: 'http://localhost:4111', // default dev port for Mastra
    				apiKey: process.env.NEXT_PUBLIC_MASTRA_API_KEY, // optional â€” only for backend auth
    			}}>
    			<YourApp />
    		</CedarCopilot>
    	);
    }
    ```
  </Step>

  <Step title="Configure Mastra endpoints to talk to Cedar">
    Configure your Mastra backend to work with Cedar by following the Mastra-specific configuration options: [Mastra Configuration Options](https://docs.cedarcopilot.com/agent-backend-connection/agent-backend-connection#mastra-configuration-options)

    [Register API routes](https://mastra.ai/en/examples/deployment/custom-api-route) in your Mastra server so Cedar's chat components have something to talk to:

    ```ts mastra/src/index.ts
    import { registerApiRoute } from '@mastra/core/server';

    // POST /chat
    // The chat's non-streaming default endpoint
    registerApiRoute('/chat', {
    	method: 'POST',
    	// â€¦validate input w/ zod
    	handler: async (c) => {
    		/* your agent.generate() logic */
    	},
    });

    // POST /chat/stream (SSE)
    // The chat's streaming default endpoint
    registerApiRoute('/chat/stream', {
    	method: 'POST',
    	handler: async (c) => {
    		/* stream agent output in SSE format */
    	},
    });
    ```
  </Step>

  <Step title="Add Cedar Chat">
    Drop a Cedar chat component into your frontend â€“ see [Chat Overview](https://docs.cedarcopilot.com/chat/chat-overview).
    Your backend and frontend are now linked! You're ready to start bringing the power of your Mastra agentic workflows to your UI.
  </Step>
</Steps>

## Features to explore

Now that you have Cedar-OS connected to Mastra, explore these powerful features:

* **[State Access & Manipulation](https://docs.cedarcopilot.com/state-access/agentic-state-access)** - Use the `useRegisterState` hook for communicating frontend state and letting agents manipulate your frontend state
* **[Mentions & Context](https://docs.cedarcopilot.com/agent-input-context/mentions)** - Send @ mentions to your backend using the `useStateBasedMentionProvider`

## New to Mastra? Here are a few primitives to understand

<Tabs>
  <Tab title="Agent">
    ```ts
    // Agents encapsulate instructions, model, memory and tools
    export const roadmap = new Agent({
      name: 'Roadmap',
      model: openai('gpt-4o-mini'),
      tools: { upvoteTool },
      instructions: `You are â€¦`,
    });
    // Docs: https://mastra.ai/en/docs/agents/overview
    ```
  </Tab>

  <Tab title="Tool">
    ```ts
    // Tools expose type-safe side effects
    export const upvoteTool = createTool({
      id: 'upvote-feature',
      inputSchema: z.object({ id: z.string() }),
      execute: async ({ context }) => { /* â€¦ */ },
    });
    // Docs: https://mastra.ai/en/docs/tools-mcp/overview
    ```
  </Tab>

  <Tab title="Workflow">
    ```ts
    // Orchestrate multi-step logic
    const roadmapWorkflow = createWorkflow({ id: 'roadmap-analysis' })
      .then(step1)
      .then(step2);
    roadmapWorkflow.commit();
    // Docs: https://mastra.ai/en/docs/workflows/overview
    ```
  </Tab>

  <Tab title="index.ts">
    ```ts
    // Register all your Mastra primitives here, and configure agent memory, message storage, etc.
    export const mastra = new Mastra({
      agents: { roadmap },
      server: { apiRoutes },
      workflows: { roadmapWorkflow }
      storage: new LibSQLStore({ url: ':memory:' }),
    });
    ```
  </Tab>
</Tabs>

## Deployment

The recommended deployment setup is:

* **Frontend**: Deploy to [Vercel](https://vercel.com) for optimal performance and seamless integration
* **Backend**: Use [Mastra Cloud](https://mastra.ai/cloud) for hosting your Mastra server

## Next Steps

* Clone & run the [cedar-mastra-starter](https://github.com/CedarCopilot/cedar-mastra-starter) to see everything in action.
* Explore the official Mastra docs for further customisation.


# Advanced Context Management
Source: https://docs.cedarcopilot.com/agent-input-context/advanced-context-management

Handle complex state serialization and circular dependencies

## Handling Circular Dependencies with sanitiseJson

Cedar automatically applies `sanitiseJson` to your state when sending it as agent context, which intelligently handles circular dependencies by replacing them with reference paths (e.g., `"$ref:$.parent.child"`). If your backend has access to Cedar utilities, you can use `desanitiseJson` to restore the original object structure with all circular references intact.

For cases where you need precise control over the JSON structure being sent, pre-stringify your state before adding it to the context. This bypasses automatic sanitization, ensuring the exact shape you define is transmitted to your agent backend. This approach is particularly useful when working with backends that don't support reference resolution or when you need to maintain specific data formats.

```tsx
useSubscribeStateToInputContext<typeof Data>(
	'dashboard-data',
	(state) => {
		console.log('dashboard-data', state);
		return {
			Data: Flatten.stringify(state),
		};
	},
	{
		labelField: 'title',
	}
);
```


# Agent Input Context
Source: https://docs.cedarcopilot.com/agent-input-context/agent-input-context

Provide additional context to your AI agents

Agent Input Context allows you to provide additional information to your AI agents beyond just the user's message.

This includes application state, user data, conversation history, and any other contextual information that helps the agent provide better responses.

The underlying source of truth for this information is [Cedar state](/state-access/agentic-state-access), so it is helpful to understand how that works first.

## How It Works

When a user sends a message, Cedar automatically gathers context from various sources:

1. **Subscribed States**: Application state you've made available to the agent via `useCedarState` and subscribed to via `useSubscribeStateToInputContext`
2. **Mentions**: Specific data the user has referenced with @ mentions (registered using `useStateBasedMentionProvider`)
3. **Additional Context**: Context entries you've manually added (via `addContextEntry`)
4. **Chat Input Content**: The current editor content with mentions

Cedar provides several methods to stringify and access this context for your AI agents.

# Adding Context

> **Prerequisite** â€“ Before you can add any context or mentions *you must register the relevant React state in Cedar* using either [`useRegisterState`](/state-access/agentic-state-access#useRegisterState-Hook) or [`useCedarState`](/state-access/agentic-state-access#useCedarState). All examples below assume that registration step has already happened (or they demonstrate it explicitly).

## Mentions System

Cedar's mention system allows users to reference specific data using @ symbols. You can create mention providers that let users easily reference state data:

```tsx
import { useStateBasedMentionProvider } from 'cedar-os';
import { FileText } from 'lucide-react';

function DocumentChat() {
	const [documents] = useCedarState('documents', [
		{ id: 'doc1', title: 'Project Proposal', type: 'pdf' },
		{ id: 'doc2', title: 'Meeting Notes', type: 'doc' },
	]);

	// Create a mention provider for documents
	useStateBasedMentionProvider({
		stateKey: 'documents',
		trigger: '@',
		labelField: 'title',
		searchFields: ['title', 'type'],
		description: 'Documents',
		icon: <FileText size={16} />,
		color: '#8b5cf6',
		order: 5, // Control display order when mentioned
	});

	return <ChatInput />;
}
```

For detailed information about mentions, including custom providers, multiple triggers, and advanced rendering, see the [Mentions documentation](/agent-input-context/mentions).

## State Subscription

Keep a Cedar state continuously in sync with the agent input context via `useSubscribeStateToInputContext`:

```tsx
import { useCedarState, useSubscribeStateToInputContext } from 'cedar-os';
import { Settings } from 'lucide-react';

function AutoSyncChat() {
	// 1) Register / create the state in Cedar
	const [appState, setAppState] = useCedarState(
		'appState',
		{
			currentTab: 'dashboard',
			selectedItems: ['item1', 'item2'],
		},
		'UI navigation & selection info'
	);

	// 2) Subscribe that state to the agent context
	useSubscribeStateToInputContext(
		'appState',
		(state) => ({
			'app-state': [
				{
					id: 'current-state',
					currentTab: state.currentTab,
					selectedItems: state.selectedItems,
				},
			],
		}),
		{
			icon: <Settings size={16} />,
			color: '#6b7280',
			order: 10, // Control display order of context badges
		}
	);

	return <ChatInput />;
}
```

For comprehensive examples and best practices for state subscription, see the [Subscribing State documentation](/agent-input-context/subscribing-state).

# Advanced

This is for advanced understanding. Move on to [Agentic State Access](/state-access/agentic-state-access) or [Spells](/spells/spells) for better functionality.

## Default Context Tokenization

Cedar's `sendMessage` function automatically handles context based on your provider configuration:

### For Structured Providers (Mastra, Custom)

```tsx
// Inside sendMessage for Mastra/Custom providers
const editorContent = state.stringifyEditor(); // "Update @task-123 status"
const structuredContext = sanitizeJson(state.additionalContext); // Raw object

// Sent as separate fields:
const llmParams = {
	prompt: editorContent, // Clean user text
	additionalContext: structuredContext, // Structured data object
	route: '/chat',
	userId: 'user-123',
};
```

### For Text-Based Providers (OpenAI, Anthropic, AI-SDK)

```tsx
// Inside sendMessage for direct LLM providers
const editorContent = state.stringifyEditor(); // "Update @task-123 status"
const fullContext = state.stringifyInputContext(); // Combined string

// Sent as unified prompt:
const llmParams = {
	prompt: fullContext, // Contains: "User Text: ... \n\nAdditional Context: {...}"
	model: 'gpt-4o-mini',
};
```

## Backend Integration Examples

### Mastra Backend Example

```typescript
// Your Mastra agent receives structured data
export const chatAgent = {
	name: 'Chat Agent',
	instructions: 'You are a helpful assistant',
	model: 'gpt-4o-mini',

	async execute(input: { prompt: string; additionalContext?: any }) {
		const { prompt, additionalContext } = input;

		// Process user intent from clean prompt
		console.log('User wants:', prompt);

		// Access structured context programmatically
		if (additionalContext?.tasks) {
			const mentionedTasks = additionalContext.tasks
				.filter((entry) => entry.source === 'mention')
				.map((entry) => entry.data);

			console.log('Referenced tasks:', mentionedTasks);
		}

		// Your custom logic here...
	},
};
```

### Custom Provider Backend Example

```typescript
// Your custom endpoint receives both fields
app.post('/api/chat', async (req, res) => {
	const { prompt, additionalContext, userId } = req.body;

	// Clean user message for intent processing
	const userIntent = await processIntent(prompt);

	// Structured context for data operations
	const contextualData = {
		mentions: additionalContext?.tasks || [],
		userState: additionalContext?.['user-state'] || [],
		documents: additionalContext?.documents || [],
	};

	// Combine for LLM call
	const systemPrompt = `
    User Intent: ${userIntent}
    Available Context: ${JSON.stringify(contextualData)}
    
    Respond helpfully using the provided context.
  `;

	const response = await openai.chat.completions.create({
		model: 'gpt-4o-mini',
		messages: [
			{ role: 'system', content: systemPrompt },
			{ role: 'user', content: prompt },
		],
	});

	res.json({ content: response.choices[0].message.content });
});
```

## Accessing Additional Context

You can access the context data in several ways:

### Raw Context Access

```tsx
import { useCedarStore } from 'cedar-os';

function ContextInspector() {
	const { additionalContext } = useCedarStore();

	// Access raw context structure
	const tasks = additionalContext.tasks || [];
	const mentionedDocuments = additionalContext.documents || [];

	return (
		<div>
			<h3>Current Context:</h3>
			{Object.entries(additionalContext).map(([key, entries]) => (
				<div key={key}>
					<h4>{key}</h4>
					{entries.map((entry) => (
						<div key={entry.id}>
							{entry.metadata?.label} ({entry.source})
						</div>
					))}
				</div>
			))}
		</div>
	);
}
```

### Stringified Context Access

```tsx
import { useCedarStore } from 'cedar-os';

function ContextStringifier() {
	const { stringifyEditor, stringifyAdditionalContext, stringifyInputContext } =
		useCedarStore();

	const inspectContext = () => {
		// Get just the user's text input
		const userText = stringifyEditor();
		console.log('User text:', userText);

		// Get additional context as JSON (includes state data, setters, and schemas)
		const contextData = stringifyAdditionalContext();
		console.log('Context data:', contextData);

		// Get combined input and context (what gets sent to AI)
		const fullContext = stringifyInputContext();
		console.log('Full context:', fullContext);
	};

	return <button onClick={inspectContext}>Inspect Context</button>;
}
```

## Adding Specific Context

### Manual Context Entries

Add context entries programmatically for specific use cases:

```tsx
import { useCedarStore } from 'cedar-os';

function ErrorReportingChat() {
	const { addContextEntry, removeContextEntry } = useCedarStore();

	const addErrorContext = (error: Error) => {
		addContextEntry('errors', {
			id: `error-${Date.now()}`,
			source: 'manual',
			data: {
				message: error.message,
				stack: error.stack,
				timestamp: new Date().toISOString(),
				url: window.location.href,
			},
			metadata: {
				label: `Error: ${error.message}`,
				color: '#ef4444',
			},
		});
	};

	const addUserContext = (user: any) => {
		addContextEntry('user-info', {
			id: 'current-user',
			source: 'manual',
			data: {
				id: user.id,
				role: user.role,
				permissions: user.permissions,
			},
			metadata: {
				label: `User: ${user.name}`,
				color: '#3b82f6',
			},
		});
	};

	return (
		<div>
			<button onClick={() => addErrorContext(new Error('Sample error'))}>
				Add Error Context
			</button>
			<ChatInput />
		</div>
	);
}
```

### Conditional Context

Add context based on application state or user actions:

```tsx
import { useCedarStore } from 'cedar-os';
import { useEffect } from 'react';

function ConditionalContextChat() {
	const { addContextEntry, clearContextBySource } = useCedarStore();
	const currentRoute = useRouter().pathname;
	const selectedItems = useSelection();

	useEffect(() => {
		// Clear previous route context
		clearContextBySource('manual');

		// Add route-specific context
		if (currentRoute === '/dashboard') {
			addContextEntry('navigation', {
				id: 'dashboard-context',
				source: 'manual',
				data: {
					page: 'dashboard',
					widgets: getDashboardWidgets(),
					metrics: getCurrentMetrics(),
				},
				metadata: {
					label: 'Dashboard Context',
				},
			});
		}

		// Add selection context if items are selected
		if (selectedItems.length > 0) {
			addContextEntry('selection', {
				id: 'current-selection',
				source: 'manual',
				data: {
					items: selectedItems,
					count: selectedItems.length,
					types: [...new Set(selectedItems.map((item) => item.type))],
				},
				metadata: {
					label: `${selectedItems.length} items selected`,
				},
			});
		}
	}, [currentRoute, selectedItems]);

	return <ChatInput />;
}
```

## Custom Context Processing

Create your own message sending logic with custom context filtering:

```tsx
import { useCedarStore } from 'cedar-os';

function CustomContextProcessor() {
	const store = useCedarStore();

	const sendMessageWithFilteredContext = async (
		contextFilter?: (key: string, entries: ContextEntry[]) => ContextEntry[]
	) => {
		// Get the user's input
		const editorContent = store.stringifyEditor();

		// Get raw additional context
		const rawContext = store.additionalContext;

		// Apply custom filtering if provided
		let filteredContext = rawContext;
		if (contextFilter) {
			filteredContext = {};
			Object.entries(rawContext).forEach(([key, entries]) => {
				const filtered = contextFilter(key, entries);
				if (filtered.length > 0) {
					filteredContext[key] = filtered;
				}
			});
		}

		// Create custom context string
		const contextString = JSON.stringify(filteredContext, null, 2);
		const customPrompt = `User Text: ${editorContent}\n\nFiltered Context: ${contextString}`;

		// Send to AI with custom prompt
		const response = await store.callLLM({
			prompt: customPrompt,
			systemPrompt:
				'You are a helpful assistant with access to filtered context.',
		});

		// Handle response
		store.handleLLMResult(response);

		// Add user message to chat (persists by default if message storage is configured)
		store.addMessage({
			role: 'user',
			type: 'text',
			content: editorContent,
		});

		// Clear mentions after sending
		store.clearMentions();
	};

	// Example: Only include high-priority tasks
	const sendWithHighPriorityTasksOnly = () => {
		sendMessageWithFilteredContext((key, entries) => {
			if (key === 'tasks') {
				return entries.filter((entry) => entry.data.priority === 'high');
			}
			return entries; // Keep other context as-is
		});
	};

	// Example: Exclude sensitive data
	const sendWithoutSensitiveData = () => {
		sendMessageWithFilteredContext((key, entries) => {
			if (key === 'user-profile') {
				return entries.map((entry) => ({
					...entry,
					data: {
						...entry.data,
						email: undefined,
						phone: undefined,
						ssn: undefined,
					},
				}));
			}
			return entries;
		});
	};

	// Example: Only include recent items
	const sendWithRecentContextOnly = () => {
		const oneHourAgo = Date.now() - 60 * 60 * 1000;

		sendMessageWithFilteredContext((key, entries) => {
			return entries.filter((entry) => {
				const entryTime = entry.data.timestamp || entry.data.createdAt;
				return entryTime && new Date(entryTime).getTime() > oneHourAgo;
			});
		});
	};

	return (
		<div>
			<ChatInput />
			<div className='flex gap-2 mt-2'>
				<button onClick={sendWithHighPriorityTasksOnly}>
					Send with High Priority Tasks Only
				</button>
				<button onClick={sendWithoutSensitiveData}>
					Send without Sensitive Data
				</button>
				<button onClick={sendWithRecentContextOnly}>
					Send with Recent Context Only
				</button>
			</div>
		</div>
	);
}
```

## Next Steps

* Learn about [mentions functionality](/agent-input-context/mentions) for detailed @ mention patterns
* Explore [subscribing to state](/agent-input-context/subscribing-state) for automatic state synchronization


# Mentions
Source: https://docs.cedarcopilot.com/agent-input-context/mentions

Enable @ mentions for contextual references in chat

Cedar's mention system allows users to reference specific data, people, or objects in their messages using @ symbols. This provides a natural way to give agents precise context about what the user is referring to.

### State-Based Mentions using `useStateBasedMentionProvider`

> **Prerequisite** â€“ the state referenced by `stateKey` must already be registered in Cedar with [`useCedarState`](/state-access/agentic-state-access#useCedarState) or [`useRegisterState`](/state-access/agentic-state-access#useRegisterState-Hook).

Automatically allows the user to @ mention any registered state items. The state must first be a cedarState. See the [Agentic State](/state-access/agentic-state-access) documentation.

```tsx
import { useState } from 'react';
import { useRegisterState, useStateBasedMentionProvider } from 'cedar-os';

function TodoApp() {
	const [todos, setTodos] = useState([
		{ id: 1, text: 'Buy groceries', category: 'shopping' },
		{ id: 2, text: 'Call dentist', category: 'health' },
	]);

	// Register the state
	useRegisterState({
		key: 'todos',
		value: todos,
		setValue: setTodos,
		description: 'Todo items',
	});

	// Enable mentions for todos
	useStateBasedMentionProvider({
		stateKey: 'todos',
		trigger: '@',
		labelField: 'text',
		searchFields: ['text', 'category'],
		description: 'Todo items',
		icon: 'ðŸ“',
		color: '#3b82f6',
		order: 10, // Control display order of mentioned todos
	});

	return <ChatInput />;
}
```

This keeps all mentionable data in the unified Cedar store and makes it automatically available to the agent.

State-based mention providers take in the following configuration options:

```ts
export interface StateBasedMentionProviderConfig {
	stateKey: string; // What state to allow users to mention
	trigger?: string;
	labelField?: string | ((item: any) => string); // How it should be labelled when mentioned in the chat
	searchFields?: string[]; // What fields the user should be able to type to search for the element
	description?: string;
	icon?: ReactNode;
	color?: string; // Hex color
	order?: number; // Order for display (lower numbers appear first)
	renderMenuItem?: (item: MentionItem) => ReactNode;
	renderEditorItem?: (
		item: MentionItem,
		attrs: Record<string, any>
	) => ReactNode;
	renderContextBadge?: (entry: ContextEntry) => ReactNode;
}
```

## Custom Rendering

Customize how mentions appear in different contexts:

```tsx
import { useStateBasedMentionProvider } from 'cedar-os';

function CustomRendering() {
	useStateBasedMentionProvider({
		stateKey: 'users',
		trigger: '@',
		label: 'Users',
		icon: 'ðŸ‘¤',
		getItems: (query) => {
			// ... get items logic
		},
		toContextEntry: (item) => ({
			id: item.id,
			source: 'mention',
			data: item.data,
			metadata: { label: item.label, icon: 'ðŸ‘¤' },
		}),

		// Custom rendering in the mention menu
		renderMenuItem: (item) => (
			<div className='flex items-center gap-2 p-2'>
				<span className='text-lg'>ðŸ‘¤</span>
				<div>
					<div className='font-medium'>{item.label}</div>
					<div className='text-sm text-gray-500'>{item.data.role}</div>
				</div>
			</div>
		),

		// Custom rendering in the editor
		renderEditorItem: (item, attrs) => (
			<span className='bg-blue-100 text-blue-800 px-1 rounded'>
				ðŸ‘¤ {item.label}
			</span>
		),

		// Custom rendering in context badges
		renderContextBadge: (entry) => (
			<div className='bg-gray-100 px-2 py-1 rounded text-sm'>
				ðŸ‘¤ {entry.metadata?.label}
			</div>
		),
	});

	return <ChatInput />;
}
```

## Multiple Mention Types

Support different mention triggers:

```tsx
import { useStateBasedMentionProvider } from 'cedar-os';

function MultiMentionChat() {
	const users = [
		{ id: '1', name: 'Alice', role: 'Designer' },
		{ id: '2', name: 'Bob', role: 'Developer' },
	];

	const channels = [
		{ id: '1', name: 'general', topic: 'General discussion' },
		{ id: '2', name: 'dev', topic: 'Development updates' },
	];

	const commands = [
		{ id: '1', name: 'help', description: 'Show help' },
		{ id: '2', name: 'reset', description: 'Reset chat' },
	];

	// @ for users
	useStateBasedMentionProvider({
		stateKey: 'users',
		trigger: '@',
		label: 'Users',
		icon: 'ðŸ‘¤',
		getItems: (query) => {
			const filtered = query
				? users.filter((u) =>
						u.name.toLowerCase().includes(query.toLowerCase())
				  )
				: users;
			return filtered.map((user) => ({
				id: user.id,
				label: user.name,
				data: user,
				metadata: { icon: 'ðŸ‘¤' },
			}));
		},
		toContextEntry: (item) => ({
			id: item.id,
			source: 'mention',
			data: item.data,
			metadata: { label: item.label, icon: 'ðŸ‘¤' },
		}),
	});

	// # for channels/topics
	useStateBasedMentionProvider({
		stateKey: 'channels',
		trigger: '#',
		label: 'Channels',
		icon: 'ðŸ“¢',
		getItems: (query) => {
			const filtered = query
				? channels.filter((c) =>
						c.name.toLowerCase().includes(query.toLowerCase())
				  )
				: channels;
			return filtered.map((channel) => ({
				id: channel.id,
				label: channel.name,
				data: channel,
				metadata: { icon: 'ðŸ“¢' },
			}));
		},
		toContextEntry: (item) => ({
			id: item.id,
			source: 'mention',
			data: item.data,
			metadata: { label: item.label, icon: 'ðŸ“¢' },
		}),
	});

	// / for commands
	useStateBasedMentionProvider({
		stateKey: 'commands',
		trigger: '/',
		label: 'Commands',
		icon: 'âš¡',
		getItems: (query) => {
			const filtered = query
				? commands.filter((c) =>
						c.name.toLowerCase().includes(query.toLowerCase())
				  )
				: commands;
			return filtered.map((command) => ({
				id: command.id,
				label: command.name,
				data: command,
				metadata: { icon: 'âš¡' },
			}));
		},
		toContextEntry: (item) => ({
			id: item.id,
			source: 'mention',
			data: item.data,
			metadata: { label: item.label, icon: 'âš¡' },
		}),
	});

	return <ChatInput />;
}
```

## Contextual Mentions

Show different mentions based on context:

```tsx
import { useEffect } from 'react';
import { useStateBasedMentionProvider } from 'cedar-os';

function ContextualMentions() {
	const currentPage = useCurrentPage();

	// Conditional mention providers
	useEffect(() => {
		if (currentPage === 'projects') {
			const projects = getProjects();
			useStateBasedMentionProvider({
				stateKey: 'projects',
				trigger: '@',
				label: 'Projects',
				icon: 'ðŸ“',
				getItems: (query) => {
					const filtered = query
						? projects.filter((p) =>
								p.name.toLowerCase().includes(query.toLowerCase())
						  )
						: projects;
					return filtered.map((project) => ({
						id: project.id,
						label: project.name,
						data: project,
						metadata: { icon: 'ðŸ“' },
					}));
				},
				toContextEntry: (item) => ({
					id: item.id,
					source: 'mention',
					data: item.data,
					metadata: { label: item.label, icon: 'ðŸ“' },
				}),
			});
		} else if (currentPage === 'tasks') {
			const tasks = getTasks();
			useStateBasedMentionProvider({
				stateKey: 'tasks',
				trigger: '@',
				label: 'Tasks',
				icon: 'âœ…',
				getItems: (query) => {
					const filtered = query
						? tasks.filter((t) =>
								t.title.toLowerCase().includes(query.toLowerCase())
						  )
						: tasks;
					return filtered.map((task) => ({
						id: task.id,
						label: task.title,
						data: task,
						metadata: { icon: 'âœ…' },
					}));
				},
				toContextEntry: (item) => ({
					id: item.id,
					source: 'mention',
					data: item.data,
					metadata: { label: item.label, icon: 'âœ…' },
				}),
			});
		}
	}, [currentPage]);

	return <ChatInput />;
}

// Mock functions for demonstration
function useCurrentPage() {
	return 'projects'; // or 'tasks'
}

function getProjects() {
	return [
		{ id: '1', name: 'Website Redesign' },
		{ id: '2', name: 'Mobile App' },
	];
}

function getTasks() {
	return [
		{ id: '1', title: 'Review PR #123' },
		{ id: '2', title: 'Update documentation' },
	];
}
```

## Ordering Mentions

When you have multiple mention providers or context subscriptions, you can control their display order using the `order` property. This ensures the most important context appears first in the UI.

### Order Property

The `order` property (optional) determines the display order of context badges:

* **Lower numbers appear first**: `order: 1` appears before `order: 10`
* **Default behavior**: Items without an order appear last
* **Applies to both**: Mention providers and `useSubscribeInputContext`

### Example: Prioritized Mentions

```tsx
import {
	useStateBasedMentionProvider,
	useSubscribeInputContext,
} from 'cedar-os';
import { User, FileText, Tag, Archive } from 'lucide-react';

function PrioritizedMentions() {
	// Current user context - highest priority (order: 1)
	useSubscribeInputContext(currentUser, (user) => ({ currentUser: user }), {
		icon: <User />,
		color: '#8B5CF6',
		order: 1, // Always visible first
	});

	// Active documents - high priority (order: 5)
	useStateBasedMentionProvider({
		stateKey: 'activeDocuments',
		trigger: '@',
		labelField: 'title',
		description: 'Active Documents',
		icon: <FileText />,
		color: '#3B82F6',
		order: 5, // After user, before tags
	});

	// Tags - medium priority (order: 10)
	useStateBasedMentionProvider({
		stateKey: 'tags',
		trigger: '#',
		labelField: 'name',
		description: 'Tags',
		icon: <Tag />,
		color: '#10B981',
		order: 10, // After documents
	});

	// Archived items - low priority (order: 100)
	useStateBasedMentionProvider({
		stateKey: 'archivedItems',
		trigger: '@',
		labelField: 'title',
		description: 'Archived',
		icon: <Archive />,
		color: '#6B7280',
		order: 100, // Appears last
	});

	return <ChatInput />;
}
```

### Custom Provider with Order

When using `useStateBasedMentionProvider`, include order:

```tsx
useStateBasedMentionProvider({
	stateKey: 'priority-users',
	trigger: '@',
	order: 10,
});
```

### Best Practices for Ordering

1. **Reserve low numbers (1-9)** for critical context like user info
2. **Use 10-49** for active/selected items
3. **Use 50-99** for general mentions
4. **Use 100+** for archived or low-priority items
5. **Leave gaps** between orders for future additions

## Mention Data in Context

Access mentioned items in your agent context:

```tsx
// When user types: "Update the status of @task-123 to completed"
// The agent receives:
{
  message: "Update the status of @task-123 to completed",
  mentions: [
    {
      id: "task-123",
      type: "tasks",
      data: {
        id: "task-123",
        title: "Implement user authentication",
        status: "in-progress",
        assignee: "Alice"
      },
      position: { start: 23, end: 32 }
    }
  ]
}
```

## Next Steps

* Explore [state access patterns](/state-access/agentic-state-access)
* Learn about [spells and shortcuts](/spells/spells)


# Subscribing State to Input
Source: https://docs.cedarcopilot.com/agent-input-context/subscribing-state

Automatically add state to the agent input context

Cedar's `useSubscribeStateToInputContext` function allows you to automatically make any Cedar-registered state available to AI agents as context. This enables agents to understand your app's current state and provide more relevant, contextual responses.

> **Prerequisite** â€“ The state you want to subscribe **must first be registered** in Cedar using either [`useCedarState`](/state-access/agentic-state-access#useCedarState) *or* [`useRegisterState`](/state-access/agentic-state-access#useRegisterState-Hook).

## useSubscribeStateToInputContext Overview

The `useSubscribeStateToInputContext` function subscribes to local state changes and automatically updates the agent's input context whenever the state changes. This means your AI agent always has access to the most up-to-date information from your application, including any Zod schemas defined for the state.

### Function Signature

```typescript
function useSubscribeStateToInputContext<T>(
	stateKey: string,
	mapFn: (state: T) => Record<string, any>,
	options?: {
		icon?: ReactNode;
		color?: string;
		labelField?: string | ((item: unknown) => string);
		order?: number;
		showInChat?: boolean;
	}
): void;
```

### Parameters

* **`stateKey: string`** - The registered state key that we want to subscribe to
* **`mapFn: (state: T) => Record<string, any>`** - Function that maps your state to context entries
* **`options`** (optional) - Configuration for visual representation and label extraction:
  * `icon?: ReactNode` - Icon to display for this context
  * `color?: string` - Hex color for visual styling
  * `labelField?: string | ((item: unknown) => string)` - How to extract labels from your data
  * `order?: number` - Display order for context badges (lower numbers appear first)
  * `showInChat?: boolean` - Whether to show or hide the state when subscribed to as a context badge in the chat (default = true)

## Basic Usage Example

Here's a simple example with a todo list:

```tsx
import { useCedarState, useSubscribeStateToInputContext } from 'cedar-os';
import { CheckCircle } from 'lucide-react';

function TodoApp() {
	// 1) Register the state in Cedar
	const [todos, setTodos] = useCedarState(
		'todos',
		[
			{ id: 1, text: 'Buy groceries', completed: false },
			{ id: 2, text: 'Walk the dog', completed: true },
		],
		'Todo items'
	);

	// 2) Subscribe that state to input context
	useSubscribeStateToInputContext(
		'todos',
		(todoList) => ({
			todos: todoList, // Key 'todos' will be available to the agent
		}),
		{
			icon: <CheckCircle />,
			color: '#10B981', // Green color
			labelField: 'text', // Use the 'text' field as label for each todo
		}
	);

	return (
		<div>
			<TodoList todos={todos} onToggle={setTodos} />
			<ChatInput /> {/* Agent can now see todos in context */}
		</div>
	);
}
```

## Complex State Example

Here's a more advanced example from the Product Roadmap demo:

```tsx
import { useRegisterState, useSubscribeStateToInputContext } from 'cedar-os';
import { Box } from 'lucide-react';
import { Node } from 'reactflow';

interface FeatureNodeData {
	title: string;
	status: 'planned' | 'in-progress' | 'completed';
	priority: 'low' | 'medium' | 'high';
	description?: string;
}

function SelectedNodesPanel() {
	const [selected, setSelected] = useState<Node<FeatureNodeData>[]>([]);

	// Register the react-flow selection array in Cedar
	useRegisterState({
		key: 'selectedNodes',
		value: selected,
		description: 'Currently selected nodes in the canvas',
	});

	// Subscribe selected nodes to input context
	useSubscribeStateToInputContext(
		'selectedNodes',
		(nodes: Node<FeatureNodeData>[]) => ({
			selectedNodes: nodes.map((node) => ({
				id: node.id,
				title: node.data.title,
				status: node.data.status,
				priority: node.data.priority,
				description: node.data.description,
			})),
		}),
		{
			icon: <Box />,
			color: '#8B5CF6', // Purple color for selected nodes
			labelField: 'title', // Use title field for labels
		}
	);

	// Update selection when user selects nodes
	useOnSelectionChange({
		onChange: ({ nodes }) => setSelected(nodes),
	});

	return (
		<div>
			<h4>Selected Nodes</h4>
			{selected.map((node) => (
				<div key={node.id}>{node.data.title}</div>
			))}
		</div>
	);
}
```

## Using the labelField Option

The `labelField` option allows you to specify how labels should be extracted from your data. This is especially useful when your data has custom field names or when you need custom label logic.

### labelField as a String

Specify which field to use as the label:

```tsx
const [users, setUsers] = useState([
	{ userId: 'u1', fullName: 'John Doe', email: 'john@example.com' },
	{ userId: 'u2', fullName: 'Jane Smith', email: 'jane@example.com' },
]);

useSubscribeStateToInputContext(
	users,
	(userList) => ({ activeUsers: userList }),
	{
		labelField: 'fullName', // Will use fullName as the label
		icon: <User />,
		color: '#3B82F6',
	}
);
```

### labelField as a Function

Use a function for custom label generation:

```tsx
const [products, setProducts] = useState([
	{ sku: 'P001', name: 'Laptop', price: 999, inStock: true },
	{ sku: 'P002', name: 'Mouse', price: 29, inStock: false },
]);

useSubscribeStateToInputContext(
	products,
	(productList) => ({ inventory: productList }),
	{
		labelField: (product) =>
			`${product.name} (${product.inStock ? 'In Stock' : 'Out of Stock'})`,
		icon: <Package />,
		color: '#10B981',
	}
);
```

### Single Values Support

`useSubscribeInputContext` now supports single values (not just arrays):

```tsx
const [count, setCount] = useState(42);
const [isEnabled, setIsEnabled] = useState(true);
const [userName, setUserName] = useState('Alice');

// Subscribe a number
useSubscribeStateToInputContext(count, (value) => ({ itemCount: value }), {
	icon: <Hash />,
	color: '#F59E0B',
});

// Subscribe a boolean
useSubscribeStateToInputContext(
	isEnabled,
	(value) => ({ featureEnabled: value }),
	{
		icon: <ToggleLeft />,
		color: '#10B981',
	}
);

// Subscribe a string with custom label
useSubscribeStateToInputContext(userName, (value) => ({ currentUser: value }), {
	labelField: (name) => `User: ${name}`,
	icon: <User />,
	color: '#8B5CF6',
});
```

## Controlling Display Order

The `order` property allows you to control the display order of context badges in the UI. This is useful when you have multiple context subscriptions and want to prioritize their visibility.

### How Order Works

* **Lower numbers appear first**: `order: 1` will appear before `order: 10`
* **Default behavior**: Items without an order are treated as having the maximum order value
* **Stable sorting**: Items with the same order maintain their original relative position

### Basic Order Example

```tsx
function PrioritizedContext() {
	const [criticalAlerts, setCriticalAlerts] = useState([]);
	const [normalTasks, setNormalTasks] = useState([]);
	const [archivedItems, setArchivedItems] = useState([]);

	// Critical alerts appear first (order: 1)
	useSubscribeStateToInputContext(
		criticalAlerts,
		(alerts) => ({ criticalAlerts: alerts }),
		{
			icon: <AlertCircle />,
			color: '#EF4444',
			order: 1, // Highest priority - appears first
		}
	);

	// Normal tasks appear second (order: 10)
	useSubscribeStateToInputContext(
		normalTasks,
		(tasks) => ({ activeTasks: tasks }),
		{
			icon: <CheckCircle />,
			color: '#3B82F6',
			order: 10, // Medium priority
		}
	);

	// Archived items appear last (order: 100)
	useSubscribeStateToInputContext(
		archivedItems,
		(items) => ({ archivedItems: items }),
		{
			icon: <Archive />,
			color: '#6B7280',
			order: 100, // Low priority - appears last
		}
	);

	return <ChatInput />;
}
```

### Complex Order Example with Mention Providers

When combining `useSubscribeInputContext` with mention providers, you can create a well-organized context display:

```tsx
import { useStateBasedMentionProvider } from 'cedar-os';

function OrganizedWorkspace() {
	const [selectedNodes, setSelectedNodes] = useState([]);
	const [user, setUser] = useState(null);

	// User context appears first (order: 1)
	useSubscribeStateToInputContext(
		user,
		(userData) => ({ currentUser: userData }),
		{
			icon: <User />,
			color: '#8B5CF6',
			labelField: 'name',
			order: 1, // User info always visible first
		}
	);

	// Selected items appear second (order: 5)
	useSubscribeStateToInputContext(
		selectedNodes,
		(nodes) => ({ selectedNodes: nodes }),
		{
			icon: <Box />,
			color: '#F59E0B',
			labelField: 'title',
			order: 5, // Selection context after user
		}
	);

	// Mention provider for all nodes (order: 10)
	useStateBasedMentionProvider({
		stateKey: 'nodes',
		trigger: '@',
		labelField: 'title',
		description: 'All nodes',
		icon: <Box />,
		color: '#3B82F6',
		order: 10, // Available nodes after selections
	});

	// Mention provider for connections (order: 20)
	useStateBasedMentionProvider({
		stateKey: 'edges',
		trigger: '@',
		labelField: (edge) => `${edge.source} â†’ ${edge.target}`,
		description: 'Connections',
		icon: <ArrowRight />,
		color: '#10B981',
		order: 20, // Connections appear last
	});

	return <ChatInput />;
}
```

### Order Best Practices

1. **Use consistent spacing**: Leave gaps between order values (1, 10, 20) to allow for future insertions
2. **Group related contexts**: Give similar contexts adjacent order values
3. **Prioritize by importance**: Most relevant context should have lower order values
4. **Document your ordering**: Comment why certain items have specific orders

```tsx
// Order schema for our app:
// 1-9: User and session data (critical context)
// 10-19: Current selections and active state
// 20-49: General application state
// 50-99: Historical or computed data
// 100+: Low priority or debug information

useSubscribeStateToInputContext('sessionData', mapper, { order: 1 }); // Critical
useSubscribeStateToInputContext('selectedItems', mapper, { order: 10 }); // Active
useSubscribeStateToInputContext('appState', mapper, { order: 20 }); // General
useSubscribeStateToInputContext('history', mapper, { order: 50 }); // Historical
useSubscribeStateToInputContext('debugInfo', mapper, { order: 100 }); // Debug
```

### Default Label Extraction

When no `labelField` is specified, the function looks for labels in this order:

1. `title` field
2. `label` field
3. `name` field
4. `id` field
5. String representation of the value

When using `useSubscribeInputContext`, entries are automatically marked with `source: 'subscription'`.

## Output Behavior and Structure

### What Gets Sent to the Agent

When the agent receives context from `useSubscribeStateToInputContext`, it gets a simplified structure containing only the essential data:

```json
{
	"contextKey": {
		"source": "subscription",
		"data": {
			/* your actual data */
		}
	}
}
```

<Info>
  The agent only receives the `source` and `data` fields. Visual metadata like
  `icon`, `color`, and `label` are used only for UI display and are not sent to
  the agent.
</Info>

### Array Behavior

The output structure depends on how you pass data to `useSubscribeStateToInputContext`:

<Tabs>
  <Tab title="Single Value â†’ Single Entry">
    When your `mapFn` returns a single non-array value, it's stored as a single context entry:

    ```tsx
    // Input: Single object
    useSubscribeStateToInputContext('user', (userData) => ({
      currentUser: userData, // Single object
    }));

    // Agent receives:
    {
      "currentUser": {
        "source": "subscription",
        "data": { "id": "123", "name": "John Doe" }
      }
    }
    ```
  </Tab>

  <Tab title="Array â†’ Array of Entries">
    When your `mapFn` returns an array, it's preserved as an array of context entries:

    ```tsx
    // Input: Array
    useSubscribeStateToInputContext('todos', (todoList) => ({
      todos: todoList, // Array of todos
    }));

    // Agent receives:
    {
      "todos": [
        { "source": "subscription", "data": { "id": 1, "text": "Buy groceries" }},
        { "source": "subscription", "data": { "id": 2, "text": "Walk dog" }}
      ]
    }
    ```
  </Tab>

  <Tab title="Single-Item Array â†’ Array">
    Even single-item arrays are preserved as arrays:

    ```tsx
    // Input: Array with one item
    useSubscribeStateToInputContext('selected', (selection) => ({
      selectedItems: [selection[0]], // Single-item array
    }));

    // Agent receives:
    {
      "selectedItems": [
        { "source": "subscription", "data": { "id": "item1", "title": "Selected Item" }}
      ]
    }
    ```
  </Tab>
</Tabs>

### Practical Examples

Here are real-world examples showing the input and output:

<CodeGroup>
  ```tsx React Component
  // Example 1: User profile (single value)
  const [user] = useState({ id: '123', name: 'Alice', role: 'admin' });

  useSubscribeStateToInputContext('user', (userData) => ({
  currentUser: userData, // Single object
  }), { labelField: 'name' });

  ```

  ```json Agent Context
  {
    "currentUser": {
      "source": "subscription",
      "data": {
        "id": "123",
        "name": "Alice",
        "role": "admin"
      }
    }
  }
  ```
</CodeGroup>

<CodeGroup>
  ```tsx React Component  
  // Example 2: Shopping cart (array)
  const [cart] = useState([
    { id: 'p1', name: 'Laptop', price: 999 },
    { id: 'p2', name: 'Mouse', price: 29 }
  ]);

  useSubscribeStateToInputContext('cart', (items) => ({
  cartItems: items, // Array
  }), { labelField: 'name' });

  ```

  ```json Agent Context
  {
    "cartItems": [
      {
        "source": "subscription",
        "data": { "id": "p1", "name": "Laptop", "price": 999 }
      },
      {
        "source": "subscription",
        "data": { "id": "p2", "name": "Mouse", "price": 29 }
      }
    ]
  }
  ```
</CodeGroup>

<CodeGroup>
  ```tsx React Component
  // Example 3: Single selected item (preserved as array)
  const [selected] = useState([
    { id: 'node1', title: 'Important Feature', status: 'planned' }
  ]);

  useSubscribeStateToInputContext('selection', (nodes) => ({
  selectedNodes: nodes, // Single-item array
  }), { labelField: 'title' });

  ```

  ```json Agent Context
  {
    "selectedNodes": [
      {
        "source": "subscription",
        "data": {
          "id": "node1",
          "title": "Important Feature",
          "status": "planned"
        }
      }
    ]
  }
  ```
</CodeGroup>

<Tip>
  **Why preserve array structure?** This allows the agent to understand whether
  you're working with a single item or a collection, even when that collection
  has only one item. This distinction can be important for generating
  appropriate responses.
</Tip>

### Multiple Context Keys

When you return multiple keys from your `mapFn`, each follows the same behavior rules:

```tsx
useSubscribeStateToInputContext('appState', (state) => ({
	currentUser: state.user, // Single object â†’ single entry
	activeTasks: state.tasks, // Array â†’ array of entries
	selectedItems: [state.selected], // Single-item array â†’ array
	preferences: state.prefs, // Single object â†’ single entry
}));

// Agent receives all four keys with appropriate structures
```

## Multiple State Subscriptions

You can subscribe multiple pieces of state:

```tsx
function MyApp() {
	const [user, setUser] = useState(null);
	const [preferences, setPreferences] = useState({});
	const [currentPage, setCurrentPage] = useState('/dashboard');

	// Subscribe user data
	useSubscribeStateToInputContext(
		user,
		(userData) => ({
			currentUser: userData
				? {
						id: userData.id,
						name: userData.name,
						role: userData.role,
				  }
				: null,
		}),
		{
			icon: <User />,
			color: '#3B82F6',
		}
	);

	// Subscribe preferences
	useSubscribeStateToInputContext(
		preferences,
		(prefs) => ({
			userPreferences: prefs,
		}),
		{
			icon: <Settings />,
			color: '#6B7280',
		}
	);

	// Subscribe navigation state
	useSubscribeStateToInputContext(
		currentPage,
		(page) => ({
			currentPage: {
				path: page,
				timestamp: new Date().toISOString(),
			},
		}),
		{
			icon: <Navigation />,
			color: '#F59E0B',
		}
	);

	return <YourAppContent />;
}
```

## Best Practices

### 1. Transform Sensitive Data

Don't expose sensitive information to the agent:

```tsx
useSubscribeStateToInputContext('userProfile', (profile) => ({
	user: {
		name: profile.name,
		tier: profile.subscriptionTier,
		preferences: profile.preferences,
		// Don't include: email, password, tokens, etc.
	},
}));
```

### 2. Use Meaningful Keys

Choose descriptive keys for your context:

```tsx
useSubscribeStateToInputContext('shoppingCart', (cart) => ({
	shoppingCart: cart.items, // Clear and descriptive
	cartTotal: cart.total,
	cartItemCount: cart.items.length,
}));
```

### 3. Optimize Large Data Sets

For large data sets, consider filtering or summarizing:

```tsx
useSubscribeStateToInputContext(allTransactions, (transactions) => ({
	recentTransactions: transactions
		.slice(0, 10) // Only last 10 transactions
		.map((t) => ({
			id: t.id,
			amount: t.amount,
			date: t.date,
			// Exclude detailed metadata
		})),
	transactionSummary: {
		total: transactions.length,
		totalAmount: transactions.reduce((sum, t) => sum + t.amount, 0),
	},
}));
```

## Visual Customization

The `options` parameter allows you to customize how the context appears in the UI:

```tsx
import { Star, AlertCircle, CheckCircle } from 'lucide-react';

// Different colors and icons for different priorities
useSubscribeStateToInputContext(
	highPriorityTasks,
	(tasks) => ({ highPriorityTasks: tasks }),
	{
		icon: <AlertCircle />,
		color: '#EF4444', // Red for high priority
	}
);

useSubscribeStateToInputContext(
	completedTasks,
	(tasks) => ({ completedTasks: tasks }),
	{
		icon: <CheckCircle />,
		color: '#10B981', // Green for completed
	}
);

useSubscribeStateToInputContext(
	starredItems,
	(items) => ({ starredItems: items }),
	{
		icon: <Star />,
		color: '#F59E0B', // Yellow for starred
	}
);
```

## Integration with Chat Input

The subscribed context automatically becomes available to your AI agent when using Cedar's chat components:

```tsx
import { ChatInput } from 'cedar-os-components';

function MyChat() {
	// Your useSubscribeInputContext calls here...

	return (
		<div>
			{/* Context is automatically included when user sends messages */}
			<ChatInput placeholder='Ask me about your todos, selected nodes, or anything else...' />
		</div>
	);
}
```

The agent will receive the context in a structured format and can reference it when generating responses, making the conversation more contextual and relevant to your application's current state.


# Blog
Source: https://docs.cedarcopilot.com/blog/index



We can yap about AI interfaces and UX for hours.

Therefore, we have some thoughts.

<CardGroup cols={2}>
  <Card title="How we became obsessed with AI interfaces" icon="pen" href="/blog/on-advancing-ai-interfaces">
    On advancing AI interfaces: why chat is just the beginning, and what comes
    next for truly native AI UX.
  </Card>
</CardGroup>


# Changelog
Source: https://docs.cedarcopilot.com/changelog

See what we're up to :-D

<Update label="August 2025" description="v0.1.0">
  Cedar-OS launches its first public release! ðŸŽ‰
</Update>


# Chat Components (Advanced)
Source: https://docs.cedarcopilot.com/chat/chat-components

Deep dive into individual chat components for advanced customization

Cedar provides you with fully working chat out of the box, so this documentation is only needed if you want to customize or build your own chat interface. We break down every component so you can understand how they work together and modify them as needed.

## Chat Input Components

The chat input system consists of several key components that handle user input, mentions, and context management.

<img src="https://vrhlhwfhghqbpdpfnpdq.supabase.co/storage/v1/object/public/logos/caption.gif" alt="Bottom Center Chat Demo" />

### ContextBadgeRow

The `ContextBadgeRow` component displays selected context items (like mentions, state, or custom context) as badges above the input field. Users can click these badges to remove them from the context.

```tsx
import { ContextBadgeRow } from '@/chatInput/ContextBadgeRow';

<ContextBadgeRow editor={editor} />;
```

**Key Features:**

* Displays context entries as removable badges
* Shows icons and colors from mention providers
* Handles removal of mentions from both context and editor
* Supports custom rendering through mention providers
* Automatically renders badges for all registered mention types

**Props:**

* `editor` - The Tiptap editor instance for mention removal

### Editor Section (Tiptap Integration)

Cedar uses [Tiptap](https://tiptap.dev/) as the rich text editor for chat input. This provides powerful text editing capabilities with support for mentions, formatting, and extensibility.

```tsx
import { useCedarEditor } from 'cedar-os';
import { EditorContent } from '@tiptap/react';

const { editor, isEditorEmpty, handleSubmit } = useCedarEditor({
	onSubmit,
	onFocus: handleFocus,
	onBlur: handleBlur,
});

<EditorContent
	editor={editor}
	className='prose prose-sm max-w-none focus:outline-none'
/>;
```

**Key Features:**

* Rich text editing with markdown support
* Mention system integration (@, #, / triggers)
* Keyboard shortcuts and navigation
* Multi-line input support
* Extensible through Tiptap extensions

**Editor Extensions Included:**

* Document, Paragraph, Text (core)
* HardBreak for line breaks
* Mention extension for @mentions
* History for undo/redo
* Placeholder support

### MentionList

The `MentionList` component renders the dropdown menu that appears when users type mention triggers (like @ or #). It displays available mention options with custom rendering support.

```tsx
import MentionList from '@/components/chatInput/MentionList';

<MentionList items={mentionItems} command={selectMention} />;
```

**Key Features:**

* Keyboard navigation (arrow keys, enter)
* Custom rendering through mention providers
* Color theming based on mention metadata
* Hover and selection states
* Provider-specific item rendering

**Props:**

* `items` - Array of `MentionItem` objects to display
* `command` - Function called when an item is selected

For more details on setting up mentions, see the [Mentions documentation](/agent-input-context/mentions).

## Message Components

Message components handle the display and rendering of chat messages in different formats and layouts.

### ChatRenderer

The `ChatRenderer` is the core component responsible for rendering individual messages based on their type. It supports both built-in message types and custom message renderers.

```tsx
import { ChatRenderer } from '@/chatMessages/ChatRenderer';

<ChatRenderer message={message} />;
```

**Built-in Message Types:**

* `text` - Standard text messages with markdown support
* `dialogue_options` - Interactive option buttons
* `multiple_choice` - Choice buttons with keyboard shortcuts
* `todolist` - Interactive todo list items
* `ticker` - Horizontal scrolling content cards
* `slider` - Slider input for numeric values

**Key Features:**

* Automatic message type detection
* Custom renderer registration support
* Markdown rendering with code block support
* Consistent styling across message types
* Dark/light mode support

**Custom Renderers:**

```tsx
// Register a custom message renderer
store.registerMessageRenderer({
	type: 'my-custom-type',
	renderer: ({ message }) => <div>{message.content}</div>,
});
```

### ChatBubbles

The `ChatBubbles` component manages the scrollable message container with animations and auto-scrolling behavior.

```tsx
import { ChatBubbles } from '@/chatMessages/ChatBubbles';

<ChatBubbles maxHeight='400px' className='custom-chat-container' />;
```

**Key Features:**

* Auto-scroll to latest messages
* Smooth animations for new messages
* Typing indicator support
* Consecutive message grouping
* Custom height and styling options
* Optimized scrolling performance

**Props:**

* `maxHeight` - Maximum height (e.g., "300px", "60vh")
* `className` - Additional CSS classes

### CaptionMessages

The `CaptionMessages` component is specialized for caption-style chat interfaces, showing only the latest message with enhanced typography and interactions.

```tsx
import CaptionMessages from '@/chatMessages/CaptionMessages';

<CaptionMessages showThinking={true} />;
```

**Key Features:**

* Shows only the latest relevant message
* Enhanced typography with typewriter effects
* Shimmer text for thinking states
* Interactive elements (buttons, sliders)
* Keyboard shortcut integration
* Optimized for overlay/caption use cases

**Props:**

* `showThinking` - Whether to show user messages and thinking states

**Message Type Handling:**

* `text` - Typewriter animation with "Cedar:" prefix
* `dialogue_options` - 3D button grid with hover effects
* `ticker` - Horizontal scrolling with "Next Step" button
* `multiple_choice` - Inline choice buttons with shortcuts
* `slider` - Interactive 3D slider component

## Container Components

Container components provide the structural layout and positioning for different chat interface styles.

### FloatingContainer

The `FloatingContainer` provides a floating, resizable chat window that can be positioned at different screen locations.

```tsx
import { FloatingContainer } from '@/structural/FloatingContainer';

<FloatingContainer
	isActive={isOpen}
	position='bottom-right'
	dimensions={{
		width: 400,
		height: 600,
		minWidth: 300,
		minHeight: 400,
	}}
	resizable={true}
	onResize={(width, height) => console.log('Resized:', width, height)}>
	{/* Chat content */}
</FloatingContainer>;
```

**Key Features:**

* Multiple positioning options (bottom-left, bottom-right, bottom-center)
* Resizable with drag handles (corner positions only)
* Smooth animations with spring physics
* Responsive design with mobile adaptations
* Constraint-based resizing with min/max limits

**Props:**

* `isActive` - Whether the container is visible
* `position` - Screen position ('bottom-left' | 'bottom-right' | 'bottom-center')
* `dimensions` - Size configuration object
* `resizable` - Enable/disable resize functionality
* `onResize` - Callback for size changes
* `className` - Additional CSS classes

**Dimensions Object:**

```tsx
interface FloatingDimensions {
	width?: number | string;
	height?: number | string;
	minWidth?: number | string;
	minHeight?: number | string;
	maxWidth?: number | string;
	maxHeight?: number | string;
}
```

### SidePanelContainer

The `SidePanelContainer` creates a side panel that pushes the main content to make room for the chat interface.

```tsx
import { SidePanelContainer } from '@/structural/SidePanelContainer';

<SidePanelContainer
	isActive={isOpen}
	side='right'
	dimensions={{
		width: 600,
		minWidth: 300,
		maxWidth: 800,
	}}
	resizable={true}
	topOffset={64} // Account for navbar
	onResize={(width) => console.log('Panel width:', width)}
	panelContent={<ChatInterface />}>
	{/* Main page content */}
	<div>Your app content here</div>
</SidePanelContainer>;
```

**Key Features:**

* Left or right side positioning
* Content area automatically adjusts padding
* Resizable with drag handle
* Mobile-responsive (full screen on mobile)
* Top offset support for fixed headers
* Smooth slide animations

**Props:**

* `isActive` - Whether the panel is open
* `side` - Panel position ('left' | 'right')
* `panelContent` - React node to render in the panel
* `dimensions` - Width configuration object
* `resizable` - Enable/disable resize functionality
* `topOffset` - Top spacing in pixels (for fixed headers)
* `onResize` - Callback for width changes
* `className` - Additional CSS classes for main content
* `panelClassName` - Additional CSS classes for panel

**Dimensions Object:**

```tsx
interface SidePanelDimensions {
	width?: number;
	minWidth?: number;
	maxWidth?: number;
}
```

## Component Integration

These components work together to create the complete chat experience:

1. **Input Flow**: `ContextBadgeRow` â†’ Tiptap Editor â†’ `MentionList`
2. **Message Flow**: `ChatRenderer` â†’ `ChatBubbles` or `CaptionMessages`
3. **Layout Flow**: `FloatingContainer` or `SidePanelContainer` wraps the entire chat

Each component is designed to be used independently or as part of the complete system, giving you flexibility in how you build your chat interface.

## Next Steps

* Explore [Custom Message Rendering](/chat/custom-message-rendering) to create your own message types
* Learn about [Mentions](/agent-input-context/mentions) to add contextual references
* Check out [Streaming](/chat/streaming) for real-time message updates


# Chat Overview
Source: https://docs.cedarcopilot.com/chat/chat-overview

Get started with Cedar chat components and understand how they work

With one component, you can download a fully working chat. The chat automatically handles streaming, custom message rendering, input, [mentions](/agent-input-context/mentions) and more. You also get all of the individual components, so you can customise styling, rendering, and functionality.

## Quick Start

To get started, choose one of the 3 types of chat. See [cedarcopilot.com/examples/cedar-playground](https://cedarcopilot.com/examples/cedar-playground) to see them in action.

### Chat Types

**Caption Chat**
A caption-style chat interface that appears at the bottom center of the screen, perfect for overlay-style interactions. Great for AI assistants that provide contextual help without taking up dedicated screen space.

We realised that in a conversation, you don't need to see an entire history of the chat all the time, just the latest message (of course, we give the user the option to see past texts). This gives a much more central and embedded experience for agentic interactions

<img src="https://vrhlhwfhghqbpdpfnpdq.supabase.co/storage/v1/object/public/logos/caption.gif" alt="Bottom Center Chat Demo" />

**Floating Chat**
A floating chat window that can be positioned on the left or right side of the screen with expand/collapse functionality. Perfect for assistance that doesn't interfere with the main application.

<img src="https://vrhlhwfhghqbpdpfnpdq.supabase.co/storage/v1/object/public/logos/floating.gif" alt="Floating Chat Demo" />

**Side Panel Chat**\
A side panel chat that pushes your main content to make room for the chat interface. This is if you want the chat to not overlap with any elements, and always have its own dedicated spot.

<img src="https://vrhlhwfhghqbpdpfnpdq.supabase.co/storage/v1/object/public/logos/sidepanel.gif" alt="Side Panel Chat Demo" />

<CodeGroup>
  ```tsx Floating Chat
  import { FloatingCedarChat } from '@/chatComponents/FloatingCedarChat';

  function App() {
  	return (
  		<div>
  			{/* Your main content */}
  			<FloatingCedarChat
  				side='right'
  				title='Assistant'
  				collapsedLabel='How can I help you today?'
  				dimensions={{
  					width: 400,
  					height: 600,
  					minWidth: 350,
  					minHeight: 400,
  				}}
  				resizable={true}
  			/>
  		</div>
  	);
  }

  // Props interface
  interface FloatingCedarChatProps {
  	side?: 'left' | 'right';
  	title?: string;
  	collapsedLabel?: string;
  	companyLogo?: React.ReactNode;
  	dimensions?: {
  		width?: number;
  		height?: number;
  		minWidth?: number;
  		minHeight?: number;
  		maxWidth?: number;
  		maxHeight?: number;
  	};
  	resizable?: boolean;
  }
  ```

  ```tsx Side Panel Chat
  import { SidePanelCedarChat } from '@/chatComponents/SidePanelCedarChat';

  function App() {
  	return (
  		<SidePanelCedarChat
  			side='right'
  			title='Chat Assistant'
  			dimensions={{
  				width: 600,
  				minWidth: 300,
  				maxWidth: 800,
  			}}
  			resizable={true}
  			topOffset={64} // Offset for navbar height (optional)
  			className='' // Additional styling (optional)
  		>
  			{/* Your main page content goes here */}
  			<div className='p-8'>
  				<h1>Your App Content</h1>
  				<p>This content will be pushed to the side when chat opens.</p>
  			</div>
  		</SidePanelCedarChat>
  	);
  }

  // Props interface
  interface SidePanelCedarChatProps {
  	children?: React.ReactNode; // Page content to wrap
  	side?: 'left' | 'right';
  	title?: string;
  	collapsedLabel?: string;
  	showCollapsedButton?: boolean; // Control whether to show the collapsed button
  	companyLogo?: React.ReactNode;
  	dimensions?: {
  		width?: number;
  		minWidth?: number;
  		maxWidth?: number;
  	};
  	resizable?: boolean;
  	className?: string; // Additional CSS classes for positioning
  	topOffset?: number; // Top offset in pixels (e.g., for navbar height)
  }
  ```

  ```tsx Bottom Center Chat
  import { CedarCaptionChat } from '@/chatComponents/CedarCaptionChat';

  function App() {
  	return (
  		<div>
  			{/* Your main content */}
  			<CedarCaptionChat
  				dimensions={{
  					width: 600,
  					maxWidth: 800,
  				}}
  				showThinking={true}
  			/>
  		</div>
  	);
  }

  // Props interface
  interface CedarCaptionChatProps {
  	dimensions?: {
  		width?: number;
  		maxWidth?: number;
  	};
  	className?: string;
  	showThinking?: boolean; // Whether to show "Thinking..." state and user messages
  }
  ```
</CodeGroup>

## Understanding & Customising Chat

Chat works through 2 main modules working together: **AgentInputContext** and **MessagesSlice**.

### AgentInputContext

[**AgentInputContext**](/agent-input-context/agent-input-context) manages everything that we pass into the agent. This includes not only the user message, but also:

* **State** that the agent is subscribed to ([learn more about state access](/chat/subscribing-state))
* **User @mentions** of specific items in your application ([learn more about mentions](/chat/mentions))
* **Conversation history** and contextual information
* **Custom context** you provide programmatically, such as user role

This ensures your AI agent has full context about your application's current state and what the user is specifically referring to.

### MessagesSlice

**MessagesSlice** takes care of the saving and rendering of messages. It handles:

* **Message storage** and conversation history
* **Message rendering** with support for different message types
* **Streaming responses** from AI providers
* **Custom message components** for rich interactions

### Additional Customization

* **[Streaming](/chat/streaming)** - Enable real-time response streaming
* **[Configuring the Cedar Editor](/chat/configuring-cedar-editor)** - Customize the chat input experience
* **[Custom Message Rendering](/chat/custom-message-rendering)** - Create custom message types and interactions
* **[Understanding Chat Components](/chat/chat-components)** - Deep dive into individual chat components for advanced customization

## Next Steps

1. **Try it out**: Visit the [Cedar Playground](https://cedarcopilot.com/examples/cedar-playground) to see all chat types in action
2. **Choose your style**: Pick the chat type that best fits your application
3. **Add context**: Set up state access and mentions to make your agent context-aware
4. **Customize**: Tailor the appearance and behavior to match your application's needs


# Configuring the Cedar Editor
Source: https://docs.cedarcopilot.com/chat/configuring-cedar-editor

Customize the chat input editor behavior and features

The Cedar editor is the rich text input component that powers chat interactions. It supports mentions, keyboard shortcuts, auto-completion, and extensive customization options.

## Basic Configuration

Configure the editor through the `useCedarEditor` hook or ChatInput props:

```tsx
import { ChatInput } from 'cedar-os-components/chatInput';

function CustomChat() {
	return <ChatInput className='custom-chat-input' />;
}
```

## Advanced Editor Configuration

Use the `useCedarEditor` hook for fine-grained control:

```tsx
import { useCedarEditor } from 'cedar-os';
import { EditorContent } from '@tiptap/react';

function AdvancedChat() {
	const { editor, isEditorEmpty, handleSubmit } = useCedarEditor({
		placeholder: 'Ask me anything...',
		onFocus: () => console.log('Editor focused'),
		onBlur: () => console.log('Editor blurred'),
	});

	return (
		<div>
			<EditorContent editor={editor} />
			<button onClick={() => editor?.commands.focus()}>Focus Editor</button>
			<button onClick={handleSubmit} disabled={isEditorEmpty}>
				Submit
			</button>
		</div>
	);
}
```

## Keyboard Shortcuts

Cedar editor comes with built-in keyboard shortcuts:

| Shortcut        | Action            |
| --------------- | ----------------- |
| `Enter`         | Submit message    |
| `Shift + Enter` | New line          |
| `@`             | Trigger mentions  |
| `Tab`           | Focus editor      |
| `M`             | Toggle microphone |

### Custom Shortcuts

The editor uses TipTap under the hood, so you can extend it with custom keyboard shortcuts by configuring the editor extensions directly.

## Styling and Themes

Customize the editor appearance:

```tsx
<ChatInput className='custom-chat-input' />
```

You can customize the appearance using CSS classes. The component uses Tailwind CSS classes internally, so you can override them:

```css
.custom-chat-input {
	background: #f8f9fa;
	border-radius: 12px;
	padding: 16px;
	min-height: 120px;
}

.custom-chat-input .ProseMirror {
	font-family: 'Inter', sans-serif;
	font-size: 14px;
	line-height: 1.5;
}
```

## Editor Events

Handle various editor events:

```tsx
<ChatInput
	handleFocus={() => console.log('Editor focused')}
	handleBlur={() => console.log('Editor blurred')}
	className='my-chat-input'
/>
```

## Content Validation

Content validation can be implemented using the `useCedarEditor` hook:

```tsx
import { useCedarEditor } from 'cedar-os';
import { EditorContent } from '@tiptap/react';

function ValidatedChat() {
	const { editor, isEditorEmpty, handleSubmit } = useCedarEditor({
		placeholder: 'Type your message...',
		onFocus: () => console.log('Editor focused'),
		onBlur: () => console.log('Editor blurred'),
	});

	const handleCustomSubmit = () => {
		if (!editor) return;

		const text = editor.getText();

		if (text.length > 1000) {
			console.error('Message too long');
			return;
		}
		if (text.includes('@everyone')) {
			console.error('Mass mentions are not allowed');
			return;
		}

		// Process valid message
		console.log('Valid message:', text);
		handleSubmit();
	};

	return (
		<div>
			<EditorContent editor={editor} />
			<button onClick={handleCustomSubmit} disabled={isEditorEmpty}>
				Submit
			</button>
		</div>
	);
}

<ChatInput />;
```

## Next Steps

* Learn about [custom message rendering](/chat/custom-message-rendering)
* Explore [agent input context](/agent-input-context/agent-input-context)


# Custom Message Rendering
Source: https://docs.cedarcopilot.com/chat/custom-message-rendering

Create custom message components and renderers for the chat interface

Cedar allows you to completely customize how messages are displayed in your chat interface. This is used for use cases like Generative UI, or any custom logic you want for the way that messages are rendered to the user.

This system mirrors the architecture of [Custom Response Processing](/agent-backend-connection/custom-response-processing).

## Base Message Type

All messages in Cedar extend the `BaseMessage` interface from `@messages/types`:

```tsx
interface BaseMessage {
	id: string; // Unique identifier (auto-generated if not provided)
	role: MessageRole; // 'bot' | 'user' | 'assistant'
	content: string; // The text content of the message
	createdAt?: string; // ISO timestamp (auto-generated)
	metadata?: Record<string, unknown>; // Optional key-value pairs
	type: string; // String identifier for renderer matching
}
```

## Requirements for Custom Messages

To use the custom message rendering system, your message objects must have a `type` field. This field determines which renderer will be used to display the message.

```tsx
// Valid message - has required 'type' field
{
  type: 'alert',
  role: 'assistant',
  content: 'This is an alert message',
  level: 'warning'
}

// Invalid - missing 'type' field
{
  role: 'assistant',
  content: 'This message will use default rendering'
}
```

## Message Renderer Interface

Cedar uses a strongly typed `MessageRenderer` interface that ensures type safety throughout the rendering pipeline:

```tsx
export type MessageRenderer<T extends Message = Message> = {
	type: T['type']; // Must match the message type
	render: (message: T) => ReactNode; // Receives narrowly typed message
	namespace?: string; // Optional organization namespace
	validateMessage?: (message: Message) => message is T; // Receives broadly typed Message for validation
};
```

**Key typing features:**

* The `render` function receives your **narrowly typed custom message** (e.g., `AlertMessage`)
* The `validateMessage` function receives the **broadly typed `Message`** for runtime validation

## Custom Message Type Definition

Cedar exports a `CustomMessage<T, P>` type that allows you to create type-safe custom messages:

```tsx
import { CustomMessage } from 'cedar-os';

// T = type string, P = additional properties
export type CustomMessage<
	T extends string,
	P extends object = Record<string, never>
> = BaseMessage & { type: T } & P;

// Example usage
type AlertMessage = CustomMessage<
	'alert',
	{
		level: 'info' | 'warning' | 'error';
	}
>;

type TodoListMessage = CustomMessage<
	'todo-list',
	{
		items: Array<{ id: string; text: string; completed: boolean }>;
		onToggle?: (id: string) => void;
	}
>;
```

## Message Renderer Factory Function

Cedar exports a `createMessageRenderer` factory function to create type-safe renderers:

```tsx
import { createMessageRenderer } from 'cedar-os';

// Create a renderer with full type safety
const AlertRenderer = createMessageRenderer<AlertMessage>({
	type: 'alert',
	namespace: 'my-app',
	render: (message) => {
		// message is narrowly typed as AlertMessage
		return <div className={`alert-${message.level}`}>{message.content}</div>;
	},
	validateMessage: (msg): msg is AlertMessage => {
		// msg is broadly typed as Message for validation
		return msg.type === 'alert' && 'level' in msg;
	},
});
```

## How Message Rendering Works Internally

The chat system uses the following process to render messages:

1. **Message Reception**: When a message is added to the chat, the system examines its `type` field
2. **Renderer Lookup**: The system searches for a registered renderer that matches the message type
3. **Validation**: If a renderer is found and has a validation function, it checks if the message structure is valid
4. **Rendering**: If validation passes (or no validation exists), the renderer's `render` function is called
5. **Fallback**: If no matching renderer is found or validation fails, the default text renderer is used

## Full Implementation Examples

Here's an example of creating a custom message renderer for an AlertMessage.

```tsx
import { createMessageRenderer, CustomMessage } from 'cedar-os';

// Define custom message type
type AlertMessage = CustomMessage<'alert', { level: string }>;

// Create the renderer
const AlertMessageRenderer = createMessageRenderer<AlertMessage>({
	type: 'alert',
	namespace: 'product-roadmap',
	render: (message) => {
		const levelColors = {
			info: 'bg-blue-100 text-blue-800',
			warning: 'bg-yellow-100 text-yellow-800',
			error: 'bg-red-100 text-red-800',
		};

		return (
			<div
				className={`p-3 rounded-lg ${
					levelColors[message.level] || levelColors.info
				}`}>
				<div className='font-semibold'>Alert</div>
				<div>{message.content}</div>
			</div>
		);
	},
	validateMessage: (msg): msg is AlertMessage => {
		return (
			msg.type === 'alert' && 'level' in msg && typeof msg.level === 'string'
		);
	},
});

// Register with CedarCopilot
<CedarCopilot
	messageRenderers={[AlertMessageRenderer]}
	// ... other props
>
	{children}
</CedarCopilot>;
```

## Default Message Types and Renderers

Cedar automatically handles these message types with default behavior. Each type has a corresponding default renderer:

### `"message"` Type

* **Behavior**: Standard text messages with role-based styling
* **Properties**: `content: string`, `role: 'user' | 'assistant' | 'bot'`
* **Renderer**: Built-in text message renderer with role-based styling
* **Warning**: Overriding this type will disable default text message rendering

### `"setState"` Type

* **Behavior**: Executes state actions and displays completion status
* **Properties**: `stateKey: string`, `setterKey: string`, `args?: unknown[]`
* **Default Renderer**: `SetStateRenderer` shows setState completion with shimmer effects

**SetState Factory Functions**: Cedar provides special factory functions for setState messages:

```tsx
import { createSetStateMessageRenderer, SetStateMessageFor } from 'cedar-os';

// Specific setState message type using helper
type UpdateCounterSetState = SetStateMessageFor<
	'counter', // StateKey
	'increment', // SetterKey
	[number] // Args
>;

// Create custom setState renderer with filtering
const CounterSetStateRenderer =
	createSetStateMessageRenderer<UpdateCounterSetState>({
		namespace: 'counter',
		setterKey: 'increment', // Only handle increment actions
		render: (message) => (
			<div className='setState-message'>
				âœ… Incremented counter by {message.args?.[0] || 1}
			</div>
		),
	});
```

### `"progress_update"` Type

* **Behavior**: Shows progress indicators with shimmer effects
* **Properties**: `content: string`, `metadata.state?: 'in_progress' | 'complete' | 'error'`
* **Default Renderer**: `ProgressUpdateRenderer` with animated shimmer text

### Additional Built-in Renderers

Cedar also includes renderers for streaming events:

#### Mastra Event Renderer

Cedar automatically receives and renders all Mastra streamed events. Any of these can be customized or overridden with your own renderers:

**Supported Mastra Event Types:**

* `'start'` - Agent run started
* `'step-start'` - Agent step started
* `'tool-call'` - Tool being called
* `'tool-result'` - Tool call result
* `'step-finish'` - Agent step completed
* `'tool-output'` - Tool output received
* `'step-result'` - Step result available
* `'step-output'` - Step output received
* `'finish'` - Agent run completed

**Customization**: You can override any specific Mastra event type by creating a custom renderer with the same `type`. For example, to customize just the `'tool-call'` event:

```tsx
const CustomToolCallRenderer = createMessageRenderer<
	CustomMastraMessage<'tool-call'>
>({
	type: 'tool-call',
	render: (
		message // typed
	) => (
		<div className='custom-tool-call'>
			ðŸ”§ Calling tool: {message.payload.toolName}
		</div>
	),
});
```

**âš ï¸ Important**: If you override any of these default types, you lose the built-in behavior. Ensure your custom implementation covers all cases you want to support.

## Recommended File Structure

Cedar encourages organizing custom renderers in dedicated files for easier maintenance and debugging:

```
src/
  cedar-os/
    renderers/
      messageRenderers.tsx    // All custom message renderers
      index.ts               // Export registration function
  components/
    Layout.tsx              // Register renderers with CedarCopilot
```

This structure keeps all Cedar-related logic organized under a `cedar-os` directory, making it easier to maintain, debug, and ensure consistency across your application.


# Message Storage Configuration
Source: https://docs.cedarcopilot.com/chat/message-storage-configuration

Configure how Cedar persists chat messages and manages threads

Cedar provides a flexible storage system for managing chat messages with automatic persistence and **automatic thread management**. By default, Cedar uses **no storage** - no persistence unless you configure a storage adapter.

<Warning>
  **Storage Requirements:** Message persistence requires both `userId` and
  `threadId` to be set. Without these IDs, storage operations are skipped and
  messages remain in memory only.
</Warning>

# Quick Start

Cedar works out of the box with no storage (no persistence). To enable persistence, configure a storage adapter.

# Storage Options

Cedar supports three storage adapters:

1. **Local Storage** (default) - Browser localStorage
2. **No Storage** - Disables persistence
3. **Custom Storage** - Your own implementation

Configure storage by passing the `messageStorage` prop to CedarCopilot:

<CodeGroup>
  ```typescript Local Storage (Default)
  import { CedarCopilot } from 'cedar-os';

  function App() {
  	return (
  		<CedarCopilot
  			// No storage prop needed - uses local storage by default.
  			// Optionally pass in user ID
  			userId='user-123'>
  			<YourChatComponent />
  		</CedarCopilot>
  	);
  }
  ```

  ```typescript Local Storage (Custom Key)
  import { CedarCopilot } from 'cedar-os';

  function App() {
  	return (
  		<CedarCopilot
  			messageStorage={{
  				type: 'local',
  				options: {
  					key: 'my-app', // Optional: defaults to 'cedar'
  				},
  			}}
  			userId='user-123'>
  			<YourChatComponent />
  		</CedarCopilot>
  	);
  }
  ```

  ```typescript No Storage
  import { CedarCopilot } from 'cedar-os';

  function App() {
  	return (
  		<CedarCopilot messageStorage={{ type: 'none' }} userId='user-123'>
  			<YourChatComponent />
  		</CedarCopilot>
  	);
  }
  ```

  ```typescript Custom Storage
  import { CedarCopilot } from 'cedar-os';

  const myCustomAdapter = {
  	async listThreads(userId) {
  		return await myDatabase.getThreads(userId);
  	},
  	async loadMessages(userId, threadId) {
  		return await myDatabase.getMessages(userId, threadId);
  	},
  	async persistMessage(userId, threadId, message) {
  		await myDatabase.appendMessage(userId, threadId, message);
  	},
  };

  function App() {
  	return (
  		<CedarCopilot
  			messageStorage={{
  				type: 'custom',
  				adapter: myCustomAdapter,
  			}}
  			userId='user-123'>
  			<YourChatComponent />
  		</CedarCopilot>
  	);
  }
  ```
</CodeGroup>

# Additional Configuration Requirements by Storage Type

### Local Storage & No Storage

**No additional configuration needed** - these options work out of the box.

### Custom Storage

Implement your own storage solution by providing a custom adapter:

<CodeGroup>
  ```typescript Interface
  interface MessageStorageBaseAdapter {
  	// Required methods
  	loadMessages(userId: string, threadId: string): Promise<Message[]>;
  	persistMessage(
  		userId: string,
  		threadId: string,
  		message: Message
  	): Promise<Message>; // returns the saved message

  	// Optional thread methods
  	listThreads?(userId: string): Promise<MessageThreadMeta[]>;
  	createThread?(
  		userId: string,
  		threadId: string,
  		meta: MessageThreadMeta
  	): Promise<MessageThreadMeta>; // returns new meta
  	updateThread?(
  		userId: string,
  		threadId: string,
  		meta: MessageThreadMeta
  	): Promise<MessageThreadMeta>; // returns updated meta
  	deleteThread?(
  		userId: string,
  		threadId: string
  	): Promise<MessageThreadMeta | undefined>; // returns deleted meta (optional)

  	// Optional message methods
  	updateMessage?(
  		userId: string,
  		threadId: string,
  		message: Message
  	): Promise<Message>; // returns updated message
  	deleteMessage?(
  		userId: string,
  		threadId: string,
  		messageId: string
  	): Promise<Message | undefined>; // returns deleted message (optional)
  }
  ```

  All mutator/creator functions return the object they operate on, making it easy to work with the freshly-persisted data (IDs, timestamps, etc.).

  ```typescript Example Implementation
  import { CedarCopilot } from 'cedar-os';

  // Your custom storage implementation
  const myCustomAdapter = {
  	async listThreads(userId) {
  		return await myDatabase.getThreads(userId);
  	},

  	async loadMessages(userId, threadId) {
  		return await myDatabase.getMessages(userId, threadId);
  	},

  	async persistMessage(userId, threadId, message) {
  		await myDatabase.appendMessage(userId, threadId, message);
  	},
  };

  function App() {
  	return (
  		<CedarCopilot
  			messageStorage={{
  				type: 'custom',
  				adapter: myCustomAdapter,
  			}}
  			userId='user-123' // User ID passed in initial configuration
  		>
  			<YourChatComponent />
  		</CedarCopilot>
  	);
  }
  ```
</CodeGroup>

## How Default Message Storage Works

Cedar preconfigures several storage methods that orchestrate your adapter's functionality. Understanding these helps you work with Cedar's storage system effectively.

### Preconfigured Storage Methods

<Note>
  Cedar provides these methods out of the box. These methods are automatically
  called by Cedar at appropriate times - you don't need to call them directly.
  To customize their behavior, you can override them in your implementation.
</Note>

#### 1. `initializeChat({threadId?: string, userId?: string})`

This method orchestrates the initial loading of threads and messages. It's automatically called:

* When the message storage adapter is first set
* When userId or threadId changes in Cedar state

Here's what it does with your adapter:

```typescript
// Cedar's initializeChat flow:
1. Get userId (from params or Cedar state)
2. Get threadId (from params or Cedar state)
3. Call adapter.listThreads(userId) to load user's threads
4. If no thread is selected and threads exist:
   - Automatically select the first thread
5. If **no threads exist** and `adapter.createThread` is available:
   - A brand-new thread is created (ID `thread-{timestamp}-{rand}`)
   - The new thread metadata is persisted via `adapter.createThread`
   - Cedar sets this new ID in state
6. Use the provided threadId OR the auto-selected / newly-created threadId
7. Clear any existing messages in the UI
8. If both userId and threadId exist:
   - Call adapter.loadMessages(userId, threadId)
   - Display the loaded messages
```

#### 2. `persistMessageStorageMessage(message)`

This method handles message persistence with intelligent thread management:

```typescript
// Cedar's persistMessageStorageMessage flow:
1. Get userId from Cedar state (skip entire process if no userId)
2. Get threadId from Cedar state
3. Call adapter.persistMessage(userId, threadId, message)
4. If adapter.updateThread is available:
   - Update thread metadata (preserving original title if exists)
   - Set updatedAt to current timestamp
5. Reload and refresh the thread list via loadAndSelectThreads()
```

#### 3. `sendMessage()` Storage Actions

When a user sends a message, Cedar performs these storage operations:

```typescript
// Cedar's sendMessage storage flow:
1. Add user message to UI via addMessage()
   - addMessage() automatically calls persistMessageStorageMessage()
   - This triggers the persistence flow described above
2. When assistant responds:
   - For non-streaming: Add response via addMessage() (auto-persisted)
   - For streaming:
     - Append content to messages during stream
     - Persist all new messages after stream completes
```

<Info>
  Best practice: make your **load** endpoints idempotent. Implementations of
  `listThreads` or `loadMessages` should **NOT** perform any mutations such as
  creating threads or messages. Cedar may call these functions multiple times
  during normal operation; if they create data each time you could end up with
  duplicated threads or messages.
</Info>

### Automatic Behaviors

**Thread & Message Loading:**

* **When storage adapter is set**: Adapter is configured but chat initialization happens separately
* **When user ID or thread ID changes**: Triggers `initializeChat` which:
  * Loads all threads for the user
  * May auto-select first thread if none selected
  * Loads messages for the selected thread
* **When userId is undefined**: Storage operations are skipped entirely
* **When threadId is undefined**: A new UUID is generated during message persistence

# User and Thread Management

<Info>
  User ID and thread ID are both stored as Cedar State variables and are
  automatically sent to the backend for Mastra and Custom backends. See Agent
  Backend Connection docs for more details.
</Info>

### Setting User ID

User ID is a Cedar State variable that can be set in two ways:

**Method 1**: Initial Configuration (Recommended)

Pass the user ID directly to CedarCopilot as a prop. This is the simplest and most common approach:

```typescript
import { CedarCopilot } from 'cedar-os';

function App({ userId }: { userId: string }) {
	return (
		<CedarCopilot
			userId={userId} // Set user ID in initial configuration
			messageStorage={{
				type: 'local', // or 'none', 'custom'
			}}>
			<YourChatComponent />
		</CedarCopilot>
	);
}
```

<Note>
  When you pass `userId` to CedarCopilot, it automatically: - Registers it as a
  Cedar State variable (null values become empty strings) - Triggers
  `initializeChat` which loads threads for that user - Makes it available
  throughout your app via Cedar State
</Note>

**Method 2**: Dynamic Setting via State APIs

Use this when you need to change users at runtime (e.g., after login, user switching):

<CodeGroup>
  ```typescript Using setCedarState
  import { setCedarState } from 'cedar-os';

  function LoginHandler() {
  	const handleLogin = async (credentials) => {
  		const user = await loginUser(credentials);

  		// Set user ID - Cedar will load this user's threads
  		setCedarState('userId', user.id);
  	};

  	return <LoginForm onSubmit={handleLogin} />;
  }
  ```

  ```typescript Using useCedarState Hook
  import { useCedarState } from 'cedar-os';

  function UserSwitcher() {
  	const [userId, setUserId] = useCedarState('userId', null);

  	const switchUser = (newUserId: string) => {
  		// This will trigger thread reload for the new user
  		setUserId(newUserId);
  	};

  	return (
  		<select onChange={(e) => switchUser(e.target.value)}>
  			<option value='user-1'>User 1</option>
  			<option value='user-2'>User 2</option>
  		</select>
  	);
  }
  ```

  ```typescript Getting Current User
  import { getCedarState } from 'cedar-os';

  function CurrentUserDisplay() {
  	const userId = getCedarState('userId');

  	return <div>Current user: {userId || 'Not logged in'}</div>;
  }
  ```
</CodeGroup>

When the user ID changes:

1. Cedar loads threads for the new user
2. If no thread is selected, may auto-select first thread (if `listThreads` is implemented)
3. Messages are cleared and reloaded based on the user's threads

### Setting Thread ID

Thread ID is a Cedar State variable that can be set in three ways:

**Method 1**: Initial Configuration

Pass the thread ID directly to CedarCopilot as a prop. This is useful when you want to start with a specific thread:

```typescript
import { CedarCopilot } from 'cedar-os';

function App({ userId, threadId }: { userId: string; threadId: string }) {
	return (
		<CedarCopilot
			userId={userId}
			threadId={threadId} // Set initial thread ID
			messageStorage={{
				type: 'local',
			}}>
			<YourChatComponent />
		</CedarCopilot>
	);
}
```

<Note>
  Like userId, threadId is registered as a Cedar State variable with null values
  converted to empty strings. This triggers `initializeChat` to load messages
  for the specified thread.
</Note>

**Method 2**: Explicit Setting (User Control)

Use this when users manually select threads, navigate to specific conversations, or create new threads at runtime:

<CodeGroup>
  ```typescript Using Store API
  import { setCedarState } from 'cedar-os';

  function ConversationSwitcher() {
  	const switchToThread = (threadId: string) => {
  		// Cedar will save current thread and load the new one
  		setCedarState('threadId', threadId);
  	};

  	return (
  		<div>
  			<button onClick={() => switchToThread('project-discussion')}>
  				Project Discussion
  			</button>
  			<button onClick={() => switchToThread('support-ticket')}>
  				Support Ticket
  			</button>
  		</div>
  	);
  }
  ```

  ```typescript Using Hook
  import { useCedarState } from 'cedar-os';

  function ConversationManager() {
  	const [threadId, setThreadId] = useCedarState('threadId', null);

  	return (
  		<div>
  			<p>Current thread: {threadId || 'No thread selected'}</p>
  			<button onClick={() => setThreadId('new-thread-123')}>
  				Start New Thread
  			</button>
  		</div>
  	);
  }
  ```

  ```typescript Programmatic Control
  // From anywhere in your application
  import { setCedarState, getCedarState } from 'cedar-os';

  // Set a specific thread
  setCedarState('threadId', 'thread-abc-123');

  // Get current thread
  const currentThread = getCedarState('threadId');

  // Navigate to a thread from URL params
  const threadFromUrl = searchParams.get('thread');
  if (threadFromUrl) {
  	setCedarState('threadId', threadFromUrl);
  }
  ```
</CodeGroup>

**Method 3**: Automatic Selection via `listThreads`

If you implement the `listThreads` method in your storage adapter, Cedar will automatically select the first available thread when no thread is currently selected. This is perfect for app initialization:

```typescript
const myStorageAdapter = {
	async listThreads(userId) {
		// Return user's threads from your backend/database
		return [
			{
				id: 'thread-1',
				title: 'General Chat',
				updatedAt: '2024-01-20T10:00:00Z',
			},
			{
				id: 'thread-2',
				title: 'Project Discussion',
				updatedAt: '2024-01-19T15:30:00Z',
			},
		];
	},
	// ... other required methods
};

// When storage adapter is set or threads are loaded:
// - If threadId is null AND threads exist
// - Cedar automatically calls: setCedarState('threadId', threads[0].id)
// - In this example, 'thread-1' would be selected
```

When the thread ID changes (via any method), Cedar automatically:

1. Clears the current messages from the UI
2. Loads messages for the new thread from storage
3. Updates the UI with the new thread's messages

## Next Steps

* Learn about [custom message rendering](/getting-started/chat/custom-message-rendering) for rich content
* Explore [streaming responses](/getting-started/chat/streaming) for real-time interactions
* Set up [agent backend connections](/getting-started/agent-backend-connection/agent-backend-connection) for AI responses


# Streaming
Source: https://docs.cedarcopilot.com/chat/streaming

Enable real-time streaming responses in chat components

Cedar enables streaming responses by default in your chat interface. Responses appear in real-time as they're generated. You can disable streaming by setting the `stream` prop to `false` on any chat component or ChatInput.

<Info>
  **Partial Object Streaming Not Supported**: Cedar currently doesn't support
  partial object streaming. For structured data to be handled via Cedar's
  automatic handlers, only complete objects should be streamed or streaming
  should be turned off.
</Info>

## Quick Start

### With Pre-built Components

Streaming is enabled by default for all pre-built chat components:

```tsx
import { FloatingCedarChat } from 'cedar-os-components';

function App() {
	return (
		<FloatingCedarChat
			// Streaming is enabled by default
			side='right'
			title='Streaming Assistant'
		/>
	);
}
```

To disable streaming, set `stream={false}`:

```tsx
<FloatingCedarChat
	stream={false} // Disable streaming
	side='right'
	title='Non-Streaming Assistant'
/>
```

### With Individual Components

The ChatInput component has streaming enabled by default, but you can override it:

```tsx
import { ChatInput, ChatBubbles } from 'cedar-os';

function CustomChat() {
	return (
		<div className='flex flex-col h-full'>
			<div className='flex-1'>
				<ChatBubbles />
			</div>
			<ChatInput
				stream={false} // Override to disable streaming
				position='embedded'
			/>
		</div>
	);
}
```

## How It Works

When streaming is enabled:

1. **Real-time Updates**: Text streams in character by character as it's generated
2. **Out of the box support for streaming flexible objects**: Handle structured objects and custom events (see [Custom Message Rendering](/chat/custom-message-rendering))
3. **Smooth Animation**: Built-in typewriter effect for natural reading experience
4. **Error Handling**: Graceful fallbacks if streaming fails

## Additional Configuration necessary by provider

* **OpenAI and AI SDK**: Streaming is supported out of the box
* **Mastra and Custom backend**: The backend is required to send a data-only SSE stream of information in either streamed text or entire objects

<AccordionGroup>
  <Accordion title="Uhhh... what is a data-only SSE stream?">
    Server-Sent Events (SSE) are part of a one-way streaming protocol to deliver a sequence of `data:` messages over a single HTTP connection. The stream mixes plain text and structured JSON, sent as newline-delimited chunks prefixed with `data:`.

    Under the hood, the server emits:

    **Text chunks for incremental message rendering**

    ```
    â†’ data: Hello, how can I help you?
    ```

    **JSON objects for structured data or tool outputs**

    ```
    â†’ data: {"type":"setState","command":"search","query":"nearest cafe"}
    ```

    Our client handlers will parse each `data:` line as it arrives and handle parsed text or JSON accordingly. This enables real-time, mixed-format updates with minimal overhead.
  </Accordion>
</AccordionGroup>

<AccordionGroup>
  <Accordion title="Sample Backend Streaming Handler Implementation">
    Feel free to drop these handlers into your backend to take care of Cedar-OS-compatible streaming.

    **1. Example Usage:**

    ```typescript
    // Return statement of /handleStream
    return createSSEStream(async (controller) => {
    	// Handle application execution logic with controller variable available

    	// Stream text responses from your agent
    	const streamResult = await agent.stream({
    		prompt,
    		temperature,
    		maxTokens,
    		systemPrompt,
    	});

    	// Stream the text result using the helper function
    	await handleTextStream(streamResult, controller);

    	// Example: Stream a tool call result as structured JSON
    	const toolCallResult = {
    		type: 'tool_call',
    		tool: 'plant_seed',
    		result: {
    			status: 'success',
    			message: 'A new Cedar tree has been planted <3',
    		},
    		timestamp: new Date().toISOString(),
    	};

    	// Stream the JSON event using the helper function
    	streamJSONEvent(controller, toolCallResult);
    });

    /**
     * Handles streaming of text chunks using data-only format.
     * Pass your agent's stream result and the controller to stream text chunks to frontend.
     */
    export async function handleTextStream(
    	streamResult: StreamTextResult<any, any>,
    	streamController: ReadableStreamDefaultController<Uint8Array>
    ): Promise<string> {
    	const encoder = new TextEncoder();
    	const chunks: string[] = [];

    	// Stream raw text chunks through data field
    	for await (const chunk of streamResult.textStream) {
    		chunks.push(chunk);
    		// Escape literal newlines for SSE compliance
    		const escaped = chunk.replace(/\n/g, '\\n');
    		streamController.enqueue(encoder.encode(`data:${escaped}\n\n`));
    	}

    	return chunks.join('');
    }

    /**
     * Emit any JSON object as a data event.
     * Use this to stream structured data like tool results, progress updates, or custom events.
     */
    export function streamJSONEvent<T>(
    	controller: ReadableStreamDefaultController<Uint8Array>,
    	eventData: T
    ) {
    	const encoder = new TextEncoder();
    	controller.enqueue(encoder.encode('data: '));
    	controller.enqueue(encoder.encode(`${JSON.stringify(eventData)}\n\n`));
    }
    ```

    **2. Core SSE Stream Creator:**

    ```typescript
    /**
     * Creates a Server-Sent Events stream response.
     * Pass a callback function that receives a controller for streaming data.
     * Use this as your main endpoint return value for streaming responses.
     */
    export function createSSEStream(
    	cb: (controller: ReadableStreamDefaultController<Uint8Array>) => Promise<void>
    ): Response {
    	const encoder = new TextEncoder();

    	const stream = new ReadableStream<Uint8Array>({
    		async start(controller) {
    			try {
    				// Execute your application logic with streaming controller
    				await cb(controller);

    				// Signal completion with empty data
    				controller.enqueue(encoder.encode('event: done\n'));
    				controller.enqueue(encoder.encode('data:\n\n'));
    			} catch (err) {
    				console.error('Error during SSE stream', err);

    				const message = err instanceof Error ? err.message : 'Internal error';
    				controller.enqueue(encoder.encode('data: '));
    				controller.enqueue(
    					encoder.encode(`${JSON.stringify({ type: 'error', message })}\n\n`)
    				);
    			} finally {
    				controller.close();
    			}
    		},
    	});

    	return new Response(stream, {
    		headers: {
    			'Content-Type': 'text/event-stream',
    			'Cache-Control': 'no-cache',
    			Connection: 'keep-alive',
    		},
    	});
    }
    ```
  </Accordion>
</AccordionGroup>

## Next Steps

* Set up our [cedar-mastra-starter](https://github.com/CedarCopilot/cedar-mastra-starter) for an example of streaming from a separate Mastra server.
* Sending back a custom object type? Render it using [custom message rendering](/chat/custom-message-rendering)
* Learn about [configuring the Cedar editor](/chat/configuring-cedar-editor)


# null
Source: https://docs.cedarcopilot.com/components/markdown-renderer



# MarkdownRenderer Component

The `MarkdownRenderer` component provides consistent markdown rendering across Cedar OS with advanced features like code syntax highlighting, copy functionality, and prefix processing for chat interfaces.

## Features

* **GitHub Flavored Markdown**: Full GFM support including tables, strikethrough, and more
* **Code Highlighting**: Syntax highlighting with copy-to-clipboard functionality
* **Prefix Processing**: Special handling for prefixed content (useful in chat)
* **Cedar OS Integration**: Automatic theming and styling consistency
* **Inline/Block Modes**: Flexible rendering for different contexts
* **Interactive Elements**: Copy buttons, hover effects, and edit placeholders

## Import

```tsx
import { MarkdownRenderer } from 'cedar-os-components/chatMessages/MarkdownRenderer';
```

## Basic Usage

```tsx
<MarkdownRenderer content='# Hello World\n\nThis is **bold** and *italic* text.' />
```

## Props

| Prop            | Type      | Default | Description                                           |
| --------------- | --------- | ------- | ----------------------------------------------------- |
| `content`       | `string`  | -       | The markdown content to render (required)             |
| `processPrefix` | `boolean` | `false` | Whether to process prefix markers for special styling |
| `className`     | `string`  | `''`    | Additional CSS classes                                |
| `inline`        | `boolean` | `false` | Whether to render in inline mode                      |

## Supported Markdown Elements

### Headers

```markdown
# H1 Header

## H2 Header

### H3 Header

#### H4 Header

##### H5 Header

###### H6 Header
```

### Text Formatting

```markdown
**Bold text**
_Italic text_
~~Strikethrough~~
`Inline code`
```

### Links

```markdown
[Link text](https://example.com)
```

* Opens in new tab automatically
* `noopener noreferrer` for security

### Code Blocks

````markdown
```javascript
function hello() {
	console.log('Hello World!');
}
```
````

Features:

* Language detection and display
* Copy to clipboard button
* Edit placeholder button
* Syntax highlighting
* Horizontal scrolling for long lines

### Lists

```markdown
- Unordered list item 1
- Unordered list item 2

1. Ordered list item 1
2. Ordered list item 2
```

### Blockquotes

```markdown
> This is a blockquote
> It can span multiple lines
```

### Tables

```markdown
| Column 1 | Column 2 | Column 3 |
| -------- | -------- | -------- |
| Row 1    | Data     | More     |
| Row 2    | Data     | More     |
```

## Inline Mode

Perfect for rendering markdown within text flows:

```tsx
<MarkdownRenderer content='This is **bold** text inline' inline={true} />
```

In inline mode:

* Paragraphs render as `<span>` instead of `<p>`
* Maintains text flow
* Preserves inline formatting

## Prefix Processing

For chat interfaces where you need special styling for prefixes:

```tsx
<MarkdownRenderer
	content="@@PREFIX@@Assistant: @@ENDPREFIX@@Here's my response with **markdown**!"
	processPrefix={true}
/>
```

The prefix markers (`@@PREFIX@@` and `@@ENDPREFIX@@`) are automatically:

* Styled with the accent color
* Processed recursively in nested elements
* Removed from final output

## Code Block Features

### Copy Functionality

* Hover over code blocks to see copy button
* Visual feedback when copied
* Automatic timeout after 2 seconds

### Language Support

```tsx
<MarkdownRenderer
	content={`
\`\`\`typescript
interface User {
  name: string;
  email: string;
}
\`\`\`
`}
/>
```

### Inline Code

```tsx
<MarkdownRenderer content='Use the `useState` hook for state management.' />
```

## Styling Integration

The component automatically integrates with Cedar OS theming:

```tsx
// Uses current styling context
const { styling } = useStyling();

// Applied to:
// - Accent colors for borders and highlights
// - Text colors for consistency
// - Background colors for code blocks
// - Table styling and borders
```

## Advanced Examples

### Chat Message Rendering

````tsx
<MarkdownRenderer
	content="@@PREFIX@@System: @@ENDPREFIX@@**Task completed!** Here's your code:\n\n```javascript\nconsole.log('Done!');\n```"
	processPrefix={true}
	className='chat-message'
/>
````

### Documentation Content

```tsx
<MarkdownRenderer
	content={`
# API Documentation

## Overview
This API provides **powerful** functionality.

### Example Request
\`\`\`bash
curl -X POST https://api.example.com/data
\`\`\`

| Parameter | Type | Description |
|-----------|------|-------------|
| \`name\` | string | User name |
| \`email\` | string | User email |
  `}
/>
```

### Inline Rich Text

```tsx
<p>
	Welcome to our platform!
	<MarkdownRenderer
		content='Read our **documentation** and try the `API`'
		inline={true}
	/>
	to get started.
</p>
```

## Accessibility

* Proper semantic HTML structure
* Keyboard navigation support
* Screen reader friendly
* High contrast code blocks
* Focus indicators on interactive elements

## Performance

* Efficient re-rendering with React.memo patterns
* Lazy loading for complex content
* Optimized regex processing
* Minimal DOM updates

## Browser Support

* Modern browsers with ES6+ support
* Clipboard API for copy functionality
* CSS Grid/Flexbox for layout
* Graceful degradation for older browsers

## Integration Notes

* Works seamlessly with TypewriterText component
* Consistent with other Cedar OS components
* Supports dark/light theme switching
* Responsive design for all screen sizes


# null
Source: https://docs.cedarcopilot.com/components/typewriter-text



# TypewriterText Component

The `TypewriterText` component provides an animated typing effect with adaptive speed based on text length. It supports markdown rendering, customizable delays, and optional prefix styling.

## Features

* **Adaptive Speed**: Automatically adjusts typing speed based on text length
* **Markdown Support**: Built-in markdown rendering with prefix support
* **Customizable Cursor**: Optional blinking cursor with styling
* **Prefix Support**: Special styling for prefixed content
* **Performance Optimized**: Uses Framer Motion for smooth animations

## Import

```tsx
import { TypewriterText } from 'cedar-os-components/text/TypewriterText';
```

## Basic Usage

```tsx
<TypewriterText text='Hello, this text will type out automatically!' />
```

## Props

| Prop               | Type         | Default | Description                                                         |
| ------------------ | ------------ | ------- | ------------------------------------------------------------------- |
| `text`             | `string`     | -       | The text to be typed out (required)                                 |
| `className`        | `string`     | `''`    | Additional CSS classes                                              |
| `charDelay`        | `number`     | `0.025` | Base character delay in seconds. If default, adaptive speed is used |
| `minCharDelay`     | `number`     | `0.002` | Minimum delay for very long texts (fastest speed)                   |
| `maxCharDelay`     | `number`     | `0.04`  | Maximum delay for short texts (slowest speed)                       |
| `showCursor`       | `boolean`    | `true`  | Whether to show the typing cursor                                   |
| `onTypingStart`    | `() => void` | -       | Callback when typing animation starts                               |
| `onTypingComplete` | `() => void` | -       | Callback when typing animation completes                            |
| `blinking`         | `boolean`    | `false` | Whether the cursor should blink                                     |
| `renderAsMarkdown` | `boolean`    | `true`  | Whether to render content as markdown                               |
| `prefix`           | `string`     | `''`    | Optional prefix text with special styling                           |

## Adaptive Speed

The component automatically adjusts typing speed based on text length:

* **Short texts** (â‰¤30 words): Use `maxCharDelay` (slower)
* **Long texts** (â‰¥400 characters): Use `minCharDelay` (faster)
* **Medium texts**: Exponential interpolation between min and max

```tsx
// Short text - types slowly
<TypewriterText text="Hi!" />

// Long text - types faster automatically
<TypewriterText text="This is a very long piece of text that will type out much faster than shorter text because the component automatically adjusts the speed based on content length..." />
```

## Custom Speed

Override adaptive speed by setting a custom `charDelay`:

```tsx
<TypewriterText
	text='Custom speed text'
	charDelay={0.05} // Fixed delay of 50ms per character
/>
```

## Prefix Styling

Use prefixes for special highlighting (useful for chat interfaces):

```tsx
<TypewriterText
	text='This is the main message content'
	prefix='Assistant: '
	renderAsMarkdown={true}
/>
```

## Callbacks

```tsx
<TypewriterText
	text='Watch the console!'
	onTypingStart={() => console.log('Started typing')}
	onTypingComplete={() => console.log('Finished typing')}
/>
```

## Markdown Support

The component supports full markdown rendering when `renderAsMarkdown` is true:

```tsx
<TypewriterText
	text='**Bold text**, *italic text*, and `code blocks` all work!'
	renderAsMarkdown={true}
/>
```

## Custom Cursor

```tsx
<TypewriterText
	text='Blinking cursor example'
	showCursor={true}
	blinking={true}
/>
```

## Advanced Example

```tsx
<TypewriterText
	text='# Welcome to Cedar OS\n\nThis is a **powerful** component with `adaptive speed`!'
	prefix='System: '
	className='text-lg font-medium'
	minCharDelay={0.001}
	maxCharDelay={0.06}
	blinking={true}
	onTypingComplete={() => setShowNextSection(true)}
/>
```

## Integration with Cedar OS

The component automatically integrates with Cedar OS styling system:

* Uses `useStyling()` hook for consistent theming
* Cursor color matches the current color scheme
* Prefix styling uses accent colors
* Markdown rendering follows Cedar OS design patterns

## Performance Notes

* Uses Framer Motion's `animate` function for optimal performance
* Automatically cleans up animations on unmount
* Efficient re-rendering with dependency tracking
* Smooth 60fps animations with hardware acceleration


# Customising Cedar
Source: https://docs.cedarcopilot.com/customising/customising-cedar

How to customize Cedar-OS for your needs

This page will cover how to customize Cedar-OS for your specific needs.

## Coming Soon

Content for this section will be added in the next phase.


# Styling
Source: https://docs.cedarcopilot.com/customising/styling

Customize the appearance of Cedar-OS components

Cedar-OS provides comprehensive styling options through the `stylingSlice` and integrates seamlessly with Tailwind CSS. This guide covers how to customize the appearance of Cedar components and ensure proper Tailwind configuration.

## Tailwind CSS Setup

Cedar-OS components use Tailwind CSS for styling. To ensure all Cedar styles work correctly, you need to configure Tailwind to scan Cedar's component files.

### Tailwind 4.0+ Configuration

If you're using Tailwind CSS 4.0 or later, add the following `@source` directive to your main CSS file:

```css
/* app/globals.css or your main CSS file */
@import 'tailwindcss';

/* Add Cedar-OS components to Tailwind's content sources */
@source "../node_modules/cedar-os/**/*.{js,ts,jsx,tsx}";
```

### Tailwind 3.x Configuration

For Tailwind CSS 3.x, add Cedar's paths to your `tailwind.config.js`:

```javascript
// tailwind.config.js
module.exports = {
	content: [
		// Your app's content paths
		'./src/pages/**/*.{js,ts,jsx,tsx,mdx}',
		'./src/components/**/*.{js,ts,jsx,tsx,mdx}',
		'./src/app/**/*.{js,ts,jsx,tsx,mdx}',
		'./src/lib/**/*.{js,ts,jsx,tsx,mdx}',
		'./src/**/*.{js,ts,jsx,tsx}',

		// Add Cedar-OS component paths
		'./node_modules/cedar-os/**/*.{js,ts,jsx,tsx}',
	],
	// ... rest of your config
};
```

## Using the Styling Slice

Cedar-OS includes a `stylingSlice` that manages global styling configuration for all Cedar components. This allows you to customize colors, dark mode, and other visual properties across your entire application.

### Accessing Styling State

```tsx
import { useCedarStore } from 'cedar-os';

function MyComponent() {
	const { styling, setStyling, toggleDarkMode } = useCedarStore();

	return (
		<div>
			<p>Current theme: {styling.darkMode ? 'Dark' : 'Light'}</p>
			<p>Primary color: {styling.color}</p>
			<button onClick={toggleDarkMode}>Toggle Dark Mode</button>
		</div>
	);
}
```

### Styling Configuration

The styling slice provides the following configuration options:

```typescript
interface StylingConfig {
	darkMode: boolean; // Enable/disable dark mode
	color: string; // Primary color (hex format)
	secondaryColor: string; // Secondary color (hex format)
	accentColor: string; // Accent color (hex format)
}
```

### Setting Custom Colors

You can update the color scheme programmatically:

```tsx
import { useCedarStore } from 'cedar-os';

function ThemeCustomizer() {
	const { setStyling } = useCedarStore();

	const applyBrandColors = () => {
		setStyling({
			color: '#3B82F6', // Blue primary
			secondaryColor: '#1E40AF', // Darker blue
			accentColor: '#F59E0B', // Amber accent
		});
	};

	const applyDarkTheme = () => {
		setStyling({
			darkMode: true,
			color: '#6366F1', // Indigo for dark mode
			secondaryColor: '#4F46E5',
			accentColor: '#EC4899', // Pink accent
		});
	};

	return (
		<div>
			<button onClick={applyBrandColors}>Apply Brand Colors</button>
			<button onClick={applyDarkTheme}>Apply Dark Theme</button>
		</div>
	);
}
```

## Component-Level Styling

### Using Styled Components

Cedar components automatically respond to the global styling configuration. For example, the chat components will use your configured colors:

```tsx
import { FloatingCedarChat } from '@/chatComponents/FloatingCedarChat';
import { useCedarStore } from 'cedar-os';

function StyledChat() {
	const { setStyling } = useCedarStore();

	// Set custom colors before rendering
	useEffect(() => {
		setStyling({
			color: '#8B5CF6', // Purple
			secondaryColor: '#7C3AED',
			accentColor: '#F97316', // Orange
		});
	}, []);

	return <FloatingCedarChat side='right' title='Support Chat' />;
}
```

### CSS Variables

Cedar-OS components use CSS variables that integrate with Tailwind's design system. These variables are automatically updated when you change the styling configuration:

```css
/* These variables are set by Cedar-OS */
:root {
	--cedar-primary: /* Your primary color */ ;
	--cedar-secondary: /* Your secondary color */ ;
	--cedar-accent: /* Your accent color */ ;
	--cedar-background: /* Background color based on theme */ ;
	--cedar-foreground: /* Text color based on theme */ ;
}
```

## Utility Functions

Cedar-OS provides several utility functions for working with colors:

### Color Manipulation

```tsx
import {
	desaturateColor,
	getShadedColor,
	getLightenedColor,
	getTextColorForBackground,
} from 'cedar-os';

// Desaturate a color (reduce vibrancy)
const mutedBlue = desaturateColor('#3B82F6');

// Create a darker shade
const darkBlue = getShadedColor('#3B82F6', 0.2); // 20% darker

// Create a lighter tint
const lightBlue = getLightenedColor('#3B82F6', 0.3); // 30% lighter

// Get appropriate text color for a background
const textColor = getTextColorForBackground('#3B82F6'); // Returns white or black
```

### Class Name Utilities

Cedar uses the `cn` utility (similar to `clsx`) for combining class names:

```tsx
import { cn } from 'cedar-os';

function MyComponent({ className, isActive }) {
	return (
		<div
			className={cn(
				'base-styles px-4 py-2',
				isActive && 'bg-blue-500 text-white',
				className
			)}>
			Content
		</div>
	);
}
```

## Dark Mode Support

Cedar-OS components automatically support dark mode through Tailwind's dark mode classes. When you toggle dark mode using `toggleDarkMode()`, all Cedar components will update their appearance.

### Implementing Dark Mode Toggle

```tsx
import { useCedarStore } from 'cedar-os';
import { Moon, Sun } from 'lucide-react';

function DarkModeToggle() {
	const { styling, toggleDarkMode } = useCedarStore();

	useEffect(() => {
		// Apply dark mode class to document
		if (styling.darkMode) {
			document.documentElement.classList.add('dark');
		} else {
			document.documentElement.classList.remove('dark');
		}
	}, [styling.darkMode]);

	return (
		<button
			onClick={toggleDarkMode}
			className='p-2 rounded-lg bg-gray-200 dark:bg-gray-800'>
			{styling.darkMode ? <Sun /> : <Moon />}
		</button>
	);
}
```

## Best Practices

1. **Configure Tailwind First**: Always ensure your Tailwind configuration includes Cedar's component paths before using Cedar components.

2. **Set Colors Early**: Configure your color scheme early in your app's lifecycle, preferably in your root component:

   ```tsx
   function App() {
   	const { setStyling } = useCedarStore();

   	useEffect(() => {
   		setStyling({
   			color: '#YourBrandColor',
   			secondaryColor: '#YourSecondaryColor',
   			accentColor: '#YourAccentColor',
   		});
   	}, []);

   	return <YourApp />;
   }
   ```

3. **Consistent Theme**: Use the styling slice to maintain consistent theming across all Cedar components rather than overriding styles individually.

4. **Responsive Dark Mode**: Always test your color choices in both light and dark modes to ensure good contrast and readability.

## Troubleshooting

### Styles Not Applying

If Cedar component styles aren't working:

1. **Check Tailwind Config**: Ensure Cedar paths are included in your Tailwind configuration
2. **Clear Cache**: Try clearing your build cache and rebuilding
3. **Check CSS Import**: Make sure you're importing your global CSS file that includes Tailwind directives
4. **Verify Installation**: Ensure both `cedar-os` and components are properly installed

### Dark Mode Issues

If dark mode isn't working:

1. **Check HTML Class**: Ensure the `dark` class is being applied to your `<html>` element
2. **Tailwind Dark Mode**: Verify your Tailwind config uses `class` strategy for dark mode:
   ```javascript
   module.exports = {
   	darkMode: 'class',
   	// ... rest of config
   };
   ```

## Next Steps

* Explore [component customization](/customising/customising-cedar) for more advanced styling options
* Learn about [custom message rendering](/chat/custom-message-rendering) to style chat messages
* Check out the [Cedar Playground](https://cedarcopilot.com/examples/cedar-playground) to see styling in action


# Demo Showcases
Source: https://docs.cedarcopilot.com/examples/demo-showcases

Explore Cedar-OS capabilities through these comprehensive examples featuring AI-native interfaces, voice interactions, and custom components.

# Demo Showcases

Explore the power of Cedar-OS through these comprehensive examples that demonstrate various capabilities including voice interactions, state management, custom message rendering, and more.

## AI-Native Email

Custom message rendering, voice, voice streaming, and more.

<iframe width="560" height="315" src="https://www.youtube.com/embed/2QEX2Gf_xKA" title="AI-Native Email (Voice)" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowFullScreen />

<iframe width="560" height="315" src="https://www.youtube.com/embed/y6oEyCjSiPA" title="AI-Native Email" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowFullScreen />

### How we built this ([open source code here](https://github.com/CedarCopilot/smail))

1. ðŸ‘€ **State**: useRegisterState(state) allows the agent to see the email draft and email opened.
2. ðŸ§± **Cedar Components**: Download `<SidePanelCedarChat/>` to own a fully functional chat component
3. ðŸŽ¤ **Microphone**: Cedar manages audio blogs to send it back to the backend
4. ðŸŒŠ **Streaming**: Cedar-OS auto-manages streaming
5. ðŸ§¶ **Custom Message Rendering**: Define custom react components for rendering.
6. ðŸ”¨ **Change Local State**: Cedar-OS takes the Agent's response and makes the local state change
7. ðŸ”Ž **Render Diff**: Render diffs through `<DiffText/>`
8. ðŸ› **Slider Spell**: Use the slider spell to intuitively redraft

***

## AI-Native Canvas

Voice, diff, set state

<iframe width="560" height="315" src="https://www.youtube.com/embed/DJsn5uetu8Y" title="AI-Native Canvas Flow" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowFullScreen />

***

## Onboarding Agent (No Chat)

Create custom, interactive onboarding experiences.

<iframe width="560" height="315" src="https://www.youtube.com/embed/LfjFg03i8kc" title="No Chat Onboarding Agent" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowFullScreen />

{' '}


# Application Based Triggers
Source: https://docs.cedarcopilot.com/external-integrations/application-triggers

Application-based trigger integrations

This page will cover application-based trigger integrations.

## Coming Soon

Content for this section will be added in the next phase.


# Email
Source: https://docs.cedarcopilot.com/external-integrations/email

Email-based external integrations

This page will cover email-based external integrations.

## Coming Soon

Content for this section will be added in the next phase.


# External Integrations
Source: https://docs.cedarcopilot.com/external-integrations/external-integrations

Overview of external integrations

This page will cover external integrations with Cedar-OS.

## Coming Soon

Content for this section will be added in the next phase.


# Text
Source: https://docs.cedarcopilot.com/external-integrations/text

Text-based external integrations

This page will cover text-based external integrations.

## Coming Soon

Content for this section will be added in the next phase.


# Templates & CLI guide
Source: https://docs.cedarcopilot.com/getting-started/cli

Available CLI commands to create with, add, and become more advanced with Cedar

The Cedar CLI is a command-line tool that makes it easy to create new Cedar projects or add Cedar components to existing ones. It intelligently detects your environment and guides you through the setup process.

<Info>
  Because Cedar downloads files locally, it is recommended to always run these
  commands on a clean branch in case any components get overwritten.
</Info>

## Quick Start

For most users, simply run:

```bash
npx cedar-os-cli plant-seed
```

This will launch the smart `plant-seed` command that detects your environment and does the right thing automatically to add Cedar to your project. It guides you through all the steps you need.

## Available Commands

### `cedar plant-seed` (Recommended)

The smart command that automatically detects your environment and takes the appropriate action:

* **New project**: Offers template selection â†’ Creates project â†’ Installs Cedar
* **Existing Next.js/React project**: Detects and just adds Cedar and its dependencies

**Usage:**

```bash
npx cedar-os-cli plant-seed [options]
```

**Options:**

* `-p, --project-name <name>` - Project directory name (prompts if not provided)
* `-y, --yes` - Skip all prompts and use defaults (Mastra template for new projects)

### `cedar add-sapling`

Installs the latest version of Cedar-OS and optionally downloads Cedar UI components. Use to refresh your environment after Cedar updaes.

**Usage:**

```bash
cedar add-sapling [options]
```

**Options:**

* `-d, --dir <path>` - Installation directory (default: `src/cedar/components`)
* `-c, --components <names...>` - Specific components to install
* `-a, --all` - Install all available components
* `-y, --yes` - Skip confirmation prompts and auto-install dependencies

### `cedar pluck-component`

Downloads specific Cedar components locally from an existing npm installation. Use this when you've installed `cedar-os-components` via npm but want to customize specific components.

**Usage:**

```bash
cedar pluck-component [options]
```

**Options:**

* `-d, --dir <path>` - Installation directory (default: `src/cedar/components`)
* `-c, --components <names...>` - Specific components to download
* `-a, --all` - Download all available components
* `-y, --yes` - Skip confirmation prompts

You can either:

* Pass one or more component names with `-c` to download them directly, e.g.

```bash
cedar pluck-component -c FloatingCedarChat TooltipMenu
```

* Omit `-c` to open an interactive list where you can select components.

## Project Templates

When creating new projects, you can choose from several templates, or a blank NextJS component with all dependencies installed:

### Blank Cedar Project

* **What:** Next.js app with Cedar components (no backend)
* **Includes:** Basic Cedar setup using OpenAI API directly
* **Repository:** [cedar-blank](https://github.com/CedarCopilot/cedar-blank)

### Mastra Blank

* **What:** Next.js app with Mastra backend scaffolding
* **Includes:** Monorepo structure, automatic backend connection setup, minimal Cedar integration
* **Repository:** [cedar-mastra-blank](https://github.com/CedarCopilot/cedar-mastra-blank)

### Mastra Reference Repo

* **What:** Complete Cedar implementation with Mastra backend
* **Includes:** All Cedar features, backend integration, example implementations
* **Best for:** Learning Cedar features (or if anything in our docs is confusing)
* **Repository:** [cedar-mastra-starter](https://github.com/CedarCopilot/cedar-mastra-starter)

### Installation Fails

If automatic installation fails, the CLI will show manual installation steps:

```bash
# Manual Next.js creation
npx create-next-app@latest my-project
cd my-project
npx cedar-os-cli add-sapling

# Or follow the manual installation guide
```

## Next Steps

After using the CLI:

1. **Configure your Cedar setup** following the [organizing a Cedar project](/getting-started/organizing-a-cedar-project) guide
2. **Set up your backend connection** with [agent backend connection](/agent-backend-connection/agent-backend-connection)
3. **Customize your chat interface** using [chat components](/chat/chat-components)


# Getting Started Overview
Source: https://docs.cedarcopilot.com/getting-started/getting-started

Complete guide to getting started with Cedar-OS

Cedar-OS is an open-source framework for building AI-native applications. This guide will walk you through setting up your first Cedar-OS application with chat functionality, AI backend integration, and state management.

# Installing Cedar-OS

## With Cedar-CLI

<Steps>
  <Step title="Check Prerequisites">
    Cedar-OS requires:

    * React 18.2.0 or higher
    * React DOM 18.2.0 or higher
    * Node.js 18+ (for development)

    **Framework Support:**

    * âœ… **Next.js (Recommended)** - Full support with optimal performance
    * âœ… **Create React App** - Supported with additional configuration
    * âœ… **Vite + React** - Supported with additional configuration
    * âœ… **Other React frameworks** - May require manual setup
  </Step>

  <Step title="Install using the cedar-os-cli">
    Our CLI is the fastest way to get started with Cedar-OS. For most users, run this command - it automatically detects your setup and does the right thing:

    ```bash
    npx cedar-os-cli plant-seed
    ```

    **What `plant-seed` does:**

    * **New project**: Offers template selection â†’ Creates project â†’ Adds Cedar components

      <Info>
        **Recommended:** We highly recommend starting with the Mastra template. It requires the least configuration and is the most powerful way to use Cedar-OS.
      </Info>

    * **Existing Next.js project**: Automatically adds Cedar components and required dependencies to your project

    * **Existing React project**: Adds Cedar components with a note about Next.js being optimal

    **About Cedar components:** Cedar-OS uses a [shadcn](https://ui.shadcn.com/)-style approach - components are copied directly into your project (not installed as dependencies). This gives you full control to customize, modify, and style the components as needed for your application.

    **When to use `add-sapling` instead:**

    Use this command to install cedar-os and download Cedar components in an existing project if `plant-seed` fails.

    ```bash
    # Add Cedar components and install dependencies only
    npx cedar-os-cli add-sapling
    ```

    **Using CLI flags**

    You can skip prompts using the `--yes` flag:

    ```bash
    npx cedar-os-cli plant-seed --project-name my-cedar-tree --yes
    ```
  </Step>

  <Step title="Add your API key">
    Create a `.env.local` file in your project root and add your OpenAI API key:

    ```bash
    # For client-side access (Cedar-OS components in browser)
    NEXT_PUBLIC_OPENAI_API_KEY=your-openai-api-key

    # For server-side access (API routes, server components)
    OPENAI_API_KEY=your-openai-api-key
    ```

    **Choose based on your setup:**

    * Use `NEXT_PUBLIC_OPENAI_API_KEY` if Cedar-OS will make API calls directly from the browser
    * Use `OPENAI_API_KEY` if you're routing calls through your backend/API routes
    * You can include both if you need access from both client and server

    This will be based on your agent configuration, see [Agent Backend Connection](/agent-backend-connection/agent-backend-connection) for detailed configuration options.
  </Step>

  <Step title="Initialize CedarCopilot">
    Wrap your app with the `CedarCopilot` component and configure your AI provider:

    <Warning>
      **Important:** CedarCopilot must be used in a client component. Add `"use client"` at the top of any file that uses CedarCopilot.
    </Warning>

    <CodeGroup>
      ```tsx Mastra
      "use client";

      import { CedarCopilot } from 'cedar-os';

      function App() {
      	return (
      		<CedarCopilot
      			llmProvider={{
      				provider: 'mastra',
      				baseURL: 'http://localhost:4111', // Your Mastra backend URL
      				apiKey: process.env.MASTRA_API_KEY, // Optional: only if your backend requires auth
      			}}>
      			<YourApp />
      		</CedarCopilot>
      	);
      }
      ```

      ```tsx AI SDK
      "use client";

      import { CedarCopilot } from 'cedar-os';

      function App() {
      	return (
      		// You don't need to put every model,
      		// but if you try to use a model without a key it will fail
      		<CedarCopilot
      			llmProvider={{
      				provider: 'ai-sdk',
      				providers: {
      					openai: {
      						apiKey: process.env.NEXT_PUBLIC_OPENAI_API_KEY,
      					},
      					anthropic: {
      						apiKey: process.env.NEXT_PUBLIC_ANTHROPIC_API_KEY,
      					},
      					google: {
      						apiKey: process.env.NEXT_PUBLIC_GOOGLE_API_KEY,
      					},
      				},
      			}}>
      			<YourApp />
      		</CedarCopilot>
      	);
      }
      ```

      ```tsx OpenAI
      "use client";

      import { CedarCopilot } from 'cedar-os';

      function App() {
      	return (
      		<CedarCopilot
      			llmProvider={{
      				provider: 'openai',
      				apiKey: process.env.NEXT_PUBLIC_OPENAI_API_KEY,
      			}}>
      			<YourApp />
      		</CedarCopilot>
      	);
      }
      ```

      ```tsx Anthropic
      "use client";

      import { CedarCopilot } from 'cedar-os';

      function App() {
      	return (
      		<CedarCopilot
      			llmProvider={{
      				provider: 'anthropic',
      				apiKey: process.env.NEXT_PUBLIC_ANTHROPIC_API_KEY,
      			}}>
      			<YourApp />
      		</CedarCopilot>
      	);
      }
      ```

      ```tsx Custom Backend
      "use client";

      import { CedarCopilot } from 'cedar-os';

      function App() {
      	return (
      		<CedarCopilot
      			llmProvider={{
      				provider: 'custom',
      				config: {
      					baseURL: 'https://your-api.com',
      					apiKey: 'your-api-key',
      					// Any additional config your backend needs
      					organizationId: 'org-123',
      					projectId: 'project-456',
      				},
      			}}>
      			<YourApp />
      		</CedarCopilot>
      	);
      }
      ```
    </CodeGroup>

    See [Agent Backend Connection](/agent-backend-connection/agent-backend-connection) for more details. Now you're ready to add a chat!
  </Step>

  <Step title="Using Cedar">
    Now that you have Cedar-OS installed and configured, here are your next steps to build your AI-native application:

    **Choose your next feature:**

    * **[Configuring a Chat](/chat/chat-overview)** - Set up chat interfaces with `ChatInput` and `ChatBubbles` components for seamless AI conversations
    * **[Adding State Access](/state-access/agentic-state-access)** - Enable AI agents to read and modify your application state using `useCedarState`
    * **[Using Spells](/spells/spells)** - Create interactive radial menus and quick actions for enhanced user experience

    **Quick start examples:**

    <CodeGroup>
      ```tsx Chat Setup
      import { FloatingCedarChat } from 'cedar-os';

      function ChatApp() {
        return (
          <div className="h-screen">
            {/* This automatically works */}
            <FloatingCedarChat />
          </div>
        );
      }
      ```

      ```tsx State Access
      import { useRegisterState } from 'cedar-os';
      import { useState } from 'react';
      import { z } from 'zod';

      function TodoApp() {
        const [todos, setTodos] = useState([]);

        useRegisterState({
            key: 'todos',
            value: todos,
            setValue: setTodos,
            description: 'User todo list manageable by AI',
            customSetters: {
              addTodo: {
                name: 'addTodo',
                description: 'Add a new todo item',
                schema: z.object({
                  text: z.string().describe('Todo text')
                }),
                execute: (currentTodos, text) => {
                  setTodos([...currentTodos, {
                    id: Date.now(),
                    text,
                    completed: false
                  }]);
                }
              },
              toggleTodo: {
                name: 'toggleTodo',
                description: 'Toggle todo completion status',
                schema: z.object({
                  id: z.number().describe('Todo ID')
                }),
                execute: (currentTodos, id) => {
                  setTodos(currentTodos.map(t =>
                    t.id === id ? { ...t, completed: !t.completed } : t
                  ));
                }
              }
          }
        });

        return (
          <div>
            {todos.map(todo => (
              <div key={todo.id}>
                <input
                  type="checkbox"
                  checked={todo.completed}
                  onChange={() => setTodos(todos.map(t =>
                    t.id === todo.id ? { ...t, completed: !t.completed } : t
                  ))}
                />
                {todo.text}
              </div>
            ))}
          </div>
        );
      }
      ```

      ```tsx Spells Integration
      import { useSpells } from 'cedar-os';
      import { useEffect } from 'react';

      function SpellsApp() {
        const { registerSpell } = useSpells();

        useEffect(() => {
          registerSpell({
            id: 'quick-action',
            name: 'Quick Action',
            icon: 'âš¡',
            action: () => console.log('Spell activated!'),
            trigger: 'cmd+k'
          });
        }, []);

        return (
          <div>
            <p>Press Cmd+K to activate spells</p>
          </div>
        );
      }
      ```
    </CodeGroup>
  </Step>
</Steps>

## Next Steps

Now that you have Cedar-OS set up with basic functionality:

1. **Explore Advanced Features**: Check out [Voice Integration](/voice/voice-integration), [Custom Message Types](/chat/custom-message-rendering), and [Advanced State Management](/state-access/agentic-state-access).

2. **Try Different Providers**: Experiment with [Mastra](/agent-backend-connection/mastra) for full-featured agents or [Direct Provider Integration](/agent-backend-connection/custom).

3. **Customize the UI**: Learn about [Styling and Theming](/customising/styling) to match your brand.

4. **Build Complex Workflows**: Explore our [Examples](/examples) to see Cedar-OS in action with real applications.

## If Things Are Going Wrong

### Manual Installation (CLI Fallback)

Look at our [CLI guide](/getting-started/cli) for more options of CLI commands you can try. If all CLI commands are failing, you can manually install Cedar-OS:

<Steps>
  <Step title="Install the cedar-os package">
    <CodeGroup>
      ```bash npm
      npm install cedar-os
      ```

      ```bash yarn
      yarn add cedar-os
      ```

      ```bash pnpm
      pnpm add cedar-os
      ```

      ```bash bun
      bun add cedar-os
      ```
    </CodeGroup>
  </Step>

  <Step title="Copy component source code">
    You will need to manually copy the component source code locally. The component files can be found here: [Cedar-OS Components](https://github.com/CedarCopilot/cedar-OS/tree/main/packages/cedar-os-components)

    Copy the components you need into your project's component directory (typically `src/components/cedar-os/`).
  </Step>

  <Step title="Install dependencies">
    First set up Tailwind CSS (required for Cedar styling) (look at [these docs](https://tailwindcss.com/docs/installation/using-vite) for framework specific instructions)

    Then install the runtime dependencies for Cedar-OS components:

    <CodeGroup>
      ```bash npm
      npm install lucide-react motion motion-plus-react uuid react-markdown framer-motion @radix-ui/react-slot class-variance-authority
      ```

      ```bash yarn
      yarn add lucide-react motion motion-plus-react uuid react-markdown framer-motion @radix-ui/react-slot class-variance-authority
      ```

      ```bash pnpm
      pnpm add lucide-react motion motion-plus-react uuid react-markdown framer-motion @radix-ui/react-slot class-variance-authority
      ```

      ```bash bun
      bun add lucide-react motion motion-plus-react uuid react-markdown framer-motion @radix-ui/react-slot class-variance-authority
      ```
    </CodeGroup>
  </Step>
</Steps>

### Troubleshooting Common Issues

**Components not rendering**: Make sure you've wrapped your app with `CedarCopilot`.

**Components missing ALL styling**: If Cedar-OS components are missing all styling (we promise they are beautiful!), make sure you have [Tailwind CSS configured](https://tailwindcss.com/docs/installation) in your project.

**Don't see the chat?**: Make sure you add the correct chat component inside the `<CedarCopilot>` boundary. See [Chat Overview](/chat/chat-overview) for setup instructions.

**AI calls failing**: Check that your API keys are correctly set in environment variables and accessible in your client code.

**Using with non-Next.js frameworks**: While Cedar-OS works with Create React App, Vite, and other React frameworks, you may need to manually configure Tailwind CSS and ensure proper client-side rendering for optimal performance.

**TypeScript errors**: Cedar-OS is fully typed - check that you're importing types correctly and using the right component props.

Need help? Check our [Community Discord](https://discord.gg/4AWawRjNdZ) or [GitHub Issues](https://github.com/cedar-os/cedar/issues). We're always here to help :-D


# null
Source: https://docs.cedarcopilot.com/getting-started/organizing-a-cedar-project



Cedar is opinionated on the best way to organize files and folders for the optimal development experience. Following these conventions will help with debugging, observability, and onboarding new team members to your Cedar implementation. This is based on our experience building copilots in customers' products with necessary two-way visibility.

## Recommended File Structure

We recommend creating a dedicated `cedar/` folder at the same level as your `app/` directory (in Next.js projects) or equivalent in other frameworks:

```
your-project/
â”œâ”€â”€ app/                    # Your Next.js app directory
â”œâ”€â”€ cedar/                  # Cedar configuration and components
   â”œâ”€â”€ components/         # Directory for all downloaded cedar components
   â”œâ”€â”€ messageStorageAdapter.ts
   â”œâ”€â”€ messageRenderers.ts
   â””â”€â”€ responseHandlers.ts
â”œâ”€â”€ package.json
â””â”€â”€ ...
```

## Configuration Philosophy

The core principle is that **configuration should be centralized, but logic can live wherever it makes business sense**.

### âœ… Recommended Pattern

* Define all Cedar configurations in the `cedar/` folder
* Import and pass configuration objects directly to `CedarCopilot` during initialization
* Keep configuration objects in dedicated files for better organization and debugging

```tsx
// cedar/messageRenderers.ts
export const messageRenderers = {
	// Your custom message renderers
};

// cedar/responseHandlers.ts
export const responseHandlers = {
	// Your response handling logic
};

// In your main component
import { messageRenderers } from '../cedar/messageRenderers';
import { responseHandlers } from '../cedar/responseHandlers';

<CedarCopilot
	messageRenderers={messageRenderers}
	responseHandlers={responseHandlers}
	// other props...
/>;
```

### âŒ Anti-Pattern: Hooks Everywhere

We discourage using hooks scattered throughout your application for Cedar configuration because:

* Components may mount at unexpected times
* Harder to trace the source of bugs
* Reduced observability for new developers
* Inconsistent initialization timing

### Exception: State-Related Functionality

The centralized configuration pattern has one important exception: **state-related functionality must be defined where the state lives**.

When registering state with Cedar, this must happen in the component code that owns that state:

```tsx
// This MUST happen in the component where the state is defined
const [myState, setMyState] = useState();

// Register with Cedar in the same component
useRegisterState('myState', myState, setMyState);
```

## Benefits of This Approach

1. **Better Debugging**: All Cedar configuration is in one predictable location
2. **Improved Observability**: New team members know exactly where to look for Cedar setup
3. **Consistent Initialization**: Configuration is passed directly during component initialization
4. **Easier Maintenance**: Changes to Cedar behavior are centralized and easier to track

## Getting Started

1. Create a `cedar/` folder in your project root
2. Move your Cedar configurations into dedicated files within this folder
3. Import these configurations and pass them directly to `CedarCopilot`
4. Keep state registration in component code where the state is defined

This organization pattern will scale with your project and make Cedar integration more maintainable over time.


# Architecture
Source: https://docs.cedarcopilot.com/introduction/architecture

Understanding how Cedar-OS enables AI-native experiences

## Our Core Architecture

Cedar-OS bridges the gap between AI agents and React applications, providing a comprehensive framework for AI agents to read, write, and interact with your application state, just like users can.

<img src="https://mintlify.s3.us-west-1.amazonaws.com/cedar/images/architecture.png" alt="Cedar-OS Architecture Diagram" />

## Zustand State Management

Let's say you want an AI to be able to read and write different parts of your react app. For example, you're making an AI-native email, and you want it to be able to help with drafts and categorise emails. You have an AI chat on the side that the user can ask it to do things. You'd find some immediate problems with this:

1. **Component-scoped State**: React typically has state inside of the component that uses it. This totally makes sense, and makes for a really great developer experience where you can combine logic and rendering together!

   But this also means that floating up and collecting different states across the application to the AI involves a lot of scoping problems, prop drilling, and messy re-render optimisation.

2. **Lack of Predefined Interactions**: The AI needs much more predefined ways of working with state! How does it interpret what this state means? How does it know how it can and should change it?

3. **State Lifecycle Issues**: State disappears when the component is unmounted, or might have never loaded in! AI should get to make changes, then navigate the user to see those changes.

Cedar fixes this by:

1. **Register States**: Each "RegisterCedarState" acts like a portal the agent can reach the specific state. You don't need to worry about contexts, their scopes, and most importantly the fact that if one context field changes, everything that subscribes to it changes.
2. **States for agents**: Our types support agent understanding and allow you to create custom setters that allow the agent to interact in predefined, safe ways.
3. **Persistent State Registration**: State can be registered so the agent can see the contents even if the user doesn't have the component rendered in that moment, and backend loading behaviour can be configured.

### Cedar's Zustand Implementation

* **Centralized Data Store**: It stores all the data the agent needs in one centralised place
* **State Persistence**: It persists state across component lifecycles
* **Override Capability**: It allows you to override any internal function simply by registering a slice with the same field key
* **Optimized Hooks**: We provide optimised hooks (and every internal zustand slice)
* **Pre-built Components**: We create components that use these hooks and internal state
* **Complete Solutions**: We put together these components into completed functionality, so you can get a working chat in one line

### Hooks Layer - The Foundation

At the base, we provide optimized hooks that connect directly to our Zustand store. Examples:

* **`useCedarState`**: Access and modify registered state with type safety
* **`useTypedAgentConnection`**: Manage AI agent connections with full typing
* **`useCedarEditor`**: Rich text editing with AI-aware features
* **`useMessageRenderer`**: Handle streaming messages and custom components

These hooks abstract away the complexity of state management, context, and real-time updates while maintaining full type safety and performance optimization. You can of course create your own hooks that plug into the Zustand store.

### Components Layer - Shadcn-Style Customization

Our component layer adopts the shadcn/ui philosophy of **copy-and-own** rather than traditional npm packages.

**Why Copy-and-Own Works Better for AI Components:**

* **Full Customization**: You own the component code, so you can modify styling, behavior, and logic without fighting against package constraints
* **No Version Lock-in**: Updates are opt-in. You choose when and what to update, preventing breaking changes from disrupting your AI experiences
* **Transparent Implementation**: You can see exactly how components work with AI state, making debugging and customization straightforward

**Component Examples:**

* `ChatInput` - AI-aware input with mentions and context
* `StreamingText` - Real-time text rendering with typewriter effects
* `MessageRenderer` - Renders different messages with unique styling or interactivity.
* `VoiceIndicator` - Visual feedback for voice interactions

### Complete Solutions - One-Line AI Experiences

At the top layer, we provide complete, production-ready AI experiences. We can provide sophisticated solutions like this because you own the code, and so you can customise it however you want. Example:

* **`<FloatingCedarChat />`**: Floating chat interface that can be summoned anywhere. This combines `<ChatInput />`, `<ContextBadge />`, `<ChatMessages />`, and positional Containers like `<FloatingContainer />` to create a floating chat.

**The Power of This Architecture:**

1. **Start Simple**: Drop in a complete solution like `CedarCopilot` and `FloatingCedarChat` and have AI working in minutes
2. **Customize Gradually**: Customise individual components as your needs evolve
3. **Go Deep**: Use hooks directly for completely custom AI experiences
4. **Never Hit Walls**: Since you own all the code, there are no limitations on what you can build.


# Cedar-OS
Source: https://docs.cedarcopilot.com/introduction/overview

An open-source framework for building the next generation of AI native software

Cedar-OS is a open-source framework for building AI-native react apps. Basically, it helps your app go from vscode to cursor.

It's designed to give you primitives and structure for creating apps where AI is embedded as part of the product experience, such as reading and writing to local state, managing agent changes, and creating more intuitive ways to communicate with the agent.

We believe the future of AI isn't just a chatbot on the side, but something that's aware of what's going on inside the app, can directly change local state, and working tightly with the user and software to provide value.
For the first time in history, products can come to life. We want to help you build something with life.

## Core Features

<CardGroup cols={3}>
  <Card title="Streaming & Tool Calls" icon="bolt" href="/chat/streaming">
    Render real-time message streaming and agent tool execution
  </Card>

  <Card title="Voice Integration" icon="microphone" href="/voice/voice-integration">
    Voice-powered agent interactions
  </Card>

  <Card title="State Access" icon="database" href="/state-access/agentic-state-access">
    Let agents read and write application state
  </Card>

  <Card title="Diff & History" icon="code-compare" href="/state-access/diff-history-manager">
    Track what AI changes, allow user approvals, and manage history
  </Card>

  <Card title="Chat" icon="comments" href="/chat/chat-overview">
    Floating, SidePanel, Caption, or Embedded chat components
  </Card>

  <Card title="Spells" icon="wand-magic-sparkles" href="/spells/spells">
    Powerful agent interactions and workflows
  </Card>

  <Card title="Mentions" icon="at" href="/agent-input-context/mentions">
    Context-aware mention system for chat
  </Card>

  <Card title="Agent Connection Modules" icon="plug" href="/agent-backend-connection/agent-backend-connection">
    Connect to various AI backends and services
  </Card>

  <Card title="Component Library" icon="cube" href="/customising/customising-cedar">
    Pre-built UI components you own the code for, Shadcn style
  </Card>
</CardGroup>

## Quick Navigation

<CardGroup cols={2}>
  <Card title="Is Cedar right for you?" icon="lightbulb" href="/introduction/philosophy">
    Our philosophy, limitations & strengths, what Cedar is made for
  </Card>

  <Card title="Architecture" icon="diagram-project" href="/introduction/architecture">
    Understand how Cedar-OS is structured and works
  </Card>

  <Card title="Getting Started" icon="rocket" href="/getting-started">
    Start building with Cedar-OS
  </Card>

  <Card title="Demos of Cedar-OS" icon="play" href="/introduction/ai-native-experiences">
    See Cedar-OS in action
  </Card>
</CardGroup>


# Is Cedar right for you?
Source: https://docs.cedarcopilot.com/introduction/philosophy

What we built Cedar for, our principles, limitations & strengths

# Should you use Cedar?

Our goal is to enable people building **the most ambitious AI-native applications of the future**.

We believe in the craft and creativity of the community. We believe that giving you control allows you to customise Cedar to make the user experiences better.

## Cedar is fully extensible and customisable

There are good reasons not to use Cedar (see "Cedar is opinionated" below). However, worries about hitting customisability, control, and hitting a ceiling with Cedar shouldn't be one of them.

1. **Every single component is downloaded shadcn-style. You own all the code and can style it however you want**
2. **Every single internal function can be overridden in one line.**
3. **We will always consider the developer experience in extending and customising Cedar a core part of what we offer.**

## Cedar is simple.

Cedar is built so that everything works out of the box. You want a working chat? Import `<CedarFloatingChat/>` and *it just works*. Want streaming? Add `streaming={true}` to the messages component. We automatically handle the functionality switches.

Because you own the code, we feel much more comfortable creating complex configurations that work out of the box, knowing you can customise anything.

## Cedar is opinionated

We've been building copilots in production for different companies for the past month, and have converged on systems and structures that work well across the board.

We also believe that good design reflects the nature of the product, and so we're very big on animation to represent the fluidity of AI.

We use tailwind, zustand, and are built on top of react. We're working on mobile, but we want to handle react really well before moving on to different web frameworks.

See [Architecture](/introduction/architecture) for how Cedar works behind the scenes.

## We haven't figured out the future of human-software interaction

> What happens when a new medium enters the scene, is that we tend to fall back to old medium habits. If you go back to first televion shows, they were basically radio shows with a camera pointed at them. It took us the better part of the 50â€™s to really understand how television was gonna come into its own as it's own medium. **-Steve Jobs**

We think we've had a glimpse of the future, and are working on brand new interfaces for communicating back and forth with LLM's, but we know there are going to be brand new interactions and functionality that we'll need to support.

That's why we've built a pretty generalisable, extensible system as a base, but we expect Cedar to change a lot over the coming months. We hope you'll stick with us to get some of the new exciting things coming out.


# Cedar-OS Internals (advanced)
Source: https://docs.cedarcopilot.com/introduction/understanding-cedar-architecture-advanced

A deep dive into Cedar-OS internal architecture

This is for those who are interested in advanced use cases or contributing. If you just want to get started, please go to [Getting Started](/getting-started/getting-started). We recommend you come back to this once you have a working chat and are building custom AI workflows.

We'll go through an overview of the core modules, and then how we built the internal sendMessage() function that composes all the slices into end to end flows.

## The Zustand Store Structure

Cedar-OS uses [Zustand](https://zustand-demo.pmnd.rs/) as its core state management solution, organized into specialized "slices" that each handle different aspects of the system. This allows us to modularise and encapsulate functionality internally to modules.

### Core Slices Overview

```typescript
// The complete Cedar store combines all slices
interface CedarStore =
  // core modules
  & AgentConnectionSlice      // LLM communication & response processing
  & StateSlice               // Allows the agent to read & write to the state
  & AgentInputContextSlice    // Allows us to control the context we send to the agent, including state ^
  & MessagesSlice            // Chat message storage & rendering
  // additional modules
  & SpellSlice              // Interactive UI components ("spells")
  & StylingSlice            // Theme & appearance
  & VoiceSlice              // Voice interaction
  & DebuggerSlice           // Development tools
```

**`AgentConnectionSlice`** - Handles all LLM communication and response processing

**`StateSlice`** - Allows agents to read and write to local react states

**`AgentInputContextSlice`** - Gathers and formats context (such as state) for AI consumption

**`MessagesSlice`** - Stores and renders chat messages

## Breaking down an end-to-end AI workflow with Cedar-OS

Let's say you want to build this an AI-native email flow where you can say "Write a response" and have an AI agent compose a draft to respond to the currently opened email.

<iframe width="560" height="315" src="https://www.youtube.com/embed/y6oEyCjSiPA" title="AI-Native Email" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowFullScreen />

### Preparing the input

<img src="https://mintlify.s3.us-west-1.amazonaws.com/cedar/images/gettingInput.png" alt="Cedar-OS  Diagram" />

**1. The first you'd do is pass in the user ask: "Write a response" to an LLM.**

This part is easy. We get the user request and pass it in as prompt.

**2. Now we should add the user input as a message**

We call `addMessage` from `messagesSlice` to persist and add the user message to chat history.

**3. Let agent read state through `stateSlice`**

But now, how does the agent know what it's supposed to write a response to? Our next step is to allow the agent to read from local states.

To do this, we have `stateSlice` which provides functions like `registerState`. This lets us register a state into a central place no matter where and how the local states are distributed.

**4. agentInputContext**

agentInputContext handles the context that we pass into the agent. It stringifies the context & editor through `stringifyInputContext` and `stringifyAdditionalContext` and helps generally manage the context we're giving the agent.

For example, it allows users to use @notation to mention a specific email or user through `useStateBasedMentionProvider()`.

**5. callLLM()**

Now that we've pulled all the necessary context for the agent to execute its task effectively, we can pass it all in through the `agentConnectionSlice` which calls the LLM.

### Handling the LLM response

<img src="https://mintlify.s3.us-west-1.amazonaws.com/cedar/images/handlingLLMResponse.png" alt="Cedar-OS  Diagram" />

Once we get a response from the LLM, Cedar-OS processes it through a structured pipeline that handles both text content and structured actions.

**1. Response routing through `handleLLMResponse`**

When the LLM returns a response, it gets passed to `handleLLMResponse()` which processes an array of items that can be either strings (text content) or structured objects.

**2. Type-based processing with response processors**

The system uses a switch-like mechanism through `processStructuredResponse()` that looks at the `type` field of structured responses and routes them to registered response processors:

* **`message` type** - Handled by `messageResponseProcessor`, converts backend message format to chat messages
* **`setState` type** - Handled by `setStateResponseProcessor`, executes state mutations through `executeCustomSetter()`
* **`progress_update` type** - Shows loading states and progress indicators

**3. Adding to chat through `messagesSlice`**

Text content and processed messages get added to the chat history via `addMessage()` in the `messagesSlice`. This handles the display and persistence of conversation history.

**4. State mutations through registered setters**

For `setState` type responses, the system calls `executeCustomSetter()` which uses the parameters from `registerState()` to execute the appropriate custom setter function, allowing the AI to modify application state based on the registered schema and available setters.

***

## Response Processors Deep Dive

Response processors handle different types of structured AI responses:

### Built-in Processors

1. **SetStateResponseProcessor** - Executes state mutations
2. **MessageResponseProcessor** - Adds text messages to chat
3. **ProgressUpdateResponseProcessor** - Handles loading states

### Custom Response Processors

```typescript
import { createResponseProcessor } from 'cedar-os';

const emailResponseProcessor = createResponseProcessor({
	type: 'email_action',
	namespace: 'email',
	execute: async (obj, store) => {
		if (obj.action === 'send') {
			await sendEmail(obj.draftId);
			store.addMessage({
				role: 'assistant',
				type: 'text',
				content: `Email sent successfully!`,
			});
		}
	},
	validate: (obj) => obj.type === 'email_action',
});

// Register the processor
store.registerResponseProcessor(emailResponseProcessor);
```


# null
Source: https://docs.cedarcopilot.com/mcp-integration/mcp-server



# Cedar MCP Server

The Cedar Model Context Protocol (MCP) server enables seamless integration between Cedar-OS and AI development environments like Cursor, providing intelligent assistance for building AI-native frontends.

## Quick Start

### 1. Install in Cursor

Open your Cursor settings file (`~/.cursor/settings.json`) and add:

```json
{
  "mcpServers": {
    "cedar-mcp": {
      "url": "https://mcpwithcedar-production.up.railway.app/jsonrpc",
      "description": "Cedar-OS Expert MCP Server"
    }
  }
}
```

### 2. Restart Cursor

Close and reopen Cursor to activate the MCP server.

### 3. Verify Installation

In any file, type a comment and use Cursor's AI assistant:

```javascript
// Help me create a Cedar chat component
```

The MCP server should provide Cedar-specific guidance.

### 4. Start Using Cedar

Ask the MCP server natural language questions:

```
"Create a basic Cedar chat interface with streaming support"
"Add voice input to my Cedar chat"
"Implement a radial menu spell"
```

## Key Features

* **Intelligent Code Assistance**: Context-aware suggestions for Cedar components and patterns
* **Documentation Search**: Instant access to relevant Cedar documentation
* **Component Discovery**: Find and implement the right Cedar components
* **Voice Integration Support**: Specialized assistance for voice features
* **Spells Implementation**: Expert guidance on Cedar spells
* **Mastra Backend Integration**: Seamless agent backend connections

## Common Usage Patterns

### Component Implementation

```
"Help me implement a floating chat component with Cedar"
"Add voice capabilities to my Cedar chat interface"
"Create a custom spell for text selection"
"Build a mention system with Cedar"
```

### Documentation Queries

```
"Show me Cedar chat component documentation"
"How do I configure streaming in Cedar?"
"What are Cedar spells and how do they work?"
"Explain Cedar's state management approach"
```

### Integration Tasks

```
"Connect my Cedar frontend to a Mastra agent"
"Set up voice streaming with WebSockets"
"Implement state management with Cedar store"
"Configure message persistence"
```

## Advanced Features

### Contextual Awareness

The MCP server understands:

* Your project structure and existing Cedar components
* Current file context and imports
* Project dependencies and configuration
* Cedar best practices and patterns

### Specialized Modules

* **Voice Expert**: Audio streaming, permissions, WebSocket configuration
* **Spells Expert**: Spell creation, activation patterns, gesture handling
* **Mastra Expert**: Agent connections, workflow setup, backend integration
* **Chat Expert**: Message handling, streaming, custom rendering

## Common Workflows

### Setting Up a New Project

1. Initialize Cedar: `"Set up a new Cedar project with TypeScript"`
2. Add chat: `"Add Cedar chat components to my app"`
3. Configure backend: `"Connect to my Mastra agent backend"`
4. Add voice: `"Implement voice capabilities"`

### Building Features

1. Start simple: `"Create a basic chat interface"`
2. Add interactivity: `"Add mention support to chat"`
3. Enhance UX: `"Implement message streaming"`
4. Add AI features: `"Create a questioning spell"`

### Debugging Issues

* `"Debug WebSocket connection problems"`
* `"Fix streaming message display"`
* `"Resolve spell activation conflicts"`
* `"Troubleshoot voice permissions"`

## Best Practices

1. **Ask Before Building**: Query capabilities before implementing
2. **Use Examples**: Request code examples for complex features
3. **Incremental Development**: Build features step by step
4. **Leverage Search**: Use semantic search for documentation
5. **Validate Code**: Ask for best practice reviews

## Tips and Tricks

* **Auto-imports**: MCP knows Cedar import paths
* **Pattern Matching**: Ask for common Cedar patterns
* **Code Review**: Request validation of implementations
* **Component Discovery**: Ask "What Cedar components help with \[task]?"
* **Quick Fixes**: Get immediate solutions for errors

## Troubleshooting

### MCP Server Not Responding

* Verify configuration in Cursor settings
* Check Node.js is accessible
* Restart Cursor after changes

### Incorrect Suggestions

* Provide more project context
* Specify Cedar version
* Include relevant code snippets

### Performance Issues

* Clear Cursor cache
* Check internet connection
* Update MCP server version

## Prerequisites

* Cursor IDE (latest version)
* Node.js 18+ installed
* Basic TypeScript/React knowledge
* Cedar-OS project or willingness to create one

## Support

* [Cedar Discord Community](https://discord.gg/4AWawRjNdZ)
* [GitHub Issues](https://github.com/CedarCopilot/cedar-OS/issues)
* [Cedar Documentation](https://docs.cedarcopilot.com)


# Creating Custom Spells
Source: https://docs.cedarcopilot.com/spells/creating-custom-spells

Learn how to build your own magical interactions with Cedar-OS spells

# Creating Custom Spells

Spells in Cedar-OS are created using the `useSpell` hook, which provides a declarative API for binding gestures to behaviors. This guide will walk you through creating custom spells from simple to advanced.

## Basic Spell Structure

Every spell requires three core elements:

```tsx
import { useSpell, Hotkey, ActivationMode } from 'cedar-os';

function MySpell() {
	const { isActive, activate, deactivate, toggle } = useSpell({
		// 1. Unique identifier
		id: 'my-unique-spell',

		// 2. Activation conditions
		activationConditions: {
			events: [Hotkey.SPACE],
			mode: ActivationMode.TOGGLE,
		},

		// 3. Lifecycle callbacks
		onActivate: (state) => {
			console.log('Activated!', state.triggerData);
		},
		onDeactivate: () => {
			console.log('Deactivated!');
		},
	});

	return isActive ? <YourMagicUI /> : null;
}
```

## The useSpell Hook

The `useSpell` hook is your primary interface for creating spells:

### Parameters

```tsx
interface UseSpellOptions {
	/** Unique identifier for the spell */
	id: string;

	/** Conditions that trigger activation */
	activationConditions: ActivationConditions;

	/** Called when spell activates */
	onActivate?: (state: ActivationState) => void;

	/** Called when spell deactivates */
	onDeactivate?: () => void;

	/** Prevent default browser behavior */
	preventDefaultEvents?: boolean;

	/** Ignore activation in input elements */
	ignoreInputElements?: boolean;
}
```

### Return Values

```tsx
interface UseSpellReturn {
	/** Current activation state */
	isActive: boolean;

	/** Programmatically activate */
	activate: () => void;

	/** Programmatically deactivate */
	deactivate: () => void;

	/** Toggle activation state */
	toggle: () => void;
}
```

## Activation Conditions

Activation conditions define how users trigger your spell:

### Events

Spells can respond to multiple event types:

```tsx
import { Hotkey, MouseEvent, SelectionEvent } from 'cedar-os';

// Single key activation
activationConditions: {
	events: [Hotkey.Q];
}

// Keyboard combination
activationConditions: {
	events: ['ctrl+k', 'cmd+k']; // Support both Windows and Mac
}

// Mouse events
activationConditions: {
	events: [MouseEvent.RIGHT_CLICK];
}

// Text selection
activationConditions: {
	events: [SelectionEvent.TEXT_SELECT];
}

// Multiple triggers
activationConditions: {
	events: [Hotkey.SPACE, MouseEvent.RIGHT_CLICK];
}
```

### Activation Modes

Control how your spell's lifecycle works:

```tsx
import { ActivationMode } from 'cedar-os';

// TOGGLE: Press to activate, press again to deactivate
activationConditions: {
  events: [Hotkey.T],
  mode: ActivationMode.TOGGLE
}

// HOLD: Active only while key/button is held
activationConditions: {
  events: [Hotkey.SPACE],
  mode: ActivationMode.HOLD
}

// TRIGGER: Fire once with optional cooldown
activationConditions: {
  events: [Hotkey.ENTER],
  mode: ActivationMode.TRIGGER,
  cooldown: 1000 // Prevent spam (milliseconds)
}
```

## Complete Examples

### Example 1: Command Palette Spell

A command palette that appears with `Cmd+K`:

```tsx
import { useSpell, ActivationMode } from 'cedar-os';
import { useState } from 'react';

function CommandPaletteSpell() {
	const [query, setQuery] = useState('');

	const { isActive, deactivate } = useSpell({
		id: 'command-palette',
		activationConditions: {
			events: ['cmd+k', 'ctrl+k'],
			mode: ActivationMode.TOGGLE,
		},
		onActivate: () => {
			setQuery(''); // Reset on open
		},
		preventDefaultEvents: true, // Prevent browser default for Ctrl+K
	});

	if (!isActive) return null;

	return (
		<div className='fixed inset-0 z-50 flex items-center justify-center bg-black/50'>
			<div className='w-96 bg-white rounded-lg shadow-xl p-4'>
				<input
					autoFocus
					value={query}
					onChange={(e) => setQuery(e.target.value)}
					onKeyDown={(e) => {
						if (e.key === 'Escape') deactivate();
					}}
					placeholder='Type a command...'
					className='w-full p-2 border rounded'
				/>
				{/* Command results here */}
			</div>
		</div>
	);
}
```

### Example 2: Context Menu Spell

A context menu that appears on right-click:

```tsx
import { useSpell, MouseEvent, ActivationMode, useCedarStore } from 'cedar-os';

function ContextMenuSpell() {
	const [position, setPosition] = useState({ x: 0, y: 0 });

	const { isActive } = useSpell({
		id: 'context-menu',
		activationConditions: {
			events: [MouseEvent.RIGHT_CLICK],
			mode: ActivationMode.TOGGLE,
		},
		onActivate: (state) => {
			// Capture mouse position from trigger data
			if (state.triggerData?.mousePosition) {
				setPosition(state.triggerData.mousePosition);
			}
		},
		preventDefaultEvents: true, // Prevent browser context menu
	});

	if (!isActive) return null;

	return (
		<div
			className='fixed bg-white rounded shadow-lg p-2 z-50'
			style={{ left: position.x, top: position.y }}>
			<button className='block w-full text-left p-2 hover:bg-gray-100'>
				Copy
			</button>
			<button className='block w-full text-left p-2 hover:bg-gray-100'>
				Paste
			</button>
			{/* More menu items */}
		</div>
	);
}
```

### Example 3: AI Assistant Spell

A spell that integrates with Cedar's AI capabilities:

```tsx
import { useSpell, SelectionEvent, useCedarStore } from 'cedar-os';

function AIAssistantSpell() {
	const { sendMessage } = useCedarStore();
	const [selectedText, setSelectedText] = useState('');

	const { isActive } = useSpell({
		id: 'ai-assistant',
		activationConditions: {
			events: [SelectionEvent.TEXT_SELECT],
			mode: ActivationMode.TOGGLE,
		},
		onActivate: (state) => {
			if (state.triggerData?.selectedText) {
				setSelectedText(state.triggerData.selectedText);
			}
		},
		ignoreInputElements: false, // Allow in text areas
	});

	if (!isActive || !selectedText) return null;

	const handleAction = (action: string) => {
		sendMessage({
			content: `${action}: ${selectedText}`,
			role: 'user',
		});
	};

	return (
		<div className='fixed bottom-4 right-4 bg-white rounded-lg shadow-xl p-4'>
			<h3 className='font-bold mb-2'>AI Assistant</h3>
			<p className='text-sm text-gray-600 mb-3'>
				Selected: "{selectedText.slice(0, 50)}..."
			</p>
			<div className='space-y-2'>
				<button
					onClick={() => handleAction('Explain')}
					className='block w-full text-left p-2 bg-blue-50 rounded hover:bg-blue-100'>
					ðŸ¤” Explain this
				</button>
				<button
					onClick={() => handleAction('Improve')}
					className='block w-full text-left p-2 bg-green-50 rounded hover:bg-green-100'>
					âœ¨ Improve writing
				</button>
				<button
					onClick={() => handleAction('Translate to Spanish')}
					className='block w-full text-left p-2 bg-purple-50 rounded hover:bg-purple-100'>
					ðŸŒ Translate
				</button>
			</div>
		</div>
	);
}
```

## Advanced Patterns

### Combining Multiple Spells

You can compose multiple spells for complex interactions:

```tsx
function MultiSpellComponent() {
	// Primary spell for activation
	const mainSpell = useSpell({
		id: 'main-menu',
		activationConditions: {
			events: [Hotkey.SPACE],
			mode: ActivationMode.HOLD,
		},
	});

	// Secondary spell that only works when main is active
	const subSpell = useSpell({
		id: 'sub-action',
		activationConditions: {
			events: [Hotkey.ENTER],
			mode: ActivationMode.TRIGGER,
		},
		onActivate: () => {
			if (mainSpell.isActive) {
				// Perform sub-action
			}
		},
	});

	return mainSpell.isActive ? <Menu /> : null;
}
```

### Dynamic Activation Conditions

Activation conditions can be changed dynamically:

```tsx
function DynamicSpell({ userPreference }) {
	const activationKey = userPreference === 'vim' ? Hotkey.J : Hotkey.ARROW_DOWN;

	const spell = useSpell({
		id: 'navigation',
		activationConditions: {
			events: [activationKey],
			mode: ActivationMode.TRIGGER,
		},
		onActivate: () => {
			// Navigate down
		},
	});

	// Spell will re-register when preference changes
}
```

### Accessing Cedar Store

Spells can interact with the Cedar store for AI operations:

```tsx
import { useCedarStore } from 'cedar-os';

function StoreIntegratedSpell() {
	const store = useCedarStore();

	const spell = useSpell({
		id: 'ai-spell',
		activationConditions: {
			events: ['alt+a'],
			mode: ActivationMode.TOGGLE,
		},
		onActivate: () => {
			// Access messages
			const lastMessage = store.messages[store.messages.length - 1];

			// Send new message
			store.sendMessage({
				content: 'Activated spell!',
				role: 'user',
			});

			// Access other store slices
			const styling = store.styling;
		},
	});
}
```

## Best Practices

### 1. Use Descriptive IDs

```tsx
// âœ… Good
id: 'command-palette-main';
id: 'context-menu-editor';

// âŒ Bad
id: 'spell1';
id: 'menu';
```

### 2. Handle Cleanup

```tsx
// The hook automatically handles cleanup, but you can add custom logic
onDeactivate: () => {
	// Reset state
	setMenuItems([]);
	// Clear timers
	clearTimeout(timeoutId);
};
```

### 3. Prevent Conflicts

```tsx
// Use ignoreInputElements to avoid conflicts in forms
ignoreInputElements: true; // Default

// Use preventDefaultEvents to override browser shortcuts
preventDefaultEvents: true; // When using Ctrl+S, etc.
```

### 4. Provide Visual Feedback

```tsx
const { isActive } = useSpell({...});

// Always indicate spell state to users
return (
  <>
    {isActive && <StatusIndicator />}
    {isActive && <SpellUI />}
  </>
);
```

### 5. Consider Accessibility

```tsx
// Provide alternative activation methods
activationConditions: {
	events: [
		'ctrl+space', // Keyboard users
		MouseEvent.RIGHT_CLICK, // Mouse users
		'alt+enter', // Screen reader friendly
	];
}
```

## API Reference

### Available Hotkeys

All single keys (A-Z, 0-9) plus:

* Function keys: `F1` - `F12`
* Special keys: `ESCAPE`, `ENTER`, `SPACE`, `TAB`, `DELETE`, `BACKSPACE`
* Arrow keys: `ARROW_UP`, `ARROW_DOWN`, `ARROW_LEFT`, `ARROW_RIGHT`
* Modifiers: `CTRL`, `CMD`, `META`, `ALT`, `SHIFT`

### Mouse Events

* `RIGHT_CLICK` - Right mouse button
* `DOUBLE_CLICK` - Double left click
* `MIDDLE_CLICK` - Middle mouse button
* `SHIFT_CLICK` - Shift + left click
* `CTRL_CLICK` - Ctrl + left click
* `CMD_CLICK` - Cmd + left click (Mac)
* `ALT_CLICK` - Alt + left click

### Selection Events

* `TEXT_SELECT` - Text selection in document

## Next Steps

* Explore the [Spell Architecture](/spells/spell-architecture) to understand the internals
* Check out the [Radial Menu](/spells/radial-menu) implementation for a complex example
* Visit the [Cedar Playground](/examples/cedar-playground) to see spells in action


# Questioning Spell
Source: https://docs.cedarcopilot.com/spells/questioning-spell

An interactive cursor that reveals hidden information on hover

# Questioning Spell

The `QuestioningSpell` component transforms your cursor into an interactive exploration tool that reveals hidden information when hovering over elements. It's perfect for creating educational interfaces, providing contextual help, or building discovery-based experiences.

## Features

* **Interactive Cursor**: Custom reticle cursor with smooth animations
* **Data Attribute Detection**: Automatically finds `data-question` attributes
* **Visual Feedback**: Rotating reticle that locks onto targets
* **Tooltip Display**: Shows contextual information on hover
* **Theme Aware**: Adapts to Cedar's color scheme
* **Keyboard Activation**: Default 'Q' key toggle

## Installation

```tsx
import { QuestioningSpell } from 'cedar-os-components/spells';
```

## Basic Usage

```tsx
import { QuestioningSpell } from 'cedar-os-components/spells';

function MyComponent() {
	return (
		<>
			{/* Add the spell to your app */}
			<QuestioningSpell />

			{/* Add data-question attributes to elements */}
			<div className='p-4'>
				<button
					data-question='This button submits the form and saves your data'
					className='bg-blue-500 text-white px-4 py-2 rounded'>
					Save
				</button>

				<span
					data-question='This metric shows the total number of active users in the last 30 days'
					className='font-bold'>
					Active Users: 1,234
				</span>
			</div>
		</>
	);
}
```

Press 'Q' to activate the questioning mode, then hover over elements to see their explanations.

## Props

| Prop                   | Type                   | Required | Default               | Description                               |
| ---------------------- | ---------------------- | -------- | --------------------- | ----------------------------------------- |
| `spellId`              | `string`               | No       | `'questioning-spell'` | Unique identifier for this spell instance |
| `activationConditions` | `ActivationConditions` | No       | Q key toggle          | Custom activation conditions              |

## Customization

### Custom Activation

Change the activation key or mode:

```tsx
import { Hotkey, ActivationMode } from 'cedar-os';

<QuestioningSpell
	spellId='help-cursor'
	activationConditions={{
		events: [Hotkey.H], // Press 'H' instead of 'Q'
		mode: ActivationMode.TOGGLE,
	}}
/>;
```

### Hold Mode

Use hold mode for temporary activation:

```tsx
<QuestioningSpell
	activationConditions={{
		events: [Hotkey.SHIFT],
		mode: ActivationMode.HOLD, // Active only while holding Shift
	}}
/>
```

### Multiple Triggers

Support multiple activation methods:

```tsx
<QuestioningSpell
	activationConditions={{
		events: [Hotkey.Q, 'alt+h', 'f1'],
		mode: ActivationMode.TOGGLE,
	}}
/>
```

## Advanced Examples

### Educational Interface

Create an educational UI with detailed explanations:

```tsx
function MathLesson() {
	return (
		<>
			<QuestioningSpell />

			<div className='lesson'>
				<h2>Quadratic Formula</h2>

				<div className='formula'>
					<span data-question="The coefficient 'a' represents the quadratic term">
						a
					</span>
					<span>xÂ²</span>
					<span> + </span>
					<span data-question="The coefficient 'b' represents the linear term">
						b
					</span>
					<span>x</span>
					<span> + </span>
					<span data-question="The coefficient 'c' is the constant term">
						c
					</span>
					<span> = 0</span>
				</div>

				<div
					className='solution'
					data-question='This formula finds the x-values where the parabola crosses the x-axis'>
					x = (-b Â± âˆš(bÂ² - 4ac)) / 2a
				</div>
			</div>
		</>
	);
}
```

### Dashboard with Metrics

Add context to complex data visualizations:

```tsx
function Dashboard() {
	return (
		<>
			<QuestioningSpell />

			<div className='grid grid-cols-3 gap-4'>
				<div
					className='metric-card'
					data-question='Revenue from the last 30 days compared to the previous period'>
					<h3>Monthly Revenue</h3>
					<p className='text-2xl'>$45,231</p>
					<span className='text-green-500'>+12.5%</span>
				</div>

				<div
					className='metric-card'
					data-question='Average time users spend on the platform per session'>
					<h3>Avg. Session Duration</h3>
					<p className='text-2xl'>8m 34s</p>
					<span className='text-red-500'>-5.2%</span>
				</div>

				<div
					className='metric-card'
					data-question='Percentage of users who completed the onboarding flow'>
					<h3>Onboarding Completion</h3>
					<p className='text-2xl'>73%</p>
					<span className='text-green-500'>+8.1%</span>
				</div>
			</div>
		</>
	);
}
```

### Form with Field Help

Provide inline help for form fields:

```tsx
function RegistrationForm() {
	return (
		<>
			<QuestioningSpell />

			<form className='space-y-4'>
				<div>
					<label
						htmlFor='username'
						data-question='Choose a unique username between 3-20 characters. This will be your public identifier.'>
						Username *
					</label>
					<input id='username' type='text' />
				</div>

				<div>
					<label
						htmlFor='email'
						data-question="We'll use this email for account recovery and important notifications only.">
						Email Address *
					</label>
					<input id='email' type='email' />
				</div>

				<div>
					<label
						htmlFor='timezone'
						data-question='Your timezone helps us schedule notifications and display times correctly.'>
						Timezone
					</label>
					<select id='timezone'>
						<option>Select timezone...</option>
					</select>
				</div>

				<button
					type='submit'
					data-question="Submit the form to create your account. You'll receive a confirmation email.">
					Create Account
				</button>
			</form>
		</>
	);
}
```

### Dynamic Questions

Generate questions based on data:

```tsx
function ProductList({ products }) {
	return (
		<>
			<QuestioningSpell />

			<div className='grid grid-cols-4 gap-4'>
				{products.map((product) => (
					<div
						key={product.id}
						className='product-card'
						data-question={`${product.name}: ${product.description}. In stock: ${product.stock} units. Rating: ${product.rating}/5`}>
						<img src={product.image} alt={product.name} />
						<h3>{product.name}</h3>
						<p>${product.price}</p>
					</div>
				))}
			</div>
		</>
	);
}
```

## Visual Behavior

### Cursor States

The questioning cursor has two visual states:

1. **Searching State**: Continuously rotating reticle when not hovering over a target
2. **Locked State**: Snaps to nearest 180Â° and scales slightly when hovering over an element with `data-question`

### Animation Details

* **Rotation Speed**: 3 seconds per full rotation when searching
* **Lock Animation**: Spring animation with bounce when locking onto target
* **Debounce**: 200ms delay before releasing lock to prevent flicker

### Theme Integration

The cursor automatically uses Cedar's theme colors:

* Uses `styling.color` from Cedar store for the reticle color
* Falls back to `#3b82f6` (blue) if no color is set
* Tooltip background matches the theme color

## Best Practices

### 1. Write Clear Explanations

```tsx
// âœ… Good: Specific and helpful
data-question="This button saves your draft and creates a backup. Auto-save happens every 5 minutes."

// âŒ Avoid: Vague or redundant
data-question="This is a button"
```

### 2. Keep Tooltips Concise

```tsx
// âœ… Good: Brief but informative
data-question="Shows revenue trends for the last 90 days"

// âŒ Avoid: Too lengthy
data-question="This chart displays the revenue trends for your organization over the last 90 days, including daily, weekly, and monthly breakdowns with comparison to previous periods..."
```

### 3. Add Context Where Needed

```tsx
// âœ… Good: Explains non-obvious functionality
<Icon
  name="shield"
  data-question="Protected by 256-bit encryption"
/>

// âŒ Unnecessary: Obvious elements
<button data-question="Click to submit">
  Submit
</button>
```

### 4. Use for Progressive Disclosure

```tsx
// Show basic info in UI, details in question
<div className='status-badge'>
	<span>Processing</span>
	<Icon
		name='info'
		data-question="Your request is in the queue. Estimated time: 2-3 minutes. You'll receive an email when complete."
	/>
</div>
```

## Technical Implementation

### How It Works

1. **Activation**: User presses 'Q' (or custom key) to activate
2. **Event Listening**: Listens to mousemove events when active
3. **Element Detection**: Uses `Element.closest('[data-question]')` to find attributes
4. **Tooltip Display**: Shows tooltip with the attribute value
5. **Cursor Enhancement**: Uses motion-plus-react for smooth cursor animations

### Performance Considerations

* **Event Delegation**: Single mousemove listener for all elements
* **Debounced Animations**: Prevents excessive re-renders
* **Conditional Rendering**: Only renders when spell is active
* **Ref-based State**: Uses refs for animation values to avoid re-renders

## Styling

### Custom Tooltip Styles

While the component provides a default tooltip, you can customize it:

```css
/* Override default tooltip styles */
.questioning-tooltip {
	background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
	backdrop-filter: blur(10px);
	border: 1px solid rgba(255, 255, 255, 0.2);
}
```

### Cursor Customization

The cursor consists of corner brackets that form a reticle:

```tsx
// Corner dimensions (defined in component)
const thickness = 2; // Line thickness
const length = 10; // Line length
const size = 38; // Overall reticle size
```

## Accessibility

### Keyboard Navigation

* The spell can be activated via keyboard (default: 'Q')
* Consider providing alternative ways to access the same information

### Screen Reader Support

For better accessibility, consider also providing the information in screen-reader accessible ways:

```tsx
<button
	data-question='Saves your work'
	aria-label='Save your work'
	title='Save your work'>
	Save
</button>
```

### Alternative Access

Provide multiple ways to access help information:

```tsx
function AccessibleHelp() {
	const [showHelp, setShowHelp] = useState(false);

	return (
		<>
			<QuestioningSpell />

			{/* Visual indicator that help is available */}
			<button onClick={() => setShowHelp(!showHelp)}>Toggle Help Mode</button>

			{/* Alternative help display */}
			{showHelp && <HelpPanel />}
		</>
	);
}
```

## Troubleshooting

### Tooltip not appearing

* Verify `data-question` attribute is set correctly
* Check that the spell is activated (press 'Q')
* Ensure QuestioningSpell component is mounted

### Cursor not changing

* Check motion-plus-react is installed and configured
* Verify no CSS conflicts with cursor styles
* Ensure spell activation is working

### Performance issues

* Reduce the number of elements with `data-question` if excessive
* Consider lazy-loading content with many questionable elements
* Check for memory leaks in tooltip content generation

## Related Components

* [RadialMenuSpell](/spells/radial-menu) - Circular menu for actions
* [TooltipMenuSpell](/spells/tooltip-menu) - Context menu for text selections
* [Creating Custom Spells](/spells/creating-custom-spells) - Build your own spell components


# Radial Menu Spell
Source: https://docs.cedarcopilot.com/spells/radial-menu

A circular context menu that appears around the cursor for quick actions

# Radial Menu Spell

The `RadialMenuSpell` component creates a beautiful circular menu that appears at the cursor position, perfect for providing quick contextual actions. It features smooth animations, visual feedback, and supports both keyboard and mouse activation.

<img src="https://vrhlhwfhghqbpdpfnpdq.supabase.co/storage/v1/object/public/logos//radialMenu.gif" alt="Radial Menu Demo" />

## Features

* **Circular Layout**: Items arranged in a circle for equal access
* **Visual Feedback**: Animated hover states and selection indicators
* **Cancel Zone**: Center area for canceling without action
* **Flexible Activation**: Supports keyboard shortcuts and mouse events
* **Hold-to-Select**: Natural interaction pattern for quick actions
* **Escape Support**: Press ESC to cancel without executing
* **Theme Integration**: Adapts to Cedar's light/dark mode
* **Icon Support**: Use emojis or Lucide icons for menu items

## Installation

```tsx
import { RadialMenuSpell } from 'cedar-os-components/spells';
```

## Basic Usage

```tsx
import {
	RadialMenuSpell,
	type RadialMenuItem,
} from 'cedar-os-components/spells';
import { MouseEvent, ActivationMode } from 'cedar-os';
import { Copy, Trash, Edit, Share } from 'lucide-react';

function MyComponent() {
	const menuItems: RadialMenuItem[] = [
		{
			title: 'Copy',
			icon: Copy,
			onInvoke: (store) => {
				// Access Cedar store for actions
				console.log('Copy action');
			},
		},
		{
			title: 'Edit',
			icon: Edit,
			onInvoke: (store) => {
				console.log('Edit action');
			},
		},
		{
			title: 'Share',
			icon: Share,
			onInvoke: (store) => {
				console.log('Share action');
			},
		},
		{
			title: 'Delete',
			icon: Trash,
			onInvoke: (store) => {
				console.log('Delete action');
			},
		},
	];

	return (
		<RadialMenuSpell
			spellId='my-radial-menu'
			items={menuItems}
			activationConditions={{
				events: [MouseEvent.RIGHT_CLICK],
				mode: ActivationMode.HOLD,
			}}
		/>
	);
}
```

## Props

### RadialMenuSpell Props

| Prop                   | Type                   | Required | Description                               |
| ---------------------- | ---------------------- | -------- | ----------------------------------------- |
| `spellId`              | `string`               | Yes      | Unique identifier for this spell instance |
| `items`                | `RadialMenuItem[]`     | Yes      | Array of menu items to display            |
| `activationConditions` | `ActivationConditions` | Yes      | Conditions that trigger the menu          |

### RadialMenuItem Interface

```tsx
interface RadialMenuItem {
	/** Display title (shown in center on hover) */
	title: string;

	/** Emoji string or Lucide icon component */
	icon: string | LucideIcon;

	/** Callback when item is selected */
	onInvoke: (store: CedarStore) => void;
}
```

## Activation Patterns

### Hold Pattern (Recommended)

The most natural interaction for radial menus is the hold pattern:

```tsx
activationConditions={{
  events: [MouseEvent.RIGHT_CLICK],
  mode: ActivationMode.HOLD
}}
```

**User flow:**

1. Right-click and hold to open menu
2. Move mouse to desired item (it highlights)
3. Release to execute action
4. Or move to center and release to cancel

### Toggle Pattern

For persistent menus that stay open:

```tsx
activationConditions={{
  events: [Hotkey.SPACE],
  mode: ActivationMode.TOGGLE
}}
```

**User flow:**

1. Press Space to open menu
2. Move mouse to select item
3. Click to execute or press Space again to close

### Keyboard Shortcut

Bind to any keyboard shortcut:

```tsx
activationConditions={{
  events: ['ctrl+e', 'cmd+e'],
  mode: ActivationMode.HOLD
}}
```

## Advanced Examples

### AI Actions Menu

Create an AI-powered context menu:

```tsx
import { Sparkles, Brain, Wand2, Zap } from 'lucide-react';

const aiMenuItems: RadialMenuItem[] = [
	{
		title: 'Explain',
		icon: Brain,
		onInvoke: async (store) => {
			const selection = window.getSelection()?.toString();
			if (selection) {
				await store.sendMessage({
					content: `Explain this: ${selection}`,
					role: 'user',
				});
			}
		},
	},
	{
		title: 'Improve',
		icon: Sparkles,
		onInvoke: async (store) => {
			const selection = window.getSelection()?.toString();
			if (selection) {
				await store.sendMessage({
					content: `Improve this text: ${selection}`,
					role: 'user',
				});
			}
		},
	},
	{
		title: 'Summarize',
		icon: Zap,
		onInvoke: async (store) => {
			await store.sendMessage({
				content: 'Summarize the current conversation',
				role: 'user',
			});
		},
	},
	{
		title: 'Generate',
		icon: Wand2,
		onInvoke: (store) => {
			// Open generation dialog
			store.setSpellActive('generation-dialog', true);
		},
	},
];
```

### Emoji-Based Menu

Use emojis for a playful interface:

```tsx
const emojiMenuItems: RadialMenuItem[] = [
	{
		title: 'Love it!',
		icon: 'â¤ï¸',
		onInvoke: (store) => {
			// Add reaction
		},
	},
	{
		title: 'Celebrate',
		icon: 'ðŸŽ‰',
		onInvoke: (store) => {
			// Trigger celebration
		},
	},
	{
		title: 'Question',
		icon: 'â“',
		onInvoke: (store) => {
			// Ask for clarification
		},
	},
	{
		title: 'Bookmark',
		icon: 'ðŸ“Œ',
		onInvoke: (store) => {
			// Save for later
		},
	},
];
```

### Dynamic Menu Items

Generate menu items based on context:

```tsx
function ContextualRadialMenu({ selectedElement }) {
	const menuItems = useMemo(() => {
		const items: RadialMenuItem[] = [];

		if (selectedElement?.type === 'image') {
			items.push({
				title: 'Download',
				icon: Download,
				onInvoke: () => downloadImage(selectedElement),
			});
			items.push({
				title: 'Edit',
				icon: Edit,
				onInvoke: () => openImageEditor(selectedElement),
			});
		}

		if (selectedElement?.type === 'text') {
			items.push({
				title: 'Copy',
				icon: Copy,
				onInvoke: () => copyToClipboard(selectedElement.content),
			});
		}

		// Add common items
		items.push({
			title: 'Share',
			icon: Share,
			onInvoke: () => shareContent(selectedElement),
		});

		return items;
	}, [selectedElement]);

	return (
		<RadialMenuSpell
			spellId='contextual-menu'
			items={menuItems}
			activationConditions={{
				events: [MouseEvent.RIGHT_CLICK],
				mode: ActivationMode.HOLD,
			}}
		/>
	);
}
```

## Visual Customization

The radial menu automatically adapts to Cedar's styling system:

### Theme Integration

The component uses Cedar's styling context:

* **Brand Color**: Used for hover states and selection
* **Dark Mode**: Automatically adjusts colors and contrasts
* **Text Colors**: Adapts based on theme

### Layout Constants

The component uses these layout constants (defined in the component):

```tsx
const MENU_RADIUS = 100; // Radius of the menu circle
const INNER_RADIUS = 50; // Cancel zone radius
const INNER_GAP = 4; // Gap between zones
const OUTER_PADDING = 10; // Outer padding
const BORDER_STROKE_WIDTH = 8; // Ring thickness
```

## Interaction Details

### Mouse Behavior

* **Hover**: Moving mouse over items highlights them
* **Center Zone**: Moving to center shows "Cancel"
* **Selection**: Release (hold mode) or click (toggle mode) to select
* **Visual Feedback**: Animated ring shows current selection

### Keyboard Support

* **ESC**: Cancel without executing any action
* **Activation Keys**: Defined by `activationConditions`

### Position Handling

* **Mouse Events**: Menu appears at cursor position
* **Keyboard Events**: Menu appears at viewport center
* **Smart Positioning**: Stays within viewport bounds

## Best Practices

### 1. Limit Item Count

Keep menus focused with 3-8 items:

```tsx
// âœ… Good: Focused set of actions
const items = [
	{ title: 'Edit', icon: Edit, onInvoke: handleEdit },
	{ title: 'Share', icon: Share, onInvoke: handleShare },
	{ title: 'Delete', icon: Trash, onInvoke: handleDelete },
];

// âŒ Avoid: Too many items
const items = [
	/* 12+ items */
]; // Hard to navigate quickly
```

### 2. Use Clear Icons

Choose recognizable icons:

```tsx
// âœ… Good: Clear, standard icons
{
	icon: Copy;
} // Universal copy icon
{
	icon: 'ðŸ“‹';
} // Clear emoji

// âŒ Avoid: Ambiguous icons
{
	icon: Circle;
} // What does this do?
{
	icon: 'ðŸ”®';
} // Unclear meaning
```

### 3. Consistent Actions

Keep `onInvoke` callbacks focused:

```tsx
// âœ… Good: Single responsibility
onInvoke: (store) => {
	const data = prepareData();
	store.sendMessage({ content: data, role: 'user' });
};

// âŒ Avoid: Multiple unrelated actions
onInvoke: (store) => {
	updateUI();
	saveToDatabase();
	sendAnalytics();
	showNotification();
};
```

### 4. Handle Errors Gracefully

```tsx
onInvoke: async (store) => {
	try {
		await performAction();
	} catch (error) {
		store.addMessage({
			content: 'Action failed. Please try again.',
			role: 'system',
		});
	}
};
```

## Accessibility Considerations

While the radial menu is primarily a visual component, consider these accessibility aspects:

1. **Alternative Activation**: Provide keyboard shortcuts as alternatives
2. **Clear Labels**: Use descriptive titles for screen readers
3. **Escape Route**: Always allow ESC key to cancel
4. **Visual Contrast**: The component respects Cedar's theme for proper contrast

## Performance Notes

* **Singleton Management**: Uses Cedar's spell system for efficient event handling
* **Animation Performance**: Uses CSS transforms for smooth animations
* **Memory Efficient**: Automatically cleaned up when component unmounts
* **Event Delegation**: Single set of listeners for all instances

## Common Patterns

### Tool Selection Menu

```tsx
const tools = [
	{ title: 'Select', icon: MousePointer },
	{ title: 'Draw', icon: Pencil },
	{ title: 'Erase', icon: Eraser },
	{ title: 'Text', icon: Type },
];
```

### Navigation Menu

```tsx
const navigation = [
	{ title: 'Home', icon: Home },
	{ title: 'Search', icon: Search },
	{ title: 'Settings', icon: Settings },
	{ title: 'Profile', icon: User },
];
```

### Media Controls

```tsx
const mediaControls = [
	{ title: 'Play', icon: Play },
	{ title: 'Pause', icon: Pause },
	{ title: 'Next', icon: SkipForward },
	{ title: 'Previous', icon: SkipBack },
];
```

## Troubleshooting

### Menu doesn't appear

* Check that the spell ID is unique
* Verify activation conditions are correct
* Ensure component is mounted

### Items not executing

* Verify `onInvoke` callbacks are defined
* Check for errors in callback functions
* Ensure Cedar store is accessible

### Visual issues

* Component adapts to Cedar's theme automatically
* Check that Cedar styling context is provided
* Verify Container3D component is available

## Related Components

* [TooltipMenuSpell](/spells/tooltip-menu) - Linear menu for text selections
* [QuestioningSpell](/spells/questioning-spell) - Interactive cursor for exploration
* [Creating Custom Spells](/spells/creating-custom-spells) - Build your own spell components


# Slider Spell
Source: https://docs.cedarcopilot.com/spells/slider-spell

A horizontal slider interface that appears at the cursor for precise value adjustments

# Slider Spell

The `SliderSpell` component creates an interactive horizontal slider that appears at the cursor position, perfect for making precise numerical adjustments. It features smooth mouse-based control, customizable ranges, and integrates seamlessly with Cedar's hold-mode activation pattern.

## Features

* **Mouse-Driven Control**: Horizontal mouse movement directly controls slider value
* **Hold Mode Integration**: Activates on key/mouse hold, executes on release
* **Customizable Ranges**: Configure min, max, step, and units
* **Visual Feedback**: Real-time value display above slider thumb
* **Smart Positioning**: Appears above cursor, centered horizontally
* **Theme Integration**: Adapts to Cedar's light/dark mode
* **Smooth Animations**: Container3D styling with smooth transitions

## Installation

```tsx
import { SliderSpell } from 'cedar-os-components/spells';
```

## Basic Usage

```tsx
import { SliderSpell } from 'cedar-os-components/spells';
import { ActivationMode } from 'cedar-os';

function MyComponent() {
	const handleSliderComplete = (value: number, store: CedarStore) => {
		console.log('Selected value:', value);
		// Use the value in your application
		updateOpacity(value / 100);
	};

	return (
		<SliderSpell
			spellId='opacity-slider'
			sliderConfig={{
				min: 0,
				max: 100,
				step: 1,
				unit: '%',
				label: 'Opacity',
			}}
			activationConditions={{
				events: ['o'],
				mode: ActivationMode.HOLD,
			}}
			onComplete={handleSliderComplete}
		/>
	);
}
```

**Usage:** Hold 'O' key and move mouse horizontally to adjust opacity from 0-100%.

## Props

### SliderSpell Props

| Prop                   | Type                     | Required | Description                               |
| ---------------------- | ------------------------ | -------- | ----------------------------------------- |
| `spellId`              | `string`                 | Yes      | Unique identifier for this spell instance |
| `sliderConfig`         | `SliderConfig`           | No       | Configuration for the slider              |
| `onComplete`           | `(value, store) => void` | Yes      | Callback when value is confirmed          |
| `activationConditions` | `ActivationConditions`   | Yes      | Conditions that trigger the slider        |

### SliderConfig Interface

```tsx
interface SliderConfig {
	/** Minimum value for the slider (default: 0) */
	min?: number;

	/** Maximum value for the slider (default: 100) */
	max?: number;

	/** Step increment for the slider (default: 1) */
	step?: number;

	/** Label to display below the slider (optional) */
	label?: string;

	/** Unit to display after the value (default: '%') */
	unit?: string;
}
```

## Hold Mode Pattern

The SliderSpell is designed for hold-mode interaction, providing natural and efficient value selection:

```tsx
activationConditions={{
  events: ['s'],
  mode: ActivationMode.HOLD
}}
```

**User flow:**

1. Hold key (or right-click) to activate slider
2. Move mouse horizontally to adjust value
3. Release to confirm selection and execute callback
4. Press ESC while holding to cancel

## Advanced Examples

### Volume Control

Create a volume slider with audio feedback:

```tsx
const volumeSlider = (
	<SliderSpell
		spellId='volume-control'
		sliderConfig={{
			min: 0,
			max: 100,
			step: 5,
			unit: '%',
			label: 'Volume',
		}}
		activationConditions={{
			events: ['v'],
			mode: ActivationMode.HOLD,
		}}
		onComplete={(value, store) => {
			// Update audio volume
			const audio = document.querySelector('audio');
			if (audio) {
				audio.volume = value / 100;
			}

			// Store in preferences
			localStorage.setItem('volume', value.toString());

			// Optional: Show confirmation
			store.addMessage({
				content: `Volume set to ${value}%`,
				role: 'system',
			});
		}}
	/>
);
```

### Color Opacity Adjuster

Adjust transparency for design tools:

```tsx
const opacitySlider = (
	<SliderSpell
		spellId='opacity-adjuster'
		sliderConfig={{
			min: 0,
			max: 255,
			step: 1,
			unit: '',
			label: 'Alpha Channel',
		}}
		activationConditions={{
			events: ['a', 'right-click'],
			mode: ActivationMode.HOLD,
		}}
		onComplete={(value, store) => {
			// Update selected element opacity
			const selectedElement = document.querySelector('.selected');
			if (selectedElement) {
				selectedElement.style.opacity = (value / 255).toString();
			}

			// Update design state
			store.setCedarState('selectedOpacity', value);
		}}
	/>
);
```

### Temperature Sensor Reading

For scientific or IoT applications:

```tsx
const temperatureSlider = (
	<SliderSpell
		spellId='temperature-setter'
		sliderConfig={{
			min: -20,
			max: 40,
			step: 0.5,
			unit: 'Â°C',
			label: 'Target Temperature',
		}}
		activationConditions={{
			events: ['t'],
			mode: ActivationMode.HOLD,
		}}
		onComplete={async (value, store) => {
			try {
				// Send to IoT device
				await fetch('/api/thermostat', {
					method: 'POST',
					body: JSON.stringify({ targetTemp: value }),
				});

				// Confirm with AI assistant
				await store.sendMessage({
					content: `Set thermostat to ${value}Â°C`,
					role: 'user',
				});
			} catch (error) {
				console.error('Failed to set temperature:', error);
			}
		}}
	/>
);
```

### Multiple Sliders System

Coordinate multiple sliders for complex adjustments:

```tsx
function ColorAdjustmentSystem() {
	const [currentColor, setCurrentColor] = useState({ r: 128, g: 128, b: 128 });

	const updateColorChannel =
		(channel: 'r' | 'g' | 'b') => (value: number, store: CedarStore) => {
			const newColor = { ...currentColor, [channel]: value };
			setCurrentColor(newColor);

			// Apply to selected element
			const element = document.querySelector('.color-target');
			if (element) {
				element.style.backgroundColor = `rgb(${newColor.r}, ${newColor.g}, ${newColor.b})`;
			}
		};

	return (
		<>
			{/* Red Channel */}
			<SliderSpell
				spellId='red-channel'
				sliderConfig={{ min: 0, max: 255, unit: '', label: 'Red' }}
				activationConditions={{ events: ['r'], mode: ActivationMode.HOLD }}
				onComplete={updateColorChannel('r')}
			/>

			{/* Green Channel */}
			<SliderSpell
				spellId='green-channel'
				sliderConfig={{ min: 0, max: 255, unit: '', label: 'Green' }}
				activationConditions={{ events: ['g'], mode: ActivationMode.HOLD }}
				onComplete={updateColorChannel('g')}
			/>

			{/* Blue Channel */}
			<SliderSpell
				spellId='blue-channel'
				sliderConfig={{ min: 0, max: 255, unit: '', label: 'Blue' }}
				activationConditions={{ events: ['b'], mode: ActivationMode.HOLD }}
				onComplete={updateColorChannel('b')}
			/>
		</>
	);
}
```

### Dynamic Range Slider

Adjust slider range based on context:

```tsx
function DynamicSlider({
	mode,
}: {
	mode: 'percentage' | 'pixels' | 'degrees';
}) {
	const sliderConfig = useMemo(() => {
		switch (mode) {
			case 'percentage':
				return { min: 0, max: 100, step: 1, unit: '%' };
			case 'pixels':
				return { min: 0, max: 1920, step: 1, unit: 'px' };
			case 'degrees':
				return { min: 0, max: 360, step: 1, unit: 'Â°' };
			default:
				return { min: 0, max: 100, step: 1, unit: '%' };
		}
	}, [mode]);

	return (
		<SliderSpell
			spellId={`dynamic-slider-${mode}`}
			sliderConfig={sliderConfig}
			activationConditions={{
				events: ['d'],
				mode: ActivationMode.HOLD,
			}}
			onComplete={(value, store) => {
				console.log(`${mode} value:`, value);
				// Handle based on current mode
			}}
		/>
	);
}
```

## Mouse Sensitivity

The slider uses a sensitivity system to map mouse movement to value changes:

```tsx
// Default sensitivity: 300 pixels for full range
const sensitivity = 300;
const valueRange = max - min;
const deltaValue = (mouseMovement / sensitivity) * valueRange;
```

### Customizing Sensitivity

While not directly configurable, you can adjust effective sensitivity by modifying your range:

```tsx
// More sensitive (smaller movements = bigger changes)
sliderConfig={{ min: 0, max: 10, step: 0.1 }}

// Less sensitive (larger movements needed)
sliderConfig={{ min: 0, max: 1000, step: 10 }}
```

## Visual Behavior

### Positioning

The slider appears above the cursor, centered horizontally:

* **Mouse Events**: Positioned at cursor location
* **Keyboard Events**: Positioned at viewport center
* **Above Cursor**: Positioned with 8px gap above cursor
* **Centered**: Horizontally centered on activation point

### Value Display

* **Real-time Updates**: Value shown above slider thumb
* **Unit Display**: Configured unit appears after value
* **Theme Adaptive**: Colors adapt to light/dark mode
* **Smooth Transitions**: No jarring animations, just smooth updates

### Styling Integration

The component uses Cedar's styling system:

* **Container3D**: 3D-styled slider track and thumb
* **Theme Colors**: Respects dark/light mode preferences
* **Consistent Typography**: Matches Cedar's text styling
* **Backdrop Blur**: Subtle backdrop blur for better visibility

## Interaction Details

### Mouse Control

* **Horizontal Movement**: Only horizontal mouse movement affects value
* **Relative Positioning**: Movement relative to activation point
* **Continuous Updates**: Value updates in real-time during movement
* **Clamping**: Values automatically clamped to min/max range
* **Step Snapping**: Values snap to configured step increments

### Keyboard Support

* **ESC**: Cancel slider without executing callback
* **Hold Pattern**: Must hold activation key throughout interaction
* **Release to Confirm**: Release key to execute callback with final value

### Edge Cases

* **Viewport Boundaries**: Slider stays within viewport bounds
* **Rapid Movement**: Handles fast mouse movements smoothly
* **Step Precision**: Ensures values align with step configuration

## Best Practices

### 1. Choose Appropriate Ranges

```tsx
// âœ… Good: Reasonable range for the use case
sliderConfig={{ min: 0, max: 100, step: 5 }} // Volume control

// âŒ Avoid: Excessive precision
sliderConfig={{ min: 0, max: 100, step: 0.001 }} // Too precise for UI
```

### 2. Use Meaningful Units

```tsx
// âœ… Good: Clear units
sliderConfig={{ unit: '%' }}   // Percentage
sliderConfig={{ unit: 'px' }}  // Pixels
sliderConfig={{ unit: 'Â°' }}   // Degrees

// âŒ Avoid: Ambiguous or missing units
sliderConfig={{ unit: '' }}    // What does this number mean?
```

### 3. Logical Key Bindings

```tsx
// âœ… Good: Mnemonic key bindings
events: ['v']; // Volume
events: ['o']; // Opacity
events: ['s']; // Size/Scale

// âŒ Avoid: Random key assignments
events: ['x']; // For volume control?
```

### 4. Handle Errors Gracefully

```tsx
onComplete: async (value, store) => {
	try {
		await updateSetting(value);
	} catch (error) {
		console.error('Update failed:', error);
		// Provide user feedback
		store.addMessage({
			content: 'Failed to update setting. Please try again.',
			role: 'system',
		});
	}
};
```

### 5. Provide Visual Context

```tsx
// Include labels for clarity
sliderConfig={{
  min: 0,
  max: 100,
  unit: '%',
  label: 'Volume' // Helps users understand what they're adjusting
}}
```

## Performance Considerations

### Efficient Updates

* **Throttled Rendering**: Value updates are smooth but not excessive
* **Ref-based State**: Uses refs to avoid unnecessary re-renders
* **Conditional Rendering**: Only renders when active
* **Memory Cleanup**: Automatically cleans up event listeners

### Event Handling

* **Single Listener**: Uses efficient event delegation
* **Debounced Actions**: Prevents spam during rapid movements
* **Optimized Calculations**: Minimal computation per mouse move

## Accessibility

### Keyboard Navigation

* The slider is primarily mouse-driven but keyboard accessible
* ESC key provides clear exit path
* Hold pattern is intuitive for keyboard users

### Screen Reader Support

Consider providing alternative interfaces for screen readers:

```tsx
// Provide aria-label context
<div aria-label={`Adjust ${label} from ${min} to ${max} ${unit}`}>
	<SliderSpell {...props} />
</div>
```

### Alternative Access

Provide multiple ways to adjust values:

```tsx
function AccessibleSlider() {
	return (
		<>
			<SliderSpell {...sliderProps} />

			{/* Alternative input for precise entry */}
			<input
				type='number'
				min={min}
				max={max}
				step={step}
				aria-label='Precise value entry'
			/>
		</>
	);
}
```

## Common Patterns

### Media Controls

```tsx
// Volume, playback speed, seek position
const mediaSliders = [
	{ key: 'v', label: 'Volume', min: 0, max: 100, unit: '%' },
	{ key: 's', label: 'Speed', min: 0.25, max: 2, unit: 'x', step: 0.25 },
	{ key: 't', label: 'Position', min: 0, max: duration, unit: 's' },
];
```

### Design Tools

```tsx
// Size, opacity, rotation, spacing
const designSliders = [
	{ key: 'w', label: 'Width', min: 10, max: 500, unit: 'px' },
	{ key: 'h', label: 'Height', min: 10, max: 500, unit: 'px' },
	{ key: 'a', label: 'Alpha', min: 0, max: 255, unit: '' },
	{ key: 'r', label: 'Rotation', min: 0, max: 360, unit: 'Â°' },
];
```

### Scientific Instruments

```tsx
// Temperature, pressure, flow rate
const instrumentSliders = [
	{ key: 't', label: 'Temperature', min: -273, max: 1000, unit: 'Â°C' },
	{ key: 'p', label: 'Pressure', min: 0, max: 10, unit: 'bar' },
	{ key: 'f', label: 'Flow Rate', min: 0, max: 100, unit: 'L/min' },
];
```

## Troubleshooting

### Slider not appearing

* Check that spell ID is unique
* Verify activation conditions are correct
* Ensure component is mounted
* Check for conflicting event handlers

### Values not updating

* Verify mouse movement is being detected
* Check min/max/step configuration
* Ensure onComplete callback is defined
* Check for JavaScript errors

### Position issues

* Verify cursor position detection
* Check for CSS transforms on parent elements
* Ensure proper z-index for visibility
* Check viewport boundary calculations

### Performance problems

* Reduce update frequency if needed
* Check for memory leaks in callbacks
* Verify event listeners are cleaned up
* Monitor re-render frequency

## Related Components

* [RadialMenuSpell](/spells/radial-menu) - Circular menu for multiple actions
* [TooltipMenuSpell](/spells/tooltip-menu) - Context menu for text selections
* [QuestioningSpell](/spells/questioning-spell) - Interactive cursor for exploration
* [Creating Custom Spells](/spells/creating-custom-spells) - Build your own spell components


# Spell Architecture
Source: https://docs.cedarcopilot.com/spells/spell-architecture

Understanding the technical architecture behind Cedar-OS spells

# Spell Architecture

This guide provides a deep dive into the technical architecture of Cedar-OS's spell system, explaining how spells work under the hood and how the various components interact.

## Architecture Overview

The spell system consists of three main components working in harmony:

```mermaid
graph TD
    A[useSpell Hook] --> B[SpellSlice]
    B --> C[SpellActivationManager]
    C --> D[DOM Event Listeners]
    B --> E[Cedar Store]

    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
```

1. **useSpell Hook** - React interface for components
2. **SpellSlice** - State management and coordination
3. **SpellActivationManager** - Event handling and routing

## Component Deep Dive

### 1. SpellActivationManager

The `SpellActivationManager` is a singleton class that manages all low-level event handling for spells. It's the bridge between DOM events and spell activations.

#### Key Responsibilities

* **Centralized Event Listening**: Maintains a single set of event listeners for all spells
* **Event Routing**: Routes events to the appropriate registered spells
* **Activation Logic**: Handles different activation modes (toggle, hold, trigger)
* **Performance Optimization**: Prevents duplicate listeners and manages cleanup

#### How It Works

```tsx
class SpellActivationManager {
	// Singleton pattern ensures one instance
	private static instance: SpellActivationManager;

	// Map of spell IDs to their configurations
	private registrations = new Map<string, SpellRegistration>();

	// Bound event handlers for proper cleanup
	private boundHandlers = {
		keydown: this.handleKeyDown.bind(this),
		keyup: this.handleKeyUp.bind(this),
		// ... other handlers
	};
}
```

The manager listens to various DOM events and processes them:

1. **Event Detection**: Captures keyboard, mouse, and selection events
2. **Spell Matching**: Checks which registered spells should respond
3. **State Management**: Tracks held keys, cooldowns, and active states
4. **Callback Execution**: Triggers appropriate spell callbacks

#### Event Processing Flow

```mermaid
sequenceDiagram
    participant User
    participant DOM
    participant Manager
    participant Spell

    User->>DOM: Presses key
    DOM->>Manager: keydown event
    Manager->>Manager: Check registrations
    Manager->>Manager: Match conditions
    Manager->>Spell: onActivate()
    Manager->>Manager: Update state
```

### 2. SpellSlice

The `SpellSlice` is a Zustand store slice that provides high-level spell management and integrates with Cedar's state system.

#### Core State Structure

```tsx
interface SpellSlice {
	// Map of spell configurations and states
	spells: Partial<SpellMap>;

	// Registration and management methods
	registerSpell: (registration: SpellRegistration) => void;
	unregisterSpell: (spellId: string) => void;
	activateSpell: (spellId: string, triggerData?: any) => void;
	deactivateSpell: (spellId: string) => void;
	toggleSpell: (spellId: string) => void;
	clearSpells: () => void;
}
```

#### Integration Points

The SpellSlice acts as the coordination layer:

1. **Store Integration**: Provides access to Cedar store for spell callbacks
2. **Lifecycle Management**: Handles spell registration/unregistration
3. **State Synchronization**: Keeps UI state in sync with activation manager
4. **Programmatic Control**: Enables manual spell activation/deactivation

#### Registration Flow

When a spell is registered:

```tsx
registerSpell: (registration) => {
	// 1. Add to store state
	set((state) => ({
		spells: {
			...state.spells,
			[id]: { isActive: false, registration },
		},
	}));

	// 2. Register with activation manager
	manager.register(id, conditions, {
		onActivate: (state) => {
			// Update store state
			// Call user callback
		},
		onDeactivate: () => {
			// Update store state
			// Call user callback
		},
	});
};
```

### 3. useSpell Hook

The `useSpell` hook provides the React-friendly interface for components to use spells.

#### Hook Lifecycle

```tsx
function useSpell(options: UseSpellOptions) {
  // 1. Get store methods
  const { registerSpell, unregisterSpell, ... } = useSpells();

  // 2. Use refs for callbacks to avoid re-registration
  const onActivateRef = useRef(options.onActivate);
  const onDeactivateRef = useRef(options.onDeactivate);

  // 3. Register on mount, re-register on condition changes
  useEffect(() => {
    registerSpell({
      id: options.id,
      activationConditions: options.activationConditions,
      onActivate: (state) => onActivateRef.current?.(state),
      onDeactivate: () => onDeactivateRef.current?.()
    });

    // 4. Cleanup on unmount
    return () => {
      unregisterSpell(options.id);
    };
  }, [/* dependencies */]);

  // 5. Return current state and controls
  return { isActive, activate, deactivate, toggle };
}
```

#### Performance Optimizations

* **Ref-based Callbacks**: Prevents unnecessary re-registrations
* **Dependency Tracking**: Only re-registers when conditions change
* **Automatic Cleanup**: Ensures no memory leaks

## Activation Modes Explained

### Toggle Mode

```mermaid
stateDiagram-v2
    [*] --> Inactive
    Inactive --> Active: Trigger Event
    Active --> Inactive: Trigger Event
```

* User presses key/button â†’ spell activates
* User presses again â†’ spell deactivates
* Good for persistent UI elements

### Hold Mode

```mermaid
stateDiagram-v2
    [*] --> Inactive
    Inactive --> Active: Key/Button Down
    Active --> Inactive: Key/Button Up
```

* Activates on keydown/mousedown
* Deactivates on keyup/mouseup
* Perfect for temporary overlays

### Trigger Mode

```mermaid
stateDiagram-v2
    [*] --> Ready
    Ready --> Activated: Trigger Event
    Activated --> Cooldown: Auto-deactivate
    Cooldown --> Ready: Timer expires
```

* Fires once when triggered
* Auto-deactivates after brief period
* Optional cooldown prevents spam

## Event Processing Details

### Keyboard Event Handling

The system handles both single keys and combinations:

```tsx
private matchesHotkey(event: KeyboardEvent, hotkey: string): boolean {
  if (hotkey.includes('+')) {
    // Combination like "ctrl+k"
    const combo = this.parseHotkeyCombo(hotkey);
    return event.key === combo.key &&
           event.ctrlKey === combo.modifiers.ctrl &&
           event.metaKey === combo.modifiers.meta;
  } else {
    // Single key - no unexpected modifiers
    return event.key.toLowerCase() === hotkey.toLowerCase() &&
           !event.ctrlKey && !event.metaKey && !event.altKey;
  }
}
```

### Mouse Event Handling

Mouse events include position tracking:

```tsx
private handleContextMenu(event: MouseEvent): void {
  for (const registration of this.registrations.values()) {
    if (mouseEvents.includes(RIGHT_CLICK)) {
      this.activateSpell(registration, {
        type: 'mouse',
        event: RIGHT_CLICK,
        mousePosition: { x: event.clientX, y: event.clientY },
        originalEvent: event
      });
    }
  }
}
```

### Selection Event Handling

Text selection is debounced for performance:

```tsx
private handleSelectionChange(): void {
  // Clear previous timeout
  if (this.selectionTimeout) {
    clearTimeout(this.selectionTimeout);
  }

  // Debounce selection events
  this.selectionTimeout = setTimeout(() => {
    const selection = window.getSelection();
    const selectedText = selection?.toString().trim();

    if (selectedText && selectedText.length > 0) {
      // Activate selection-based spells
    }
  }, 200); // 200ms debounce
}
```

## Performance Considerations

### Event Listener Management

The system uses a single set of listeners for all spells:

```tsx
// âœ… Efficient: One listener for all spells
window.addEventListener('keydown', this.boundHandlers.keydown);

// âŒ Inefficient: Listener per spell
spells.forEach((spell) => {
	window.addEventListener('keydown', spell.handler);
});
```

### Memory Management

* **Singleton Pattern**: One manager instance for entire app
* **Automatic Cleanup**: Listeners removed when no spells registered
* **Ref-based Callbacks**: Prevents closure memory leaks

### React Integration

The hook optimizes React re-renders:

```tsx
// Dependencies are stringified for deep comparison
useEffect(() => {
  registerSpell({...});
}, [
  options.id,
  JSON.stringify(options.activationConditions), // Deep comparison
  options.preventDefaultEvents,
  options.ignoreInputElements
]);
```

## Advanced Features

### Input Element Handling

Spells can be configured to ignore input elements:

```tsx
private isInputElement(target: EventTarget | null): boolean {
  if (!ignoreInputElements) return false;
  return target.closest('input, textarea, [contenteditable="true"]') !== null;
}
```

### Cooldown System

Prevents rapid re-triggering:

```tsx
if (mode === ActivationMode.TRIGGER) {
	const now = Date.now();
	if (now - registration.lastTriggerTime < cooldown) {
		return; // Still on cooldown
	}
	registration.lastTriggerTime = now;
}
```

### Multi-Event Support

Spells can respond to multiple triggers:

```tsx
activationConditions: {
	events: [Hotkey.SPACE, MouseEvent.RIGHT_CLICK, 'ctrl+enter'];
}
// Any of these will activate the spell
```

## Data Flow Diagram

```mermaid
graph LR
    subgraph "Component Layer"
        A[React Component]
        B[useSpell Hook]
    end

    subgraph "State Layer"
        C[SpellSlice]
        D[Cedar Store]
    end

    subgraph "Event Layer"
        E[SpellActivationManager]
        F[DOM Events]
    end

    A --> B
    B --> C
    C --> E
    E --> F
    C --> D

    F -.-> E
    E -.-> C
    C -.-> B
    B -.-> A

    style A fill:#e3f2fd
    style B fill:#e1f5fe
    style C fill:#fff3e0
    style D fill:#fce4ec
    style E fill:#f3e5f5
    style F fill:#e8f5e9
```

## Best Practices for Performance

### 1. Use Appropriate Activation Modes

```tsx
// Hold mode for temporary UI
mode: ActivationMode.HOLD; // Auto-cleanup on release

// Toggle for persistent features
mode: ActivationMode.TOGGLE; // User controls lifecycle

// Trigger for one-time actions
mode: ActivationMode.TRIGGER; // Auto-cleanup after execution
```

### 2. Optimize Spell IDs

```tsx
// Use stable IDs to prevent re-registration
const SPELL_ID = 'my-feature-spell'; // Constant

// Avoid dynamic IDs that change
const spellId = `spell-${Date.now()}`; // âŒ Changes every render
```

### 3. Leverage Refs for Callbacks

```tsx
// The hook already does this, but for custom implementations:
const callbackRef = useRef(callback);
useEffect(() => {
	callbackRef.current = callback;
}, [callback]);
```

### 4. Consider Event Delegation

For many similar spells, consider a single parent spell:

```tsx
// Instead of 100 tooltip spells
items.map(item => <TooltipSpell key={item.id} />)

// Use one spell with delegation
<TooltipManagerSpell items={items} />
```

## Debugging Spells

### Enable Debug Logging

```tsx
const { isActive } = useSpell({
	id: 'debug-spell',
	onActivate: (state) => {
		console.log('Spell activated:', {
			triggerData: state.triggerData,
			timestamp: Date.now(),
		});
	},
});
```

### Monitor Registration

```tsx
// Check registered spells in Cedar store
const { spells } = useCedarStore();
console.log('Active spells:', Object.keys(spells));
```

### Track Event Flow

Add logging to understand event propagation:

```tsx
onActivate: (state) => {
	console.log('Trigger:', state.triggerData?.event);
	console.log('Mouse position:', state.triggerData?.mousePosition);
	console.log('Original event:', state.triggerData?.originalEvent);
};
```

## Summary

The spell architecture provides a robust, performant system for gesture-based interactions:

* **Centralized Management**: Single manager handles all events efficiently
* **React Integration**: Hooks provide clean component interface
* **State Synchronization**: Zustand slice keeps everything in sync
* **Performance Optimized**: Singleton pattern, ref-based callbacks, debouncing
* **Flexible Activation**: Multiple modes and event types supported

This architecture ensures spells are both powerful for developers and performant for users, enabling truly magical interactions in your Cedar-OS applications.


# Spells Overview
Source: https://docs.cedarcopilot.com/spells/spells

Magical interactions for your Cedar-OS applications

# Spells

Spells are Cedar-OS's powerful system for creating contextual, gesture-based interactions that enhance your AI-native applications. They provide a unified way to bind keyboard shortcuts, mouse gestures, and selection events to custom UI behaviors and actions.

## What are Spells?

Spells are reusable interaction patterns that can be activated through various triggers:

* **Keyboard shortcuts** (single keys or combinations like `Ctrl+K`)
* **Mouse events** (right-click, double-click, modifier+click)
* **Text selection** (automatically activate when text is selected)
* **Programmatic activation** (trigger spells from code using `activate()`, `deactivate()`, or `toggle()`)

When activated, spells can display custom UI components, execute actions, or modify application state - all while integrating seamlessly with Cedar's AI capabilities.

<img src="https://vrhlhwfhghqbpdpfnpdq.supabase.co/storage/v1/object/public/logos//radialMenu.gif" alt="Radial Menu Demo" />

## Why Use Spells?

Spells enable you to create sophisticated interactions that feel magical to users:

* **Contextual Actions**: Display radial menus, tooltips, or floating inputs exactly when and where users need them
* **Rapid Workflows**: Bind complex AI operations to simple gestures
* **Progressive Disclosure**: Hide advanced features behind intuitive activations
* **Custom Experiences**: Build unique interaction patterns tailored to your application

## Built-in Spells

Cedar-OS comes with several pre-built spells you can use immediately:

### RadialMenuSpell

A circular menu that appears on activation, perfect for quick actions:

* Activate with right-click or custom hotkey
* Supports emoji or Lucide icons
* Execute actions on release (hold mode) or click (toggle mode)

### TooltipMenuSpell

A contextual menu for text selections:

* Automatically appears when text is selected
* Can spawn floating inputs for AI interactions
* Perfect for text editing and annotation workflows

### QuestioningSpell

An interactive cursor that reveals hidden information:

* Press 'Q' to activate questioning mode
* Hover over elements with `data-question` attributes
* Display contextual tooltips with explanations

## Quick Start

```tsx
import { useSpell, Hotkey, ActivationMode } from 'cedar-os';

function MyComponent() {
	const { isActive, activate, deactivate, toggle } = useSpell({
		id: 'my-spell',
		activationConditions: {
			events: [Hotkey.SPACE],
			mode: ActivationMode.HOLD,
		},
		onActivate: () => console.log('Spell activated!'),
		onDeactivate: () => console.log('Spell deactivated!'),
	});

	// You can also trigger spells programmatically
	const handleButtonClick = () => {
		toggle(); // or activate() / deactivate()
	};

	return (
		<>
			{isActive ? <div>âœ¨ Magic is happening!</div> : null}
			<button onClick={handleButtonClick}>Toggle Spell</button>
		</>
	);
}
```

## Learn More

<CardGroup cols={2}>
  <Card title="Creating Custom Spells" icon="code" href="/spells/creating-custom-spells">
    Learn how to build your own spells using the useSpell hook and activation
    conditions
  </Card>

  <Card title="Spell Architecture" icon="sitemap" href="/spells/spell-architecture">
    Understand the technical architecture behind the spell system
  </Card>

  <Card title="Radial Menu Example" icon="circle" href="/spells/radial-menu">
    Deep dive into the RadialMenuSpell implementation
  </Card>

  <Card title="Examples & Patterns" icon="sparkles" href="/examples/cedar-playground#spells">
    See spells in action in the Cedar Playground
  </Card>
</CardGroup>

## Key Concepts

### Activation Modes

Spells support three activation modes that determine their lifecycle:

* **Toggle**: Press to activate, press again to deactivate
* **Hold**: Active while key/button is held down
* **Trigger**: Fire once with optional cooldown

### Event Types

Spells can respond to multiple event types simultaneously:

* **Keyboard Events**: Single keys or modifier combinations
* **Mouse Events**: Clicks, right-clicks, double-clicks
* **Selection Events**: Text selection in the document

### State Management

Spells are fully integrated with Cedar's state management:

* Automatic registration/cleanup with React lifecycle
* Access to Cedar store for AI operations
* Synchronization with other Cedar components

## Next Steps

Ready to add some magic to your application? Start by [creating your first custom spell](/spells/creating-custom-spells) or explore the [technical architecture](/spells/spell-architecture) to understand how it all works under the hood.


# Tooltip Menu Spell
Source: https://docs.cedarcopilot.com/spells/tooltip-menu

A contextual menu that appears when text is selected

# Tooltip Menu Spell

The `TooltipMenuSpell` component creates a contextual menu that automatically appears when text is selected, perfect for text editing, AI-powered transformations, and quick actions on selected content. It can also spawn floating input fields for more complex interactions.

## Features

* **Automatic Text Selection Detection**: Appears when text is selected
* **Smart Positioning**: Positions above selection, adjusts to stay on screen
* **Floating Input Support**: Can spawn input fields for complex queries
* **AI Integration**: Direct access to Cedar store for AI operations
* **Selection Preservation**: Maintains text selection during interactions
* **Flexible Actions**: Support for immediate actions or input-based workflows

## Installation

```tsx
import { TooltipMenuSpell } from 'cedar-os-components/spells';
```

## Basic Usage

```tsx
import {
	TooltipMenuSpell,
	type ExtendedTooltipMenuItem,
} from 'cedar-os-components/spells';
import { Copy, Edit, Sparkles } from 'lucide-react';

function MyEditor() {
	const menuItems: ExtendedTooltipMenuItem[] = [
		{
			title: 'Copy',
			icon: Copy,
			onInvoke: (store) => {
				const selection = window.getSelection()?.toString();
				if (selection) {
					navigator.clipboard.writeText(selection);
				}
			},
		},
		{
			title: 'Improve',
			icon: Sparkles,
			onInvoke: async (store) => {
				const selection = window.getSelection()?.toString();
				if (selection) {
					await store.sendMessage({
						content: `Improve this text: ${selection}`,
						role: 'user',
					});
				}
			},
		},
		{
			title: 'Ask AI',
			icon: Edit,
			spawnsInput: true, // This will open a floating input
			onInvoke: () => {}, // Not called when spawnsInput is true
		},
	];

	return (
		<>
			<TooltipMenuSpell spellId='text-menu' items={menuItems} />

			<div className='prose'>
				<p>Select any text in this paragraph to see the tooltip menu appear.</p>
				<p>The menu provides quick actions for the selected text.</p>
			</div>
		</>
	);
}
```

## Props

### TooltipMenuSpell Props

| Prop                   | Type                        | Required | Default        | Description                                 |
| ---------------------- | --------------------------- | -------- | -------------- | ------------------------------------------- |
| `spellId`              | `string`                    | Yes      | -              | Unique identifier for this spell instance   |
| `items`                | `ExtendedTooltipMenuItem[]` | Yes      | -              | Menu items to display                       |
| `activationConditions` | `ActivationConditions`      | No       | Text selection | Custom activation conditions                |
| `stream`               | `boolean`                   | No       | `true`         | Whether to use streaming for floating input |

### ExtendedTooltipMenuItem Interface

```tsx
interface ExtendedTooltipMenuItem extends TooltipMenuItem {
	/** Display title */
	title: string;

	/** Lucide icon component */
	icon: LucideIcon;

	/** Callback when item is clicked */
	onInvoke: (store: CedarStore) => void;

	/** If true, spawns floating input instead of immediate action */
	spawnsInput?: boolean;
}
```

## Advanced Examples

### AI Writing Assistant

Create a comprehensive writing assistant:

```tsx
import { Bold, Italic, Sparkles, Languages, BookOpen, Zap } from 'lucide-react';

const writingAssistantItems: ExtendedTooltipMenuItem[] = [
	{
		title: 'Improve',
		icon: Sparkles,
		onInvoke: async (store) => {
			const text = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Improve this text while maintaining its meaning: ${text}`,
				role: 'user',
			});
		},
	},
	{
		title: 'Simplify',
		icon: Zap,
		onInvoke: async (store) => {
			const text = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Simplify this text for better readability: ${text}`,
				role: 'user',
			});
		},
	},
	{
		title: 'Translate',
		icon: Languages,
		spawnsInput: true, // Opens input for target language
	},
	{
		title: 'Expand',
		icon: BookOpen,
		onInvoke: async (store) => {
			const text = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Expand on this idea with more detail: ${text}`,
				role: 'user',
			});
		},
	},
	{
		title: 'Make Bold',
		icon: Bold,
		onInvoke: () => {
			document.execCommand('bold', false);
		},
	},
	{
		title: 'Custom',
		icon: Edit,
		spawnsInput: true, // Opens input for custom instructions
	},
];

<TooltipMenuSpell spellId='writing-assistant' items={writingAssistantItems} />;
```

### Code Editor Actions

Add code-specific actions:

```tsx
import { Code, Bug, Lightbulb, FileText, Copy, Play } from 'lucide-react';

const codeEditorItems: ExtendedTooltipMenuItem[] = [
	{
		title: 'Explain',
		icon: Lightbulb,
		onInvoke: async (store) => {
			const code = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Explain this code:\n\`\`\`\n${code}\n\`\`\``,
				role: 'user',
			});
		},
	},
	{
		title: 'Find Bugs',
		icon: Bug,
		onInvoke: async (store) => {
			const code = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Find potential bugs in this code:\n\`\`\`\n${code}\n\`\`\``,
				role: 'user',
			});
		},
	},
	{
		title: 'Add Comments',
		icon: FileText,
		onInvoke: async (store) => {
			const code = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Add helpful comments to this code:\n\`\`\`\n${code}\n\`\`\``,
				role: 'user',
			});
		},
	},
	{
		title: 'Optimize',
		icon: Zap,
		onInvoke: async (store) => {
			const code = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Optimize this code for performance:\n\`\`\`\n${code}\n\`\`\``,
				role: 'user',
			});
		},
	},
	{
		title: 'Copy',
		icon: Copy,
		onInvoke: () => {
			const code = window.getSelection()?.toString();
			if (code) navigator.clipboard.writeText(code);
		},
	},
	{
		title: 'Run',
		icon: Play,
		spawnsInput: true, // Opens input for runtime parameters
	},
];
```

### Research Assistant

Help with research and fact-checking:

```tsx
import { Search, BookOpen, Quote, Link, CheckCircle } from 'lucide-react';

const researchItems: ExtendedTooltipMenuItem[] = [
	{
		title: 'Fact Check',
		icon: CheckCircle,
		onInvoke: async (store) => {
			const claim = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Fact-check this claim and provide sources: "${claim}"`,
				role: 'user',
			});
		},
	},
	{
		title: 'Find Sources',
		icon: Search,
		onInvoke: async (store) => {
			const topic = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Find reputable sources about: ${topic}`,
				role: 'user',
			});
		},
	},
	{
		title: 'Summarize',
		icon: BookOpen,
		onInvoke: async (store) => {
			const text = window.getSelection()?.toString();
			await store.sendMessage({
				content: `Summarize this text in 2-3 sentences: ${text}`,
				role: 'user',
			});
		},
	},
	{
		title: 'Generate Citation',
		icon: Quote,
		spawnsInput: true, // Opens input for citation style (APA, MLA, etc.)
	},
	{
		title: 'Related Topics',
		icon: Link,
		onInvoke: async (store) => {
			const topic = window.getSelection()?.toString();
			await store.sendMessage({
				content: `What are related topics to explore about: ${topic}`,
				role: 'user',
			});
		},
	},
];
```

### Dynamic Menu Items

Generate menu items based on context:

```tsx
function ContextualTooltipMenu() {
	const [documentType, setDocumentType] = useState('general');

	const menuItems = useMemo(() => {
		const baseItems: ExtendedTooltipMenuItem[] = [
			{
				title: 'Copy',
				icon: Copy,
				onInvoke: () => {
					navigator.clipboard.writeText(
						window.getSelection()?.toString() || ''
					);
				},
			},
		];

		if (documentType === 'legal') {
			baseItems.push({
				title: 'Define Term',
				icon: Book,
				onInvoke: async (store) => {
					const term = window.getSelection()?.toString();
					await store.sendMessage({
						content: `Define this legal term: ${term}`,
						role: 'user',
					});
				},
			});
		}

		if (documentType === 'technical') {
			baseItems.push({
				title: 'Explain Concept',
				icon: Lightbulb,
				onInvoke: async (store) => {
					const concept = window.getSelection()?.toString();
					await store.sendMessage({
						content: `Explain this technical concept in simple terms: ${concept}`,
						role: 'user',
					});
				},
			});
		}

		return baseItems;
	}, [documentType]);

	return <TooltipMenuSpell spellId='contextual-menu' items={menuItems} />;
}
```

## Floating Input Integration

When an item has `spawnsInput: true`, it opens a floating input field:

### How It Works

1. User selects text
2. Tooltip menu appears
3. User clicks item with `spawnsInput: true`
4. Menu disappears, floating input appears
5. Selected text is automatically added to input
6. User can modify or add to the query
7. On submit, message is sent to Cedar store

### Example with Floating Input

```tsx
const translationItem: ExtendedTooltipMenuItem = {
	title: 'Translate',
	icon: Languages,
	spawnsInput: true, // This triggers floating input
	onInvoke: () => {}, // Not called when spawnsInput is true
};

// When user clicks this item:
// 1. Floating input appears
// 2. Selected text is pre-filled
// 3. User can type: "to Spanish"
// 4. Full query sent: "[selected text] to Spanish"
```

## Positioning Behavior

The tooltip menu intelligently positions itself:

1. **Default Position**: Above the selected text, centered
2. **Edge Detection**: Adjusts if too close to viewport edges
3. **Padding**: Maintains 10px minimum distance from edges
4. **Menu Dimensions**: Calculates based on item count (48px per item)

```tsx
// Position calculation (simplified)
const rect = selection.getRangeAt(0).getBoundingClientRect();
const position = {
	x: rect.left + rect.width / 2, // Center horizontally
	y: rect.top - 10, // 10px above selection
};
```

## Customization

### Custom Activation

While text selection is the default, you can customize activation:

```tsx
import { MouseEvent, Hotkey } from 'cedar-os';

<TooltipMenuSpell
	spellId='custom-menu'
	items={items}
	activationConditions={{
		events: [
			SelectionEvent.TEXT_SELECT,
			'ctrl+m', // Also activate with Ctrl+M
		],
		mode: ActivationMode.TOGGLE,
	}}
/>;
```

### Disable Streaming

For non-AI actions, disable streaming:

```tsx
<TooltipMenuSpell
	spellId='quick-actions'
	items={items}
	stream={false} // Disable streaming for floating input
/>
```

## Best Practices

### 1. Logical Item Order

Arrange items by frequency of use:

```tsx
// âœ… Good: Common actions first
const items = [
  { title: 'Copy', ... },      // Most common
  { title: 'Improve', ... },    // Frequently used
  { title: 'Translate', ... },  // Sometimes used
  { title: 'Custom', ... }      // Advanced option
];
```

### 2. Clear Icons

Use recognizable icons that match the action:

```tsx
// âœ… Good: Clear icon-action relationship
{ title: 'Copy', icon: Copy }
{ title: 'Translate', icon: Languages }
{ title: 'Search', icon: Search }

// âŒ Avoid: Ambiguous icons
{ title: 'Process', icon: Circle }
{ title: 'Action', icon: Square }
```

### 3. Preserve Selection

Don't clear selection unnecessarily:

```tsx
// âœ… Good: Preserve selection for potential follow-up
onInvoke: async (store) => {
  const text = window.getSelection()?.toString();
  // Don't clear selection here
  await store.sendMessage({...});
}

// âŒ Avoid: Clearing selection prematurely
onInvoke: async (store) => {
  window.getSelection()?.removeAllRanges(); // Too early!
  // User might want to perform another action
}
```

### 4. Handle Edge Cases

Always check for valid selection:

```tsx
onInvoke: async (store) => {
  const selection = window.getSelection()?.toString();

  if (!selection || selection.trim().length === 0) {
    // Handle empty selection gracefully
    return;
  }

  // Process valid selection
  await store.sendMessage({...});
}
```

## Technical Details

### Selection Management

The component maintains selection state using refs:

```tsx
const selectionRangeRef = useRef<Range | null>(null);
const selectedTextRef = useRef<string>('');

// Stores selection when menu appears
selectionRangeRef.current = range.cloneRange();
selectedTextRef.current = selection.toString();
```

### Event Handling

* **Text Selection**: Detected via `SelectionEvent.TEXT_SELECT`
* **Position Calculation**: Based on selection bounding rect
* **Menu Dismissal**: Click outside or press ESC
* **Selection Preservation**: Maintained until action completes

### Performance

* **Debounced Selection**: Prevents excessive re-renders
* **Conditional Rendering**: Only renders when active
* **Ref-based State**: Avoids unnecessary re-renders
* **Lazy Input Creation**: Floating input created on demand

## Accessibility

### Keyboard Support

* Text selection via keyboard works normally
* Menu items should be keyboard navigable
* ESC key closes menu and floating input

### Screen Reader Considerations

```tsx
// Provide aria-labels for actions
const accessibleItems: ExtendedTooltipMenuItem[] = [
	{
		title: 'Copy',
		icon: Copy,
		onInvoke: () => {
			// Announce action to screen readers
			const announcement = document.createElement('div');
			announcement.setAttribute('role', 'status');
			announcement.setAttribute('aria-live', 'polite');
			announcement.textContent = 'Text copied to clipboard';
			document.body.appendChild(announcement);
			setTimeout(() => announcement.remove(), 1000);

			navigator.clipboard.writeText(selection);
		},
	},
];
```

## Troubleshooting

### Menu not appearing

* Verify text selection is working
* Check that spell ID is unique
* Ensure component is mounted
* Verify no CSS `user-select: none` on text

### Position issues

* Check for CSS transforms on parent elements
* Verify viewport calculations
* Ensure menu has proper z-index

### Floating input issues

* Verify `spawnsInput` is set correctly
* Check Cedar store is accessible
* Ensure `setOverrideInputContent` is available

### Selection lost

* Check for conflicting event handlers
* Verify `preventDefaultEvents` setting
* Ensure no other components clear selection

## Related Components

* [RadialMenuSpell](/spells/radial-menu) - Circular menu for general actions
* [QuestioningSpell](/spells/questioning-spell) - Interactive cursor for exploration
* [Creating Custom Spells](/spells/creating-custom-spells) - Build your own spell components


# Agentic Actions
Source: https://docs.cedarcopilot.com/state-access/agentic-actions

Set up structured responses and interpret them as actions

Cedar enables your agent to not only read state but also execute actions through structured responses. This guide shows you how to set up an end-to-end flow where your agent can understand your application state and perform actions on it.

## Overview

The agentic actions flow consists of three main parts:

1. **Register State with Custom Setters** - Define what actions can be performed
2. **Configure Structured Responses** - Set up your agent to return structured data
3. **Handle LLM Results** - Process the structured responses and execute actions

## Complete Example: Product Roadmap

Let's walk through a complete example using a product roadmap application where the agent can add features, remove nodes, and manage diffs.

### Step 1: Register State with Custom Setters

First, register your state with custom setters that define the available actions:

```tsx
import { useRegisterState } from 'cedar-os';
import { Node } from 'reactflow';
import { z } from 'zod';

// Register nodes state with custom setters
useRegisterState({
	key: 'nodes',
	value: nodes,
	setValue: setNodes,
	description: 'Product roadmap nodes',
	customSetters: {
		addNode: {
			name: 'addNode',
			description: 'Add a new node to the roadmap',
			schema: z.object({
				node: z.object({
					data: z.object({
						title: z.string(),
						description: z.string(),
						status: z.enum(['done', 'planned', 'backlog', 'in progress']),
						nodeType: z.literal('feature').default('feature'),
					}),
				}),
			}),
			execute: (currentNodes, node) => {
				const newNode = {
					...node,
					id: node.id || uuidv4(),
					type: 'featureNode',
					position: { x: Math.random() * 400, y: Math.random() * 400 },
					data: {
						...node.data,
						nodeType: node.data.nodeType || 'feature',
						status: node.data.status || 'planned',
						upvotes: node.data.upvotes || 0,
						comments: node.data.comments || [],
						diff: 'added' as const,
					},
				};
				setNodes([...currentNodes, newNode]);
			},
		},
		removeNode: {
			name: 'removeNode',
			description: 'Remove a node from the roadmap',
			schema: z.object({
				id: z.string().describe('The ID of the node to remove'),
			}),
			execute: async (currentNodes, id) => {
				// Mark as removed with diff instead of immediate deletion
				setNodes(
					currentNodes.map((node) =>
						node.id === id
							? { ...node, data: { ...node.data, diff: 'removed' } }
							: node
					)
				);
			},
		},
		acceptAllDiffs: {
			name: 'acceptAllDiffs',
			description: 'Accept all pending diffs',
			schema: z.object({}),
			execute: async (currentNodes) => {
				const nodesWithDiffs = currentNodes.filter((n) => n.data.diff);

				// Process removals
				const removedNodeIds = nodesWithDiffs
					.filter((n) => n.data.diff === 'removed')
					.map((n) => n.id);

				for (const nodeId of removedNodeIds) {
					await deleteNode(nodeId);
				}

				// Update remaining nodes
				const remainingNodes = currentNodes.filter(
					(n) => !removedNodeIds.includes(n.id)
				);
				setNodes(
					remainingNodes.map((n) => ({
						...n,
						data: { ...n.data, diff: undefined },
					}))
				);
			},
		},
	},
});
```

### Step 2: Configure Your Agent for Structured Responses

Configure your agent backend to return structured responses. Here's an example using Mastra:

```typescript
// In your Mastra agent configuration
import { createTool } from '@mastra/core/tools';
import { z } from 'zod';

export const addFeatureTool = createTool({
	id: 'add-feature',
	description: 'Add a new feature to the product roadmap',
	inputSchema: z.object({
		title: z.string().describe('Title of the feature'),
		description: z.string().describe('Description of the feature'),
		status: z.enum(['done', 'planned', 'backlog', 'in progress']),
		nodeType: z.literal('feature').default('feature'),
	}),
	outputSchema: z.object({
		type: z.literal('setState'),
		stateKey: z.literal('nodes'),
		setterKey: z.literal('addNode'),
		args: z.array(z.any()),
	}),
	execute: async ({ context }) => {
		// Return structured response for Cedar to interpret
		return {
			type: 'setState',
			stateKey: 'nodes',
			setterKey: 'addNode',
			args: [
				{
					data: {
						title: context.title,
						description: context.description,
						status: context.status,
						nodeType: context.nodeType,
					},
				},
			],
		};
	},
});
```

### Step 3: Handle LLM Results

Cedar's `handleLLMResult` function automatically processes structured responses:

```typescript
// This is built into Cedar - showing for understanding
handleLLMResult: (response: LLMResponse) => {
	const state = get();

	// Check for structured output
	if (response.object && typeof response.object === 'object') {
		const structuredResponse = response.object;

		// Handle setState type responses
		if (structuredResponse.type === 'setState') {
			// Execute the custom setter with provided parameters
			state.executeCustomSetter(
				structuredResponse.stateKey,
				structuredResponse.setterKey,
				...structuredResponse.args
			);
			return; // Action executed, no message needed
		}
	}

	// Default: add response as message
	if (response.content) {
		state.addMessage({
			role: 'assistant',
			type: 'text',
			content: response.content,
		});
	}
};
```

> **Note**: This default handling can be customized using [Custom Response Processing](/agent-backend-connection/custom-response-processing#setstate-type). You can also customize how setState completion is displayed with [Custom Message Rendering](/chat/custom-message-rendering#setstate-type).

## Structured Response Types

Cedar supports different types of structured responses:

### SetState Type

Execute a custom setter on registered state:

```json
{
	"type": "setState",
	"stateKey": "nodes",
	"setterKey": "addNode",
	"args": [
		{
			/* node data */
		}
	]
}
```

> **Learn More**: See the complete [SetState Response Processing](/agent-backend-connection/custom-response-processing#setstate-type) documentation and [SetState Message Rendering](/chat/custom-message-rendering#setstate-type) guide for detailed information about customizing setState handling and display.

### Message Type

Add a custom message with specific role/content:

```json
{
	"type": "message",
	"role": "assistant",
	"content": "I've added the new feature to your roadmap."
}
```

## Using Actions in Your UI

You can trigger actions directly from your UI components:

```tsx
import { useCedarStore } from 'cedar-os';

function ActionButtons() {
	const executeCustomSetter = useCedarStore(
		(state) => state.executeCustomSetter
	);

	const handleAddFeature = () => {
		executeCustomSetter('nodes', 'addNode', {
			data: {
				title: 'New Feature',
				description: 'Describe your feature here',
				status: 'planned',
				nodeType: 'feature',
			},
		});
	};

	const handleAcceptAllDiffs = () => {
		executeCustomSetter('nodes', 'acceptAllDiffs');
	};

	return (
		<div className='flex gap-2'>
			<button onClick={handleAddFeature}>Add Feature</button>
			<button onClick={handleAcceptAllDiffs}>Accept All Changes</button>
		</div>
	);
}
```

## Best Practices

### 1. Use Descriptive Action Names

Make your setter names clear and action-oriented:

```tsx
// Good
customSetters: {
  addTodo: { /* ... */ },
  toggleTodoComplete: { /* ... */ },
  deleteTodo: { /* ... */ }
}

// Avoid
customSetters: {
  setter1: { /* ... */ },
  update: { /* ... */ },
  change: { /* ... */ }
}
```

### 2. Use Descriptive Schema Fields

Help your agent understand what parameters to provide using Zod's describe method:

```tsx
schema: z.object({
	priority: z
		.enum(['low', 'medium', 'high', 'critical'])
		.describe('Priority level: low, medium, high, or critical'),
});
```

### 3. Handle Errors Gracefully

Add error handling in your custom setters:

```tsx
execute: async (currentState, id) => {
	try {
		const item = currentState.find((item) => item.id === id);
		if (!item) {
			console.error(`Item with id ${id} not found`);
			return;
		}
		// Perform action
	} catch (error) {
		console.error('Failed to execute action:', error);
	}
};
```

### 4. Use Diff Patterns for Reversible Actions

Implement diff patterns for actions that users might want to review:

```tsx
execute: (currentNodes, nodeData) => {
	// Add with diff marker
	const newNode = {
		...nodeData,
		data: { ...nodeData.data, diff: 'added' },
	};
	setNodes([...currentNodes, newNode]);
};
```

## Advanced: Multi-Step Actions

For complex workflows, you can chain multiple actions:

```typescript
// Agent returns multiple actions
{
  "type": "multi-action",
  "actions": [
    {
      "type": "setState",
      "stateKey": "nodes",
      "setterKey": "addNode",
      "args": [/* node 1 */]
    },
    {
      "type": "setState",
      "stateKey": "edges",
      "setterKey": "connectNodes",
      "args": ["node1", "node2"]
    }
  ]
}
```

## Debugging Actions

Use Cedar's built-in debugging tools to monitor action execution:

```tsx
import { useCedarStore } from 'cedar-os';

// Enable debug mode to see all state changes
const debugMode = useCedarStore((state) => state.debugMode);

// View registered states and their setters
const registeredStates = useCedarStore((state) => state.registeredStates);
console.log('Available actions:', registeredStates);
```

## Automatic Schema Distribution

When you subscribe a state to input context using `useSubscribeStateToInputContext`, Cedar automatically includes both the state's schema (if defined) and the schemas of all custom setters for that state in the context sent to your agent. This enables your agent to understand both the data structure and what actions are available.

### Setter Schema Structure

The setter and state schemas are included in top-level `setters` and `schemas` fields alongside your subscribed state data:

```json
{
	"nodes": [
		// Your subscribed state data
	],
	"setters": {
		"addNode": {
			"name": "addNode",
			"stateKey": "nodes",
			"description": "Add a new node to the roadmap",
			"schema": {
				"type": "object",
				"properties": {
					"node": {
						"type": "object",
						"properties": {
							"data": {
								"type": "object",
								"properties": {
									"title": { "type": "string" },
									"description": { "type": "string" },
									"status": {
										"type": "string",
										"enum": ["done", "planned", "backlog", "in progress"]
									},
									"nodeType": { "type": "string", "default": "feature" }
								}
							}
						}
					}
				}
			}
		},
		"removeNode": {
			"name": "removeNode",
			"stateKey": "nodes",
			"description": "Remove a node from the roadmap",
			"schema": {
				"type": "object",
				"properties": {
					"id": {
						"type": "string",
						"description": "The ID of the node to remove"
					}
				}
			}
		}
	}
}
```

### Zod Schema Integration

Custom setters use Zod schemas to define parameter validation and provide rich type information to your agent. Cedar automatically converts Zod schemas to JSON Schema format using `zod-to-json-schema` and includes them in the context sent to your agent.

```tsx
// In your useRegisterState hook call
customSetters: {
  addNode: {
    name: 'addNode',
    description: 'Add a new node to the roadmap',
    schema: z.object({
      node: z.object({
        data: z.object({
          title: z.string().describe('Feature title'),
          description: z.string().describe('Detailed feature description'),
          status: z.enum(['done', 'planned', 'backlog', 'in progress']).describe('Current development status'),
          nodeType: z.literal('feature').default('feature').describe('Type of node')
        })
      })
    }),
    execute: (currentNodes, node) => {
      // Implementation with full type safety
    }
  }
}
```

This schema-based approach provides several benefits:

* **Type Safety**: Runtime validation of parameters
* **Rich Documentation**: Descriptive field information for agents
* **Automatic JSON Schema**: Converted format perfect for LLM understanding
* **Consistent API**: Single source of truth for parameter definitions

## Next Steps

* Learn about [State Access](/state-access/agentic-state-access) for more state management patterns
* Explore [Agent Input Context](/agent-input-context/agent-input-context) to provide context for actions
* See [Custom Message Rendering](/chat/custom-message-rendering) to display action results


# Agentic State
Source: https://docs.cedarcopilot.com/state-access/agentic-state-access



Cedar allows your agent to understand what is happening in your application, and the ability to change it. Registering a local state in Cedar is the first step to giving your agent frontend context, letting users point out parts of the UI to the agent, and letting agents manipulate state.

In other words, it allows your agent to read and write to the local react state.

To understand how we internally execute and render actions on your state (and how to override default behavior and rendering for state changes), read [SetState Response Processing](/agent-backend-connection/custom-response-processing#setstate-type) and [SetState Message Rendering](/chat/custom-message-rendering#setstate-type).

## useRegisterState Hook

Register your existing React state with Cedar using the `useRegisterState` hook:

<CodeGroup>
  ```tsx Example
  import { useRegisterState } from 'cedar-os';

  const [todos, setTodos] = useState([
  	{ id: 1, text: 'Learn Cedar-OS', completed: false },
  	{ id: 2, text: 'Build amazing AI apps', completed: false },
  ]);

  // Now the agent will know what the state is, how to change it,
  // and have access to calling these setters
  useRegisterState({
  	key: 'todos',
  	description: 'A list of todo items that users can check off',
  	value: todos,
  	setValue: setTodos,
  	customSetters: {
  		addTodo: {
  			name: 'addTodo',
  			description: 'Add a new todo item',
  			execute: (currentTodos, text: string) => {
  				const newTodo = {
  					id: Date.now(),
  					text,
  					completed: false,
  				};
  				setTodos([...currentTodos, newTodo]);
  			},
  		},
  		toggleTodo: {
  			name: 'toggleTodo',
  			description: 'Toggle completion status of a todo',
  			execute: (currentTodos, id: number) => {
  				setTodos(
  					currentTodos.map((todo) =>
  						todo.id === id ? { ...todo, completed: !todo.completed } : todo
  					)
  				);
  			},
  		},
  		removeTodo: {
  			name: 'removeTodo',
  			description: 'Remove a todo item',
  			execute: (currentTodos, id: number) => {
  				setTodos(currentTodos.filter((todo) => todo.id !== id));
  			},
  		},
  	},
  });
  ```

  ```tsx Type
  interface RegisterStateOptions<T> {
  	key: string;
  	description?: string;
  	value: T;
  	setValue?: (state: T, ...args: any[]) => void;
  	customSetters?: Record<string, Setter<T>>;
  	schema?: ZodSchema<T>; // Automatically included in agent input context as JSON Schema
  }

  interface Setter<T, Args extends unknown[] = unknown[]> {
  	name: string;
  	description: string;
  	schema?: ZodSchema;
  	execute: (state: T, ...args: Args) => void;
  }

  interface Todo {
  	id: number;
  	text: string;
  	completed: boolean;
  }
  ```
</CodeGroup>

### useCedarState

Use `useCedarState` to create and manage state directly in the Cedar store. It directly replaces useState and works the exact same way, but

<CodeGroup>
  ```tsx Example
  import { useCedarState } from 'cedar-os';

  function TodoComponent() {
  	const [todos, setTodos] = useCedarState(
  		'todos',
  		[
  			{ id: 1, text: 'Learn Cedar-OS', completed: false },
  			{ id: 2, text: 'Build amazing AI apps', completed: false },
  		],
  		'A list of todo items that users can check off',
  		{
  			addTodo: {
  				name: 'addTodo',
  				description: 'Add a new todo item',
  				execute: (currentTodos, text: string) => {
  					const newTodo = {
  						id: Date.now(),
  						text,
  						completed: false,
  					};
  					setTodos([...currentTodos, newTodo]);
  				},
  			},
  			toggleTodo: {
  				name: 'toggleTodo',
  				description: 'Toggle completion status of a todo',
  				execute: (currentTodos, id: number) => {
  					setTodos(
  						currentTodos.map((todo) =>
  							todo.id === id ? { ...todo, completed: !todo.completed } : todo
  						)
  					);
  				},
  			},
  			removeTodo: {
  				name: 'removeTodo',
  				description: 'Remove a todo item',
  				execute: (currentTodos, id: number) => {
  					setTodos(currentTodos.filter((todo) => todo.id !== id));
  				},
  			},
  		}
  	);

  	return (
  		<div>
  			<h2>My Todos</h2>
  			{todos.map((todo) => (
  				<div key={todo.id}>
  					<input
  						type='checkbox'
  						checked={todo.completed}
  						onChange={() => {
  							// You can call the setter directly or use custom setters
  							setTodos(
  								todos.map((t) =>
  									t.id === todo.id ? { ...t, completed: !t.completed } : t
  								)
  							);
  						}}
  					/>
  					<span>{todo.text}</span>
  					<button
  						onClick={() => {
  							setTodos(todos.filter((t) => t.id !== todo.id));
  						}}>
  						Delete
  					</button>
  				</div>
  			))}
  			<button
  				onClick={() => {
  					const newTodo = {
  						id: Date.now(),
  						text: 'New todo',
  						completed: false,
  					};
  					setTodos([...todos, newTodo]);
  				}}>
  				Add Todo
  			</button>
  		</div>
  	);
  }
  ```

  ```tsx Type
  function useCedarState<T>(
  	key: string,
  	initialValue: T,
  	description?: string,
  	customSetters?: Record<string, Setter<T>>,
  	schema?: ZodSchema<T>
  ): [T, (newValue: T) => void];
  ```
</CodeGroup>

## Accessing Cedar State Functions

### executeCustomSetter

Execute custom setter functions programmatically using the Cedar store:

<CodeGroup>
  ```tsx Example
  import { useCedarStore } from 'cedar-os';

  function TodoActions() {
  	const executeCustomSetter = useCedarStore(
  		(state) => state.executeCustomSetter
  	);

  	const handleAddTodo = async () => {
  		executeCustomSetter('todos', 'addTodo', 'Learn about Cedar State');
  	};

  	const handleToggleTodo = async () => {
  		executeCustomSetter('todos', 'toggleTodo', 1);
  	};

  	const handleRemoveTodo = async () => {
  		executeCustomSetter('todos', 'removeTodo', 1);
  	};

  	return (
  		<div>
  			<button onClick={handleAddTodo}>Add Todo</button>
  			<button onClick={handleToggleTodo}>Toggle First Todo</button>
  			<button onClick={handleRemoveTodo}>Remove First Todo</button>
  		</div>
  	);
  }
  ```

  ```tsx Type
  // Access through useCedarStore
  const executeCustomSetter = useCedarStore((state) => state.executeCustomSetter);

  // Function signature
  executeCustomSetter: (
  	key: string,
  	setterKey: string,
  	...args: unknown[]
  ) => void;
  ```
</CodeGroup>

> **Agent Actions**: Custom setters can be automatically invoked by your agent through structured responses. Learn more about [SetState Response Processing](/agent-backend-connection/custom-response-processing#setstate-type) and [SetState Message Rendering](/chat/custom-message-rendering#setstate-type) to see how agents can execute these setters and display the results.

## getCedarState

Retrieve the current state value for a registered Cedar state key:

<CodeGroup>
  ```tsx Example
  import { getCedarState } from 'cedar-os';

  // Get current todos state
  const currentTodos = getCedarState('todos');
  console.log('Current todos:', currentTodos);

  // Use in a function
  function logTodoCount() {
  	const todos = getCedarState('todos');
  	if (todos && Array.isArray(todos)) {
  		console.log(`You have ${todos.length} todos`);
  	}
  }

  // Check if state exists
  function checkTodosExist() {
  	const todos = getCedarState('todos');
  	if (todos) {
  		console.log('Todos state is available');
  	} else {
  		console.log('Todos state not found');
  	}
  }
  ```

  ```tsx Type
  function getCedarState(key: string): BasicStateValue | undefined;
  ```
</CodeGroup>

## setCedarState

Directly update the state value for a registered Cedar state key:

<CodeGroup>
  ```tsx Example
  import { setCedarState } from 'cedar-os';

  // Set new todos state
  const newTodos = [
  	{ id: 1, text: 'Updated todo', completed: true },
  	{ id: 2, text: 'Another todo', completed: false },
  ];
  setCedarState('todos', newTodos);

  // Update based on current state
  const currentTodos = getCedarState('todos');
  if (currentTodos && Array.isArray(currentTodos)) {
  	const updatedTodos = currentTodos.map((todo) => ({
  		...todo,
  		completed: true,
  	}));
  	setCedarState('todos', updatedTodos);
  }

  // Reset state
  setCedarState('todos', []);
  ```

  ```tsx Type
  function setCedarState<T>(key: string, value: T): void;
  ```
</CodeGroup>

## Exposing states to your agent

Now that your application states are registered in Cedar, learn how to expose just the right pieces of them to your agent:

* **Agent Input Context** â€“ orchestrate what context is sent alongside every user message, including state subscriptions and manual entries. See [Agent Input Context](/agent-input-context/agent-input-context).
* **Mentions** â€“ let users reference individual state items with simple `@` mentions. See [Mentions](/agent-input-context/mentions).

These docs walk you through granting the agent scoped, real-time access to your frontend data.


# Diff & History Manager (Beta)
Source: https://docs.cedarcopilot.com/state-access/diff-history-manager

AI should be creating diffs all the time, so we're tracking it

AI should be creating diffs all the time, so we're building a system to track and manage these changes.

## Coming Soon

Content for this section will be added in the next phase.


# Backend Integration
Source: https://docs.cedarcopilot.com/voice/agentic-backend

Setting up your backend to handle voice requests and responses

Cedar's voice system sends audio data to your backend for processing and expects either audio responses or structured JSON responses. This page covers how to implement the backend endpoint to handle voice interactions.

## Endpoint Configuration

### Automatic Configuration with Mastra

When using the Mastra provider, you can automatically configure the voice endpoint through the provider configuration:

```typescript
<CedarCopilot
	llmProvider={{
		provider: 'mastra',
		baseURL: 'http://localhost:3000/api',
		voiceRoute: '/chat/voice-execute', // Automatically sets voice endpoint to: http://localhost:3000/api/chat/voice-execute
	}}>
	<YourApp />
</CedarCopilot>
```

This eliminates the need to manually call `setVoiceEndpoint()` and ensures consistency between your chat and voice endpoints.

### Manual Configuration

For other providers or custom setups, configure the endpoint manually:

```typescript
const voice = useCedarStore((state) => state.voice);
voice.setVoiceEndpoint('https://your-backend.com/api/voice');
```

## Request Format

The voice system sends a `multipart/form-data` POST request to your configured endpoint with the following fields:

```typescript
FormData {
  audio: Blob,      // WebM format with Opus codec
  settings: string, // JSON string of voice settings
  context: string,  // JSON string of additional context
  // Additional dynamic parameters may be included
  // based on the specific voice request configuration
  // These params extend BaseParams that are sent to regular chat endpoints
}
```

### Audio Data

* **Format**: WebM container with Opus codec
* **Type**: Binary blob from MediaRecorder API
* **Quality**: Optimized for speech recognition

### Voice Settings

```typescript
{
  language: string;     // e.g., 'en-US'
  voiceId?: string;     // Optional voice ID for TTS
  pitch?: number;       // 0.5 to 2.0
  rate?: number;        // 0.5 to 2.0
  volume?: number;      // 0.0 to 1.0
  useBrowserTTS?: boolean;
  autoAddToMessages?: boolean;
}
```

### Additional Context

The context includes Cedar's additional context data (file contents, state information, etc.) that can be used to provide better responses.

## Response Formats

Your backend can respond in several ways:

### 1. Direct Audio Response

Return audio data directly with the appropriate content type:

```typescript
// Response headers
Content-Type: audio/mpeg
// or audio/wav, audio/ogg, etc.

// Response body: Raw audio data
```

### 2. JSON Response with Audio URL

```typescript
{
  "audioUrl": "https://example.com/response.mp3",
  "text": "Optional text transcript",
  "transcription": "What the user said"
}
```

### 3. JSON Response with Base64 Audio

```typescript
{
  "audioData": "base64-encoded-audio-data",
  "audioFormat": "mp3", // or "wav", "ogg"
  "text": "Response text",
  "transcription": "User input transcription"
}
```

### 4. Structured Response with Actions

```typescript
{
  "transcription": "Show me the user dashboard",
  "text": "I'll show you the user dashboard",
  "object": {
    "type": "setState",
    "stateKey": "ui",
    "setterKey": "navigateTo",
    "args": ["/dashboard"]
  },
  "audioUrl": "https://example.com/response.mp3"
}
```

## Implementation Examples

### Node.js with Express

```typescript
import express from 'express';
import multer from 'multer';
import OpenAI from 'openai';

const app = express();
const upload = multer();
const openai = new OpenAI();

app.post(
	'/api/chat/voice',
	upload.fields([
		{ name: 'audio', maxCount: 1 },
		{ name: 'settings', maxCount: 1 },
		{ name: 'context', maxCount: 1 },
	]),
	async (req, res) => {
		try {
			const audioFile = req.files.audio[0];
			const settings = JSON.parse(req.body.settings);
			const context = JSON.parse(req.body.context);

			// 1. Transcribe audio to text
			const transcription = await openai.audio.transcriptions.create({
				file: new File([audioFile.buffer], 'audio.webm', {
					type: 'audio/webm',
				}),
				model: 'whisper-1',
				language: settings.language?.split('-')[0] || 'en',
			});

			// 2. Process with your AI agent
			const messages = [
				{ role: 'system', content: 'You are a helpful assistant.' },
				{ role: 'user', content: transcription.text },
			];

			const completion = await openai.chat.completions.create({
				model: 'gpt-4',
				messages: messages,
			});

			const responseText = completion.choices[0].message.content;

			// 3. Convert response to speech
			const speech = await openai.audio.speech.create({
				model: 'tts-1',
				voice: settings.voiceId || 'alloy',
				input: responseText,
				speed: settings.rate || 1.0,
			});

			const audioBuffer = Buffer.from(await speech.arrayBuffer());

			// 4. Return audio response
			res.set({
				'Content-Type': 'audio/mpeg',
				'Content-Length': audioBuffer.length,
			});
			res.send(audioBuffer);
		} catch (error) {
			console.error('Voice processing error:', error);
			res.status(500).json({ error: 'Failed to process voice request' });
		}
	}
);
```

### Python with FastAPI

```python
from fastapi import FastAPI, File, Form, UploadFile
from fastapi.responses import Response
import openai
import json
import io

app = FastAPI()

@app.post("/api/chat/voice")
async def handle_voice(
    audio: UploadFile = File(...),
    settings: str = Form(...),
    context: str = Form(...)
):
    try:
        # Parse settings and context
        voice_settings = json.loads(settings)
        additional_context = json.loads(context)

        # Read audio data
        audio_data = await audio.read()

        # 1. Transcribe audio
        audio_file = io.BytesIO(audio_data)
        audio_file.name = "audio.webm"

        transcription = openai.Audio.transcribe(
            model="whisper-1",
            file=audio_file,
            language=voice_settings.get("language", "en")[:2]
        )

        # 2. Process with AI
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": transcription["text"]}
            ]
        )

        response_text = response.choices[0].message.content

        # 3. Generate speech
        speech_response = openai.Audio.speech.create(
            model="tts-1",
            voice=voice_settings.get("voiceId", "alloy"),
            input=response_text,
            speed=voice_settings.get("rate", 1.0)
        )

        # 4. Return audio
        return Response(
            content=speech_response.content,
            media_type="audio/mpeg"
        )

    except Exception as e:
        return {"error": str(e)}, 500
```

### Mastra Agent Integration

When using Cedar-OS with the Mastra provider and `voiceRoute` configuration, your Mastra backend should handle requests at the specified route. Here's how to implement the voice handler:

```typescript
import { Agent } from '@mastra/core';
import { openai } from '@mastra/openai';

const agent = new Agent({
	name: 'voice-assistant',
	instructions: 'You are a helpful voice assistant.',
	model: openai.gpt4o(),
});

export async function handleVoiceRequest(
	audioBlob: Blob,
	settings: VoiceSettings,
	context: string
) {
	// 1. Transcribe audio
	const transcription = await openai.audio.transcriptions.create({
		file: audioBlob,
		model: 'whisper-1',
		language: settings.language?.split('-')[0] || 'en',
	});

	// 2. Add context to the conversation
	const contextData = JSON.parse(context);
	const systemMessage = `Additional context: ${JSON.stringify(contextData)}`;

	// 3. Generate response with agent
	const response = await agent.generate([
		{ role: 'system', content: systemMessage },
		{ role: 'user', content: transcription.text },
	]);

	// 4. Convert to speech
	const speech = await openai.audio.speech.create({
		model: 'tts-1',
		voice: settings.voiceId || 'alloy',
		input: response.text,
		speed: settings.rate || 1.0,
	});

	return {
		transcription: transcription.text,
		text: response.text,
		audioData: await speech.arrayBuffer(),
		audioFormat: 'mp3',
	};
}

// Example Mastra route setup
// If you configured voiceRoute: '/chat/voice-execute' in Cedar-OS,
// your Mastra backend should handle POST requests to this route:

app.post(
	'/chat/voice-execute',
	upload.fields([
		{ name: 'audio', maxCount: 1 },
		{ name: 'settings', maxCount: 1 },
		{ name: 'context', maxCount: 1 },
	]),
	async (req, res) => {
		const audioFile = req.files.audio[0];
		const settings = JSON.parse(req.body.settings);
		const context = req.body.context;

		const result = await handleVoiceRequest(
			new Blob([audioFile.buffer]),
			settings,
			context
		);

		// Return the structured response
		res.json(result);
	}
);
```

## Error Handling

Your backend should handle various error cases:

```typescript
app.post('/api/chat/voice', async (req, res) => {
	try {
		// ... processing logic
	} catch (error) {
		console.error('Voice processing error:', error);

		// Return appropriate error response
		if (error.code === 'AUDIO_TRANSCRIPTION_FAILED') {
			return res.status(400).json({
				error: 'Could not understand the audio. Please try again.',
				code: 'TRANSCRIPTION_ERROR',
			});
		}

		if (error.code === 'TTS_FAILED') {
			return res.status(500).json({
				error: 'Failed to generate speech response.',
				code: 'TTS_ERROR',
				// Fallback to text-only response
				text: responseText,
				transcription: userInput,
			});
		}

		// Generic error
		res.status(500).json({
			error: 'Internal server error processing voice request',
			code: 'INTERNAL_ERROR',
		});
	}
});
```

## CORS Configuration

Ensure your backend allows CORS for the frontend domain:

```typescript
import cors from 'cors';

app.use(
	cors({
		origin: ['http://localhost:3000', 'https://your-app-domain.com'],
		methods: ['POST'],
		allowedHeaders: ['Content-Type', 'Authorization'],
	})
);
```

## Performance Considerations

### Audio Processing

* Use streaming transcription for real-time responses
* Implement audio compression to reduce bandwidth
* Cache TTS responses for common phrases

### Response Optimization

* Stream audio responses when possible
* Use CDN for serving generated audio files
* Implement request queuing for high-traffic scenarios

```typescript
// Example streaming response
app.post('/api/chat/voice-stream', async (req, res) => {
	res.writeHead(200, {
		'Content-Type': 'audio/mpeg',
		'Transfer-Encoding': 'chunked',
	});

	const audioStream = await generateAudioStream(transcription);

	audioStream.on('data', (chunk) => {
		res.write(chunk);
	});

	audioStream.on('end', () => {
		res.end();
	});
});
```

## Security Best Practices

1. **Rate Limiting**: Prevent abuse of voice endpoints
2. **Authentication**: Verify user permissions
3. **Input Validation**: Sanitize audio data and settings
4. **Content Filtering**: Screen transcriptions for inappropriate content

```typescript
import rateLimit from 'express-rate-limit';

const voiceRateLimit = rateLimit({
	windowMs: 15 * 60 * 1000, // 15 minutes
	max: 50, // 50 requests per window
	message: 'Too many voice requests, please try again later.',
});

app.post('/api/chat/voice', voiceRateLimit, handleVoiceRequest);
```

## Testing Your Integration

Test your voice endpoint with curl:

```bash
# Create test audio file
curl -X POST http://localhost:3456/api/chat/voice \
  -F "audio=@test-audio.webm" \
  -F "settings={\"language\":\"en-US\",\"rate\":1.0}" \
  -F "context={\"files\":[],\"state\":{}}" \
  -o response.mp3
```

Or use the Cedar voice system directly for end-to-end testing:

```typescript
// With Mastra provider (automatic configuration)
<CedarCopilot
	llmProvider={{
		provider: 'mastra',
		baseURL: 'http://localhost:3456/api',
		voiceRoute: '/chat/voice-execute',
	}}>
	<YourApp />
</CedarCopilot>;

// Or manually configure the endpoint
const voice = useCedarStore((state) => state.voice);
voice.setVoiceEndpoint('http://localhost:3456/api/chat/voice');
await voice.requestVoicePermission();
voice.startListening();
```


# Voice Components
Source: https://docs.cedarcopilot.com/voice/components

UI components for voice interactions including indicators, controls, and visualizations

Cedar provides pre-built React components for voice interactions, along with guidance for creating custom voice UI components. These components integrate seamlessly with the voice state management system.

## VoiceIndicator Component

The `VoiceIndicator` component provides visual feedback for voice states with smooth animations powered by Motion for React.

### Basic Usage

```typescript
import { VoiceIndicator } from '@cedar/voice';
import { useCedarStore } from '@cedar/core';

function MyVoiceApp() {
	const voice = useCedarStore((state) => state.voice);

	return (
		<div>
			<VoiceIndicator voiceState={voice} />
			{/* Your other components */}
		</div>
	);
}
```

### Component Features

* **Listening State**: Animated microphone icon with pulsing bars
* **Speaking State**: Animated speaker icon with scaling effect
* **Error State**: Alert icon with error message
* **Auto-hide**: Only shows when voice is active or there's an error

### Animation Details

The component uses Motion for React with optimized animations:

```typescript
// Listening animation - pulsing bars
{
	[0, 1, 2].map((i) => (
		<motion.div
			key={i}
			className='w-1 h-3 bg-red-500 rounded-full'
			animate={{
				scaleY: [1, 1.5, 1],
			}}
			transition={{
				duration: 0.5,
				repeat: Infinity,
				delay: i * 0.1,
			}}
		/>
	));
}

// Speaking animation - scaling effect
<motion.div
	className='w-4 h-4'
	animate={{
		scale: [1, 1.2, 1],
	}}
	transition={{
		duration: 0.8,
		repeat: Infinity,
	}}>
	<div className='w-full h-full bg-green-500 rounded-full opacity-30' />
</motion.div>;
```

## Custom Voice Button

Create a custom voice button with enhanced visual feedback:

```typescript
import React from 'react';
import { motion } from 'motion/react';
import { Mic, MicOff, Loader2 } from 'lucide-react';
import { useCedarStore } from '@cedar/core';

interface VoiceButtonProps {
	size?: 'small' | 'medium' | 'large';
	variant?: 'primary' | 'secondary' | 'outline';
	className?: string;
}

export const VoiceButton: React.FC<VoiceButtonProps> = ({
	size = 'medium',
	variant = 'primary',
	className = '',
}) => {
	const voice = useCedarStore((state) => state.voice);

	const handleClick = async () => {
		if (voice.voicePermissionStatus === 'prompt') {
			await voice.requestVoicePermission();
		}

		if (voice.voicePermissionStatus === 'granted') {
			voice.toggleVoice();
		}
	};

	const sizeClasses = {
		small: 'w-8 h-8',
		medium: 'w-12 h-12',
		large: 'w-16 h-16',
	};

	const variantClasses = {
		primary: 'bg-blue-500 hover:bg-blue-600 text-white',
		secondary: 'bg-gray-500 hover:bg-gray-600 text-white',
		outline: 'border-2 border-blue-500 text-blue-500 hover:bg-blue-50',
	};

	const isDisabled =
		voice.voicePermissionStatus === 'denied' ||
		voice.voicePermissionStatus === 'not-supported';

	return (
		<motion.button
			onClick={handleClick}
			disabled={isDisabled}
			className={`
        ${sizeClasses[size]}
        ${variantClasses[variant]}
        ${className}
        rounded-full flex items-center justify-center
        transition-colors duration-200
        disabled:opacity-50 disabled:cursor-not-allowed
        focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2
      `}
			whileHover={!isDisabled ? { scale: 1.05 } : {}}
			whileTap={!isDisabled ? { scale: 0.95 } : {}}
			animate={{
				backgroundColor: voice.isListening ? '#ef4444' : undefined,
			}}
			style={{ willChange: 'transform' }}>
			{voice.voicePermissionStatus === 'prompt' && (
				<Loader2 className='w-5 h-5 animate-spin' />
			)}

			{voice.voicePermissionStatus === 'granted' && (
				<>
					{voice.isListening ? (
						<motion.div
							initial={{ scale: 0 }}
							animate={{ scale: 1 }}
							transition={{ type: 'spring', stiffness: 500, damping: 30 }}>
							<MicOff className='w-5 h-5' />
						</motion.div>
					) : (
						<motion.div
							initial={{ scale: 0 }}
							animate={{ scale: 1 }}
							transition={{ type: 'spring', stiffness: 500, damping: 30 }}>
							<Mic className='w-5 h-5' />
						</motion.div>
					)}
				</>
			)}

			{voice.voicePermissionStatus === 'denied' && (
				<MicOff className='w-5 h-5 opacity-50' />
			)}
		</motion.button>
	);
};
```

## Voice Waveform Visualizer

Create an animated waveform visualizer for audio input:

```typescript
import React, { useEffect, useRef, useState } from 'react';
import { motion } from 'motion/react';
import { useCedarStore } from '@cedar/core';

interface VoiceWaveformProps {
	barCount?: number;
	height?: number;
	color?: string;
	className?: string;
}

export const VoiceWaveform: React.FC<VoiceWaveformProps> = ({
	barCount = 20,
	height = 40,
	color = '#3b82f6',
	className = '',
}) => {
	const voice = useCedarStore((state) => state.voice);
	const [audioData, setAudioData] = useState<number[]>([]);
	const analyserRef = useRef<AnalyserNode | null>(null);
	const animationRef = useRef<number>();

	useEffect(() => {
		if (voice.isListening && voice.audioContext && voice.audioStream) {
			// Create audio analyser
			const analyser = voice.audioContext.createAnalyser();
			const source = voice.audioContext.createMediaStreamSource(
				voice.audioStream
			);

			source.connect(analyser);
			analyser.fftSize = 256;

			const bufferLength = analyser.frequencyBinCount;
			const dataArray = new Uint8Array(bufferLength);

			analyserRef.current = analyser;

			const updateWaveform = () => {
				if (analyser) {
					analyser.getByteFrequencyData(dataArray);

					// Sample data for visualization
					const step = Math.floor(bufferLength / barCount);
					const samples = [];

					for (let i = 0; i < barCount; i++) {
						const sample = dataArray[i * step] || 0;
						samples.push(sample / 255); // Normalize to 0-1
					}

					setAudioData(samples);
				}

				if (voice.isListening) {
					animationRef.current = requestAnimationFrame(updateWaveform);
				}
			};

			updateWaveform();
		} else {
			// Reset when not listening
			setAudioData(new Array(barCount).fill(0));
			if (animationRef.current) {
				cancelAnimationFrame(animationRef.current);
			}
		}

		return () => {
			if (animationRef.current) {
				cancelAnimationFrame(animationRef.current);
			}
		};
	}, [voice.isListening, voice.audioContext, voice.audioStream, barCount]);

	return (
		<div
			className={`flex items-end justify-center gap-1 ${className}`}
			style={{ height: `${height}px` }}>
			{Array.from({ length: barCount }).map((_, index) => {
				const amplitude = audioData[index] || 0;
				const barHeight = Math.max(2, amplitude * height);

				return (
					<motion.div
						key={index}
						className='w-1 rounded-full'
						style={{
							backgroundColor: color,
							willChange: 'height',
						}}
						animate={{
							height: barHeight,
						}}
						transition={{
							duration: 0.1,
							ease: 'easeOut',
						}}
					/>
				);
			})}
		</div>
	);
};
```

## Voice Status Panel

A comprehensive status panel showing all voice information:

```typescript
import React from 'react';
import { motion, AnimatePresence } from 'motion/react';
import {
	Mic,
	MicOff,
	Volume2,
	VolumeX,
	Wifi,
	WifiOff,
	AlertCircle,
	CheckCircle,
} from 'lucide-react';
import { useCedarStore } from '@cedar/core';

export const VoiceStatusPanel: React.FC = () => {
	const voice = useCedarStore((state) => state.voice);

	const getPermissionStatus = () => {
		switch (voice.voicePermissionStatus) {
			case 'granted':
				return {
					icon: CheckCircle,
					color: 'text-green-500',
					text: 'Microphone access granted',
				};
			case 'denied':
				return {
					icon: MicOff,
					color: 'text-red-500',
					text: 'Microphone access denied',
				};
			case 'not-supported':
				return {
					icon: AlertCircle,
					color: 'text-orange-500',
					text: 'Voice not supported',
				};
			default:
				return {
					icon: Mic,
					color: 'text-gray-500',
					text: 'Microphone permission needed',
				};
		}
	};

	const getConnectionStatus = () => {
		// Assuming WebSocket connection status is available
		const isConnected = voice.voiceEndpoint && !voice.voiceError;
		return {
			icon: isConnected ? Wifi : WifiOff,
			color: isConnected ? 'text-green-500' : 'text-red-500',
			text: isConnected
				? 'Connected to voice service'
				: 'Disconnected from voice service',
		};
	};

	const permissionStatus = getPermissionStatus();
	const connectionStatus = getConnectionStatus();

	return (
		<motion.div
			initial={{ opacity: 0, y: 20 }}
			animate={{ opacity: 1, y: 0 }}
			className='bg-white rounded-lg shadow-lg p-6 max-w-md mx-auto'>
			<h3 className='text-lg font-semibold mb-4'>Voice Status</h3>

			{/* Permission Status */}
			<div className='flex items-center gap-3 mb-4'>
				<permissionStatus.icon
					className={`w-5 h-5 ${permissionStatus.color}`}
				/>
				<span className='text-sm'>{permissionStatus.text}</span>
			</div>

			{/* Connection Status */}
			<div className='flex items-center gap-3 mb-4'>
				<connectionStatus.icon
					className={`w-5 h-5 ${connectionStatus.color}`}
				/>
				<span className='text-sm'>{connectionStatus.text}</span>
			</div>

			{/* Current State */}
			<div className='flex items-center gap-3 mb-4'>
				{voice.isListening && (
					<>
						<Mic className='w-5 h-5 text-red-500' />
						<span className='text-sm'>Listening...</span>
						<motion.div
							className='ml-auto flex gap-1'
							initial={{ opacity: 0 }}
							animate={{ opacity: 1 }}>
							{[0, 1, 2].map((i) => (
								<motion.div
									key={i}
									className='w-1 h-3 bg-red-500 rounded-full'
									animate={{
										scaleY: [1, 1.5, 1],
									}}
									transition={{
										duration: 0.5,
										repeat: Infinity,
										delay: i * 0.1,
									}}
								/>
							))}
						</motion.div>
					</>
				)}

				{voice.isSpeaking && (
					<>
						<Volume2 className='w-5 h-5 text-green-500' />
						<span className='text-sm'>Speaking...</span>
						<motion.div
							className='ml-auto w-4 h-4'
							animate={{
								scale: [1, 1.2, 1],
							}}
							transition={{
								duration: 0.8,
								repeat: Infinity,
							}}>
							<div className='w-full h-full bg-green-500 rounded-full opacity-30' />
						</motion.div>
					</>
				)}

				{!voice.isListening && !voice.isSpeaking && (
					<>
						<VolumeX className='w-5 h-5 text-gray-400' />
						<span className='text-sm text-gray-500'>Idle</span>
					</>
				)}
			</div>

			{/* Voice Settings */}
			<div className='border-t pt-4'>
				<h4 className='text-sm font-medium mb-2'>Settings</h4>
				<div className='text-xs text-gray-600 space-y-1'>
					<div>Language: {voice.voiceSettings.language}</div>
					<div>Voice: {voice.voiceSettings.voiceId || 'Default'}</div>
					<div>Rate: {voice.voiceSettings.rate || 1.0}x</div>
					<div>
						Auto-add to messages:{' '}
						{voice.voiceSettings.autoAddToMessages ? 'Yes' : 'No'}
					</div>
				</div>
			</div>

			{/* Error Display */}
			<AnimatePresence>
				{voice.voiceError && (
					<motion.div
						initial={{ opacity: 0, height: 0 }}
						animate={{ opacity: 1, height: 'auto' }}
						exit={{ opacity: 0, height: 0 }}
						className='mt-4 p-3 bg-red-50 border border-red-200 rounded-md'>
						<div className='flex items-center gap-2'>
							<AlertCircle className='w-4 h-4 text-red-500' />
							<span className='text-sm text-red-700'>{voice.voiceError}</span>
						</div>
					</motion.div>
				)}
			</AnimatePresence>
		</motion.div>
	);
};
```

## Voice Settings Component

A settings panel for configuring voice options:

```typescript
import React from 'react';
import { motion } from 'motion/react';
import { Settings, Volume2, Mic } from 'lucide-react';
import { useCedarStore } from '@cedar/core';

export const VoiceSettings: React.FC = () => {
	const voice = useCedarStore((state) => state.voice);

	const voiceOptions = [
		{ value: 'alloy', label: 'Alloy' },
		{ value: 'echo', label: 'Echo' },
		{ value: 'fable', label: 'Fable' },
		{ value: 'onyx', label: 'Onyx' },
		{ value: 'nova', label: 'Nova' },
		{ value: 'shimmer', label: 'Shimmer' },
	];

	const languageOptions = [
		{ value: 'en-US', label: 'English (US)' },
		{ value: 'en-GB', label: 'English (UK)' },
		{ value: 'es-ES', label: 'Spanish' },
		{ value: 'fr-FR', label: 'French' },
		{ value: 'de-DE', label: 'German' },
		{ value: 'it-IT', label: 'Italian' },
		{ value: 'pt-BR', label: 'Portuguese (Brazil)' },
		{ value: 'ja-JP', label: 'Japanese' },
		{ value: 'ko-KR', label: 'Korean' },
		{ value: 'zh-CN', label: 'Chinese (Simplified)' },
	];

	return (
		<motion.div
			initial={{ opacity: 0, scale: 0.95 }}
			animate={{ opacity: 1, scale: 1 }}
			className='bg-white rounded-lg shadow-lg p-6 max-w-md mx-auto'>
			<div className='flex items-center gap-2 mb-6'>
				<Settings className='w-5 h-5' />
				<h3 className='text-lg font-semibold'>Voice Settings</h3>
			</div>

			<div className='space-y-6'>
				{/* Language Selection */}
				<div>
					<label className='block text-sm font-medium text-gray-700 mb-2'>
						<Mic className='w-4 h-4 inline mr-1' />
						Language
					</label>
					<select
						value={voice.voiceSettings.language}
						onChange={(e) =>
							voice.updateVoiceSettings({ language: e.target.value })
						}
						className='w-full p-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500 focus:border-transparent'>
						{languageOptions.map((option) => (
							<option key={option.value} value={option.value}>
								{option.label}
							</option>
						))}
					</select>
				</div>

				{/* Voice Selection */}
				<div>
					<label className='block text-sm font-medium text-gray-700 mb-2'>
						<Volume2 className='w-4 h-4 inline mr-1' />
						Voice
					</label>
					<select
						value={voice.voiceSettings.voiceId || 'alloy'}
						onChange={(e) =>
							voice.updateVoiceSettings({ voiceId: e.target.value })
						}
						className='w-full p-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500 focus:border-transparent'>
						{voiceOptions.map((option) => (
							<option key={option.value} value={option.value}>
								{option.label}
							</option>
						))}
					</select>
				</div>

				{/* Speech Rate */}
				<div>
					<label className='block text-sm font-medium text-gray-700 mb-2'>
						Speech Rate: {voice.voiceSettings.rate || 1.0}x
					</label>
					<input
						type='range'
						min='0.5'
						max='2.0'
						step='0.1'
						value={voice.voiceSettings.rate || 1.0}
						onChange={(e) =>
							voice.updateVoiceSettings({ rate: parseFloat(e.target.value) })
						}
						className='w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer'
					/>
					<div className='flex justify-between text-xs text-gray-500 mt-1'>
						<span>0.5x</span>
						<span>1.0x</span>
						<span>2.0x</span>
					</div>
				</div>

				{/* Volume */}
				<div>
					<label className='block text-sm font-medium text-gray-700 mb-2'>
						Volume: {Math.round((voice.voiceSettings.volume || 1.0) * 100)}%
					</label>
					<input
						type='range'
						min='0'
						max='1'
						step='0.1'
						value={voice.voiceSettings.volume || 1.0}
						onChange={(e) =>
							voice.updateVoiceSettings({ volume: parseFloat(e.target.value) })
						}
						className='w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer'
					/>
				</div>

				{/* Auto-add to Messages */}
				<div className='flex items-center justify-between'>
					<label className='text-sm font-medium text-gray-700'>
						Auto-add to Messages
					</label>
					<motion.button
						onClick={() =>
							voice.updateVoiceSettings({
								autoAddToMessages: !voice.voiceSettings.autoAddToMessages,
							})
						}
						className={`
              relative inline-flex h-6 w-11 items-center rounded-full transition-colors
              ${
								voice.voiceSettings.autoAddToMessages
									? 'bg-blue-600'
									: 'bg-gray-200'
							}
            `}
						whileTap={{ scale: 0.95 }}>
						<motion.span
							className='inline-block h-4 w-4 transform rounded-full bg-white shadow-lg'
							animate={{
								x: voice.voiceSettings.autoAddToMessages ? 24 : 4,
							}}
							transition={{ type: 'spring', stiffness: 500, damping: 30 }}
						/>
					</motion.button>
				</div>

				{/* Browser TTS */}
				<div className='flex items-center justify-between'>
					<label className='text-sm font-medium text-gray-700'>
						Use Browser TTS
					</label>
					<motion.button
						onClick={() =>
							voice.updateVoiceSettings({
								useBrowserTTS: !voice.voiceSettings.useBrowserTTS,
							})
						}
						className={`
              relative inline-flex h-6 w-11 items-center rounded-full transition-colors
              ${
								voice.voiceSettings.useBrowserTTS
									? 'bg-blue-600'
									: 'bg-gray-200'
							}
            `}
						whileTap={{ scale: 0.95 }}>
						<motion.span
							className='inline-block h-4 w-4 transform rounded-full bg-white shadow-lg'
							animate={{
								x: voice.voiceSettings.useBrowserTTS ? 24 : 4,
							}}
							transition={{ type: 'spring', stiffness: 500, damping: 30 }}
						/>
					</motion.button>
				</div>
			</div>
		</motion.div>
	);
};
```

## Complete Voice Interface

Combining all components into a comprehensive voice interface:

```typescript
import React, { useState } from 'react';
import { motion, AnimatePresence } from 'motion/react';
import { Settings } from 'lucide-react';
import {
	VoiceButton,
	VoiceWaveform,
	VoiceStatusPanel,
	VoiceSettings,
} from './VoiceComponents';

export const VoiceInterface: React.FC = () => {
	const [showSettings, setShowSettings] = useState(false);

	return (
		<div className='voice-interface'>
			{/* Main Voice Controls */}
			<div className='flex flex-col items-center gap-6 p-6'>
				{/* Voice Button */}
				<VoiceButton size='large' />

				{/* Waveform Visualizer */}
				<VoiceWaveform className='w-64' />

				{/* Settings Toggle */}
				<motion.button
					onClick={() => setShowSettings(!showSettings)}
					className='flex items-center gap-2 text-gray-600 hover:text-gray-800 transition-colors'
					whileHover={{ scale: 1.05 }}
					whileTap={{ scale: 0.95 }}>
					<Settings className='w-4 h-4' />
					<span className='text-sm'>Settings</span>
				</motion.button>
			</div>

			{/* Status Panel */}
			<div className='mb-6'>
				<VoiceStatusPanel />
			</div>

			{/* Settings Panel */}
			<AnimatePresence>
				{showSettings && (
					<motion.div
						initial={{ opacity: 0, height: 0 }}
						animate={{ opacity: 1, height: 'auto' }}
						exit={{ opacity: 0, height: 0 }}
						className='overflow-hidden'>
						<VoiceSettings />
					</motion.div>
				)}
			</AnimatePresence>
		</div>
	);
};
```

## Styling Guidelines

### CSS Classes for Voice Components

```css
/* Voice button states */
.voice-button {
	@apply transition-all duration-200 ease-out;
}

.voice-button:hover {
	@apply transform scale-105;
}

.voice-button.listening {
	@apply bg-red-500 shadow-lg shadow-red-500/25;
	animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}

.voice-button.speaking {
	@apply bg-green-500 shadow-lg shadow-green-500/25;
}

/* Voice indicator animations */
.voice-indicator {
	@apply flex items-center gap-2 justify-center;
}

.voice-indicator .listening-bars {
	@apply flex gap-1;
}

.voice-indicator .speaking-pulse {
	@apply w-4 h-4 bg-green-500 rounded-full opacity-30;
	animation: speaking-pulse 0.8s ease-in-out infinite;
}

/* Waveform visualizer */
.voice-waveform {
	@apply flex items-end justify-center gap-1;
}

.voice-waveform .bar {
	@apply w-1 rounded-full transition-all duration-100 ease-out;
	min-height: 2px;
}

/* Keyframes */
@keyframes pulse {
	0%,
	100% {
		opacity: 1;
	}
	50% {
		opacity: 0.8;
	}
}

@keyframes speaking-pulse {
	0%,
	100% {
		transform: scale(1);
	}
	50% {
		transform: scale(1.2);
	}
}
```

## Accessibility Considerations

### ARIA Labels and Screen Reader Support

```typescript
// Enhanced VoiceButton with accessibility
export const AccessibleVoiceButton: React.FC<VoiceButtonProps> = (props) => {
	const voice = useCedarStore((state) => state.voice);

	const getAriaLabel = () => {
		if (voice.isListening) return 'Stop listening';
		if (voice.voicePermissionStatus === 'denied')
			return 'Microphone access denied';
		if (voice.voicePermissionStatus === 'not-supported')
			return 'Voice not supported';
		return 'Start listening';
	};

	return (
		<motion.button
			{...props}
			aria-label={getAriaLabel()}
			aria-pressed={voice.isListening}
			role='button'
			tabIndex={0}
			onKeyDown={(e) => {
				if (e.key === 'Enter' || e.key === ' ') {
					e.preventDefault();
					handleClick();
				}
			}}>
			{/* Button content */}
		</motion.button>
	);
};
```

### Reduced Motion Support

```typescript
// Respect user's motion preferences
const shouldReduceMotion = window.matchMedia(
	'(prefers-reduced-motion: reduce)'
).matches;

const animationProps = shouldReduceMotion
	? {}
	: {
			animate: { scale: [1, 1.2, 1] },
			transition: { duration: 0.8, repeat: Infinity },
	  };

<motion.div {...animationProps}>{/* Content */}</motion.div>;
```

## Testing Voice Components

```typescript
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { VoiceButton } from './VoiceButton';
import { useCedarStore } from '@cedar/core';

// Mock the store
jest.mock('@cedar/core', () => ({
	useCedarStore: jest.fn(),
}));

describe('VoiceButton', () => {
	const mockVoice = {
		isListening: false,
		voicePermissionStatus: 'granted',
		toggleVoice: jest.fn(),
		requestVoicePermission: jest.fn(),
	};

	beforeEach(() => {
		(useCedarStore as jest.Mock).mockReturnValue(mockVoice);
	});

	it('renders correctly', () => {
		render(<VoiceButton />);
		expect(screen.getByRole('button')).toBeInTheDocument();
	});

	it('calls toggleVoice when clicked', async () => {
		render(<VoiceButton />);

		fireEvent.click(screen.getByRole('button'));

		await waitFor(() => {
			expect(mockVoice.toggleVoice).toHaveBeenCalled();
		});
	});

	it('shows correct state when listening', () => {
		(useCedarStore as jest.Mock).mockReturnValue({
			...mockVoice,
			isListening: true,
		});

		render(<VoiceButton />);

		expect(screen.getByLabelText('Stop listening')).toBeInTheDocument();
	});
});
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Voice Overview" icon="microphone" href="/voice/voice-integration">
    Return to the main voice documentation
  </Card>

  <Card title="Backend Integration" icon="server" href="/voice/agentic-backend">
    Learn about setting up voice backend processing
  </Card>
</CardGroup>

{' '}


# Voice Endpoint Format
Source: https://docs.cedarcopilot.com/voice/voice-endpoint-format

Learn how to implement voice endpoints for Mastra and custom backends

# Voice Endpoint Format

Cedar OS provides two approaches for handling voice, depending on your provider configuration:

1. **Mastra/Custom backends**: Direct voice endpoint handling
2. **AI SDK/OpenAI providers**: Automatic transcription and speech generation

## Provider-Specific Voice Handling

### Mastra and Custom Backends

When using Mastra or custom backends, Cedar OS sends voice data directly to your voice endpoint. You have full control over:

* Audio transcription
* Response generation
* Text-to-speech synthesis
* Response format

### AI SDK and OpenAI Providers

When using AI SDK or OpenAI providers, Cedar OS automatically:

1. Transcribes audio using OpenAI's Whisper model
2. Generates a text response using the configured LLM
3. Optionally generates speech using OpenAI's TTS model (when `useBrowserTTS` is false)

## Request Format (Mastra/Custom)

Cedar OS sends voice data to your endpoint as a multipart form data request:

```http
POST /voice
Content-Type: multipart/form-data
Authorization: Bearer YOUR_API_KEY (if configured)

FormData:
- audio: Blob (audio file, typically webm format)
- settings: JSON string containing voice settings
- context: String containing additional context
- any other fields off of BaseParams
```

### Voice Settings Structure

The `settings` field contains a JSON object with the following structure:

```json
{
	"language": "en-US",
	"voiceId": "optional-voice-id",
	"pitch": 1.0,
	"rate": 1.0,
	"volume": 1.0,
	"useBrowserTTS": false,
	"autoAddToMessages": true
}
```

* `language`: Language code for speech recognition/synthesis
* `voiceId`: Voice identifier for TTS (provider-specific)
* `pitch`, `rate`, `volume`: Voice modulation parameters
* `useBrowserTTS`: Whether to use browser's built-in TTS
* `autoAddToMessages`: Whether to add voice interactions to chat history

### Context

The `context` field contains stringified additional context from the Cedar state, which may include:

* Current chat messages
* Application state
* User-defined context

## Response Format (All Providers)

Your endpoint can return different types of responses:

### 1. JSON Response (Recommended)

```json
{
	"text": "The assistant's response text",
	"transcription": "What the user said",
	"audioData": "base64-encoded-audio-data",
	"audioUrl": "https://example.com/audio.mp3",
	"audioFormat": "audio/mpeg",
	"usage": {
		"promptTokens": 100,
		"completionTokens": 50,
		"totalTokens": 150
	},
	"object": {
		"type": "setState",
		"stateKey": "myState",
		"setterKey": "updateValue",
		"args": ["new value"]
	}
}
```

All fields are optional:

* `text`: The text response from the assistant
* `transcription`: The transcribed user input
* `audioData`: Base64-encoded audio response
* `audioUrl`: URL to an audio file
* `audioFormat`: MIME type of the audio
* `usage`: Token usage statistics
* `object`: Structured response for actions

### 2. Audio Response

Return raw audio data with appropriate content type:

```http
HTTP/1.1 200 OK
Content-Type: audio/mpeg

[Binary audio data]
```

### 3. Plain Text Response

```http
HTTP/1.1 200 OK
Content-Type: text/plain

This is the assistant's response.
```

## Implementation Example (Mastra)

Here's an example of implementing a voice endpoint in a Mastra backend:

```typescript
import { Agent } from '@mastra/core';

export async function POST(request: Request) {
	const formData = await request.formData();
	const audio = formData.get('audio') as Blob;
	const settings = JSON.parse(formData.get('settings') as string);
	const context = formData.get('context') as string;

	// Process audio (transcription)
	const transcription = await transcribeAudio(audio);

	// Generate response using your agent
	const agent = new Agent({
		// ... agent configuration
	});

	const response = await agent.generate({
		prompt: transcription,
		context: context,
	});

	// Optionally generate speech
	let audioData;
	if (!settings.useBrowserTTS) {
		audioData = await generateSpeech(response.text);
	}

	// Return JSON response
	return Response.json({
		text: response.text,
		transcription: transcription,
		audioData: audioData
			? Buffer.from(audioData).toString('base64')
			: undefined,
		usage: response.usage,
	});
}
```

## Voice Response Handling

Cedar OS provides a unified `handleLLMVoice` function that processes voice responses consistently across all providers:

1. **Audio Playback**: Handles base64 audio data, audio URLs, or browser TTS
2. **Message Integration**: Automatically adds transcriptions and responses to chat history
3. **Action Execution**: Processes structured responses to trigger state changes

## Structured Responses

Cedar OS supports structured responses that can trigger actions in your application:

### SetState Response

To execute a state change:

```json
{
	"text": "I've updated the value for you.",
	"object": {
		"type": "setState",
		"stateKey": "myCustomState",
		"setterKey": "setValue",
		"args": [42]
	}
}
```

This will call `myCustomState.setValue(42)` in your Cedar state.

## Error Handling

Return appropriate HTTP status codes:

* `200 OK`: Successful response
* `400 Bad Request`: Invalid request format
* `401 Unauthorized`: Missing or invalid API key
* `500 Internal Server Error`: Server-side error

## Voice Configuration

Configure voice settings when initializing Cedar:

```typescript
const store = createCedarStore({
	voiceSettings: {
		language: 'en-US',
		voiceId: 'alloy', // OpenAI voice options: alloy, echo, fable, onyx, nova, shimmer
		useBrowserTTS: false, // Use provider TTS instead of browser
		autoAddToMessages: true, // Add voice interactions to chat
	},
});
```

## Provider-Specific Notes

### OpenAI/AI SDK

* Transcription: Uses Whisper model (`whisper-1`)
* Speech: Uses TTS model (`tts-1`) with configurable voices
* Audio format: MP3 (audio/mpeg)

### Mastra/Custom

* Full control over transcription and TTS services
* Can integrate with any speech service (Google, Azure, AWS, etc.)
* Flexible audio format support


# Voice Integration (Beta)
Source: https://docs.cedarcopilot.com/voice/voice-integration

Add voice capabilities to your Cedar OS application

# Voice Integration

Cedar OS provides comprehensive voice support that integrates seamlessly with your agent backend. Voice processing is now handled through the agent connection system, providing a unified approach across different providers.

## Voice Processing Architecture

<Note>
  As of the latest update, voice processing now works out of the box for Mastra, AI SDK, and custom backends.

  * **Mastra/Custom backends**: Voice data is sent directly to your voice endpoint
  * **AI SDK/OpenAI providers**: Voice is transcribed using Whisper, then processed through the LLM.

  See the [Voice Endpoint Format](/voice/voice-endpoint-format) documentation for implementation details.

  This is still in beta. If you want more details please check out the repo, book a call at [https://calendly.com/jesse-cedarcopilot/30min](https://calendly.com/jesse-cedarcopilot/30min) or join our discord.
</Note>

## Quick Start

Initialize Cedar with voice settings (already configured with the built in Cedar chat input):

```tsx
import { CedarCopilot } from 'cedar-os';

function App() {
	return (
		<CedarCopilot
			llmProvider={{
				provider: 'openai',
				apiKey: process.env.OPENAI_API_KEY!,
			}}
			voiceSettings={{
				language: 'en-US',
				voiceId: 'alloy', // OpenAI voices: alloy, echo, fable, onyx, nova, shimmer
				useBrowserTTS: false, // Use OpenAI TTS instead of browser
				autoAddToMessages: true, // Add voice interactions to chat history
				pitch: 1.0,
				rate: 1.0,
				volume: 1.0,
				endpoint: '/api/voice', // Optional: Custom voice endpoint
			}}>
			{/* Your app content */}
		</CedarCopilot>
	);
}
```

### Voice Settings

The `voiceSettings` prop accepts a partial configuration object with the following TypeScript interface:

```typescript
interface VoiceSettings {
	language: string;                // Required - Language code for speech recognition/synthesis
	voiceId?: string;               // Optional - Voice identifier (provider-specific)
	pitch?: number;                 // Optional - Voice pitch modulation (0.5-2.0)
	rate?: number;                  // Optional - Speech rate (0.5-2.0)
	volume?: number;                // Optional - Audio volume (0.0-1.0)
	useBrowserTTS?: boolean;        // Optional - Use browser's built-in TTS
	autoAddToMessages?: boolean;    // Optional - Add voice interactions to chat
	endpoint?: string;              // Optional - Custom voice endpoint URL
}

// Usage: All properties except 'language' are optional
voiceSettings?: Partial<VoiceSettings>
```

#### Default Values

| Setting             | Type    | Default     | Description                                    |
| ------------------- | ------- | ----------- | ---------------------------------------------- |
| `language`          | string  | `'en-US'`   | Language code for speech recognition/synthesis |
| `voiceId`           | string  | `undefined` | Voice identifier (provider-specific)           |
| `pitch`             | number  | `1.0`       | Voice pitch modulation (0.5-2.0)               |
| `rate`              | number  | `1.0`       | Speech rate (0.5-2.0)                          |
| `volume`            | number  | `1.0`       | Audio volume (0.0-1.0)                         |
| `useBrowserTTS`     | boolean | `false`     | Use browser's built-in TTS                     |
| `autoAddToMessages` | boolean | `true`      | Add voice interactions to chat                 |
| `endpoint`          | string  | `undefined` | Custom voice endpoint URL                      |

### Provider-Specific Configuration

#### OpenAI / AI SDK

```tsx
<CedarCopilot
  llmProvider={{
    provider: 'ai-sdk',
    providers: {
      openai: { apiKey: process.env.OPENAI_API_KEY! },
    },
  }}
  voiceSettings={{
    voiceId: 'nova', // OpenAI voice selection
    useBrowserTTS: false, // Use OpenAI TTS
  }}
>
```

#### Mastra

```tsx
<CedarCopilot
  llmProvider={{
    provider: 'mastra',
    baseURL: 'https://your-mastra-api.com',
    apiKey: process.env.MASTRA_API_KEY,
    voiceRoute: '/voice', // Auto-configures voice endpoint
  }}
  voiceSettings={{
    language: 'en-US',
    autoAddToMessages: true,
    // endpoint is auto-configured from voiceRoute
  }}
>
```

#### Custom Backend

```tsx
<CedarCopilot
  llmProvider={{
    provider: 'custom',
    // ... custom provider config
  }}
  voiceSettings={{
    endpoint: 'https://your-api.com/voice',
    useBrowserTTS: true, // Use browser TTS if backend doesn't provide audio
  }}
>
```

## Overview

Cedar-OS provides a complete voice integration system that enables natural voice conversations with AI agents. The voice system handles audio capture, streaming to backend services, and automatic playback of responses, with seamless integration into the messaging system.

## Features

* ðŸŽ¤ **Voice Capture**: Browser-based audio recording with permission management
* ðŸ”Š **Audio Playback**: Automatic playback of audio responses from agents
* ðŸŒ **Streaming Support**: Real-time audio streaming to configurable endpoints
* ðŸ”§ **Flexible Configuration**: Customizable voice settings (language, pitch, rate, volume)
* ðŸŽ¯ **State Management**: Full integration with Cedar's Zustand-based store
* ðŸ’¬ **Message Integration**: Automatic addition of voice interactions to chat history
* ðŸ›¡ï¸ **Error Handling**: Comprehensive error states and recovery
* ðŸŽ¨ **Visual Indicators**: Animated voice status indicators

## ChatInput Component with Built-in Voice

The `ChatInput` component from `cedar-os-components` comes with voice functionality built-in, providing a seamless voice experience out of the box. When you use this component, voice capabilities are automatically available without additional configuration.

### How It Works

The ChatInput component integrates voice through the following key features:

<CodeGroup>
  ```tsx useVoice Hook
  import { useVoice } from 'cedar-os';

  // The useVoice hook provides complete access to voice state and controls
  const voice = useVoice();

  // Available properties
  voice.isListening; // Is currently recording audio
  voice.isSpeaking; // Is playing audio response
  voice.voicePermissionStatus; // 'granted' | 'denied' | 'prompt' | 'not-supported'
  voice.voiceError; // Error message if any
  voice.voiceSettings; // Current voice configuration

  // Available methods
  voice.checkVoiceSupport(); // Check browser compatibility
  voice.requestVoicePermission(); // Request microphone access
  voice.toggleVoice(); // Start/stop recording
  voice.startListening(); // Start recording
  voice.stopListening(); // Stop recording
  voice.updateVoiceSettings(); // Update configuration
  voice.resetVoiceState(); // Clean up resources
  ```

  ```tsx VoiceIndicator Component
  import { VoiceIndicator } from 'cedar-os';

  // Visual feedback component for voice status
  <VoiceIndicator
  	voiceState={{
  		isListening: voice.isListening,
  		isSpeaking: voice.isSpeaking,
  		voiceError: voice.voiceError,
  		voicePermissionStatus: voice.voicePermissionStatus,
  	}}
  />;

  // The indicator shows:
  // - Animated bars when listening (red)
  // - Pulsing circle when speaking (green)
  // - Error messages with alert icon
  // - Automatically hides when inactive
  ```

  ```tsx Voice Toggle Implementation
  // Handle voice toggle with permission management
  const handleVoiceToggle = async () => {
  	// Check browser support
  	if (!voice.checkVoiceSupport()) {
  		console.error('Voice not supported');
  		return;
  	}

  	// Request permission if needed
  	if (voice.voicePermissionStatus === 'prompt') {
  		await voice.requestVoicePermission();
  	}

  	// Toggle voice if permitted
  	if (voice.voicePermissionStatus === 'granted') {
  		voice.toggleVoice();
  	}
  };
  ```
</CodeGroup>

### ChatInput Implementation Details

The ChatInput component automatically:

1. **Displays a microphone button** that changes appearance based on voice state
2. **Shows the VoiceIndicator** when voice is active (listening or speaking)
3. **Handles keyboard shortcuts** - Press 'M' to toggle voice (when not typing)
4. **Manages permissions** - Automatically requests microphone access when needed
5. **Provides visual feedback** - Button animations and color changes for different states

<CodeGroup>
  ```tsx Microphone Button States
  // The mic button automatically changes appearance
  getMicButtonClass() {
    if (voice.isListening) {
      // Red pulsing animation when recording
      return 'text-red-500 animate-pulse';
    }
    if (voice.isSpeaking) {
      // Green when playing response
      return 'text-green-500';
    }
    if (voice.voicePermissionStatus === 'denied') {
      // Grayed out if permission denied
      return 'text-gray-400 cursor-not-allowed';
    }
    // Default state
    return 'text-gray-600 hover:text-black';
  }
  ```

  ```tsx Keyboard Shortcut
  // Global keyboard shortcut for voice
  useEffect(() => {
  	const handleKeyDown = (e: KeyboardEvent) => {
  		// Press 'M' to toggle voice
  		if (e.key === 'm' || e.key === 'M') {
  			// Only when not typing in input fields
  			if (!isTypingInInput) {
  				e.preventDefault();
  				handleVoiceToggle();
  			}
  		}
  	};

  	window.addEventListener('keydown', handleKeyDown);
  	return () => window.removeEventListener('keydown', handleKeyDown);
  }, [handleVoiceToggle]);
  ```

  ```tsx Complete ChatInput Usage
  import { ChatInput } from 'cedar-os-components';

  // Simply use the ChatInput component - voice is included!
  <ChatInput
  	stream={true}
  	className='custom-styles'
  	handleFocus={() => console.log('Focused')}
  	handleBlur={() => console.log('Blurred')}
  />;

  // Voice features are automatically available:
  // - Mic button in the input
  // - Voice indicator when active
  // - Keyboard shortcut (M key)
  // - Permission handling
  // - Visual feedback
  ```
</CodeGroup>

### Exported Components and Hooks

All voice-related functionality is exported from the main `cedar-os` package:

```typescript
// Main exports from 'cedar-os'
export { useVoice } from 'cedar-os'; // Voice control hook
export { VoiceIndicator } from 'cedar-os'; // Voice status component
export { cn } from 'cedar-os'; // Utility for className merging

// The ChatInput component is in cedar-os-components
import { ChatInput } from 'cedar-os-components';
```

## Quick Start

### 1. Automatic Configuration with Mastra

The easiest way to set up voice integration is through the Mastra provider configuration:

```typescript
import { CedarCopilot } from 'cedar-os';

function App() {
	return (
		<CedarCopilot
			llmProvider={{
				provider: 'mastra',
				baseURL: 'http://localhost:3000/api',
				voiceRoute: '/chat/voice-execute', // Automatically configures voice endpoint
			}}>
			<YourVoiceApp />
		</CedarCopilot>
	);
}
```

When you specify a `voiceRoute` in your Mastra configuration, Cedar-OS automatically sets the voice endpoint to `baseURL + voiceRoute`.

### 2. Manual Configuration

For non-Mastra providers or custom setups, configure the voice endpoint manually:

```typescript
import { useCedarStore } from '@cedar/core';

function VoiceChat() {
	const voice = useCedarStore((state) => state.voice);

	useEffect(() => {
		// Configure the voice endpoint manually
		voice.setVoiceEndpoint('http://localhost:3456/api/chat/voice');

		// Cleanup on unmount
		return () => {
			voice.resetVoiceState();
		};
	}, []);

	return (
		<div>
			<button
				onClick={() => voice.toggleVoice()}
				disabled={voice.voicePermissionStatus !== 'granted'}>
				{voice.isListening ? 'Stop Listening' : 'Start Listening'}
			</button>

			{voice.voiceError && <div className='error'>{voice.voiceError}</div>}
		</div>
	);
}
```

### 3. Request Microphone Permission

```typescript
const handleEnableVoice = async () => {
	if (!voice.checkVoiceSupport()) {
		alert('Voice features are not supported in your browser');
		return;
	}

	await voice.requestVoicePermission();

	if (voice.voicePermissionStatus === 'granted') {
		console.log('Voice enabled!');
	}
};
```

### 4. Using the Voice Indicator

```typescript
import { VoiceIndicator } from '@cedar/voice';

function App() {
	const voice = useCedarStore((state) => state.voice);

	return (
		<div>
			<VoiceIndicator voiceState={voice} />
			{/* Rest of your app */}
		</div>
	);
}
```

## Provider-Specific Voice Configuration

### Mastra Provider

When using the Mastra provider, voice configuration is streamlined through the provider setup:

```typescript
<CedarCopilot
	llmProvider={{
		provider: 'mastra',
		baseURL: 'http://localhost:3000/api',
		chatPath: '/chat',
		voiceRoute: '/chat/voice-execute', // Automatically sets voice endpoint
	}}>
	<YourApp />
</CedarCopilot>
```

**Benefits of Mastra voice integration:**

* Automatic endpoint configuration
* Consistent routing with chat endpoints
* Built-in context passing
* Structured response handling

### Other Providers

For OpenAI, Anthropic, AI SDK, or custom providers, configure the voice endpoint manually:

```typescript
const voice = useCedarStore((state) => state.voice);

useEffect(() => {
	// Set your custom voice endpoint
	voice.setVoiceEndpoint('https://your-backend.com/api/voice');
}, []);
```

## Voice State

The voice slice manages comprehensive state for voice interactions:

```typescript
interface VoiceState {
	// Core state
	isVoiceEnabled: boolean;
	isListening: boolean;
	isSpeaking: boolean;
	voiceEndpoint: string;
	voicePermissionStatus: 'granted' | 'denied' | 'prompt' | 'not-supported';
	voiceError: string | null;

	// Audio resources
	audioStream: MediaStream | null;
	audioContext: AudioContext | null;
	mediaRecorder: MediaRecorder | null;

	// Voice settings
	voiceSettings: {
		language: string; // Required - Language code (e.g., 'en-US')
		voiceId?: string; // Optional - Voice ID for TTS (provider-specific)
		pitch?: number; // Optional - Voice pitch (0.5 to 2.0)
		rate?: number; // Optional - Speech rate (0.5 to 2.0)
		volume?: number; // Optional - Audio volume (0.0 to 1.0)
		useBrowserTTS?: boolean; // Optional - Use browser TTS instead of backend
		autoAddToMessages?: boolean; // Optional - Add voice interactions to messages
		endpoint?: string; // Optional - Custom voice endpoint URL
	};
}
```

## Available Actions

### Permission Management

* `checkVoiceSupport()` - Check if browser supports voice features
* `requestVoicePermission()` - Request microphone access

### Voice Control

* `startListening()` - Start recording audio
* `stopListening()` - Stop recording and send to endpoint
* `toggleVoice()` - Toggle between listening and idle states

### Audio Processing

* `streamAudioToEndpoint(audioData)` - Send audio to backend
* `playAudioResponse(audioUrl)` - Play audio response

### Configuration

* `setVoiceEndpoint(endpoint)` - Set the backend endpoint URL
* `updateVoiceSettings(settings)` - Update voice configuration
* `setVoiceError(error)` - Set error message
* `resetVoiceState()` - Clean up and reset all voice state

## Message Integration

By default, voice interactions are automatically added to the Cedar messages store, creating a seamless conversation history:

```typescript
// User speech is transcribed and added as a user message
{
  type: 'text',
  role: 'user',
  content: 'Show me the latest reports',
  metadata: {
    source: 'voice',
    timestamp: '2024-01-01T12:00:00Z'
  }
}

// Agent response is added as an assistant message
{
  type: 'text',
  role: 'assistant',
  content: 'Here are your latest reports...',
  metadata: {
    source: 'voice',
    usage: { /* token usage data */ },
    timestamp: '2024-01-01T12:00:01Z'
  }
}
```

### Disabling Message Integration

```typescript
voice.updateVoiceSettings({
	autoAddToMessages: false,
});
```

## Browser Compatibility

The voice system requires modern browser APIs:

* `navigator.mediaDevices.getUserMedia` - Audio capture
* `MediaRecorder` API - Audio recording
* `AudioContext` API - Audio processing

**Supported browsers:**

* Chrome/Edge 47+
* Firefox 25+
* Safari 11+
* Opera 34+

<Warning>
  HTTPS is required for microphone access in production environments (localhost
  is exempt).
</Warning>

## Next Steps

<CardGroup cols={2}>
  <Card title="Backend Integration" icon="server" href="/voice/agentic-backend">
    Learn how to set up your backend to handle voice requests
  </Card>

  <Card title="Streaming Implementation" icon="wave-square" href="/voice/streams">
    Implement real-time audio streaming
  </Card>
</CardGroup>

## Examples

### Complete Voice Chat Component

```typescript
import { useCedarStore } from '@cedar/core';
import { VoiceIndicator } from '@cedar/voice';
import { useEffect } from 'react';

export function VoiceChat() {
	const voice = useCedarStore((state) => state.voice);

	useEffect(() => {
		voice.setVoiceEndpoint('http://localhost:3456/api/chat/voice');
		return () => voice.resetVoiceState();
	}, []);

	const handleVoiceToggle = async () => {
		if (voice.voicePermissionStatus === 'prompt') {
			await voice.requestVoicePermission();
		}

		if (voice.voicePermissionStatus === 'granted') {
			voice.toggleVoice();
		}
	};

	return (
		<div className='voice-chat'>
			<VoiceIndicator voiceState={voice} />

			<button
				onClick={handleVoiceToggle}
				className={`voice-button ${voice.isListening ? 'listening' : ''}`}
				disabled={voice.voicePermissionStatus === 'denied'}>
				{voice.isListening ? 'Stop' : 'Talk'}
			</button>

			{voice.voiceError && (
				<div className='error-message'>{voice.voiceError}</div>
			)}

			<div className='voice-settings'>
				<select
					value={voice.voiceSettings.language}
					onChange={(e) =>
						voice.updateVoiceSettings({ language: e.target.value })
					}>
					<option value='en-US'>English (US)</option>
					<option value='en-GB'>English (UK)</option>
					<option value='es-ES'>Spanish</option>
					<option value='fr-FR'>French</option>
				</select>
			</div>
		</div>
	);
}
```
